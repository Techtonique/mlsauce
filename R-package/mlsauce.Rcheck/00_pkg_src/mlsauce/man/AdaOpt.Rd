% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/adaopt.R
\name{AdaOpt}
\alias{AdaOpt}
\title{AdaOpt classifier}
\usage{
AdaOpt(
  n_iterations = 50L,
  learning_rate = 0.3,
  reg_lambda = 0.1,
  reg_alpha = 0.5,
  eta = 0.01,
  gamma = 0.01,
  k = 3L,
  tolerance = 0,
  n_clusters = 0,
  batch_size = 100L,
  row_sample = 1,
  type_dist = "euclidean-f",
  cache = TRUE,
  seed = 123L
)
}
\arguments{
\item{n_iterations}{number of iterations of the optimizer at training time}

\item{learning_rate}{controls the speed of the optimizer at training time}

\item{reg_lambda}{L2 regularization parameter for successive errors in the optimizer (at training time)}

\item{reg_alpha}{L1 regularization parameter for successive errors in the optimizer (at training time)}

\item{eta}{controls the slope in gradient descent (at training time)}

\item{gamma}{controls the step size in gradient descent (at training time)}

\item{k}{number of nearest neighbors selected at test time for classification}

\item{tolerance}{controls early stopping in gradient descent (at training time)}

\item{n_clusters}{number of clusters, if MiniBatch k-means is used at test time (for faster prediction)}

\item{batch_size}{size of the batch, if MiniBatch k-means is used at test time (for faster prediction)}

\item{row_sample}{percentage of rows chosen from training set (by stratified subsampling, for faster prediction)}

\item{type_dist}{distance used for finding the nearest neighbors; currently \code{euclidean-f} (euclidean distances
calculated as whole), \code{euclidean} (euclidean distances calculated row by row), \code{cosine} (cosine distance)}

\item{cache}{if the nearest neighbors are cached or not, for faster retrieval in subsequent calls}

\item{seed}{reproducibility seed for initial weak learner and clustering}
}
\value{
An object of class AdaOpt
}
\description{
AdaOpt classifier
}
\examples{

library(datasets)

X <- as.matrix(iris[, 1:4])
y <- as.integer(iris[, 5]) - 1L

n <- dim(X)[1]
p <- dim(X)[2]
set.seed(21341)
train_index <- sample(x = 1:n, size = floor(0.8*n), replace = TRUE)
test_index <- -train_index
X_train <- as.matrix(iris[train_index, 1:4])
y_train <- as.integer(iris[train_index, 5]) - 1L
X_test <- as.matrix(iris[test_index, 1:4])
y_test <- as.integer(iris[test_index, 5]) - 1L

obj <- mlsauce::AdaOpt()

print(obj$get_params())

obj$fit(X_train, y_train)

print(obj$score(X_test, y_test))

}
