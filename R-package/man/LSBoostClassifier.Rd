% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lsboost.R
\name{LSBoostClassifier}
\alias{LSBoostClassifier}
\title{LSBoost classifier}
\usage{
LSBoostClassifier(
  n_estimators = 100L,
  learning_rate = 0.1,
  n_hidden_features = 5L,
  reg_lambda = 0.1,
  row_sample = 1,
  col_sample = 1,
  dropout = 0,
  tolerance = 1e-04,
  direct_link = 1L,
  verbose = 1L,
  seed = 123L,
  solver = c("ridge", "lasso"),
  activation = "relu"
)
}
\arguments{
\item{n_estimators:}{int, number of boosting iterations.}

\item{learning_rate:}{float, controls the learning speed at training time.}

\item{n_hidden_features:}{int}

\item{number}{of nodes in successive hidden layers.}

\item{reg_lambda:}{float, L2 regularization parameter for successive errors in the optimizer (at training time).}

\item{row_sample:}{float, percentage of rows chosen from the training set.}

\item{col_sample:}{float, percentage of columns chosen from the training set.}

\item{dropout:}{float, percentage of nodes dropped from the training set.}

\item{tolerance:}{float, controls early stopping in gradient descent (at training time).}

\item{direct_link:}{bool, indicates whether the original features are included (True) in model's fitting or not (False).}

\item{verbose:}{int, progress bar (yes = 1) or not (no = 0) (currently).}

\item{seed:}{int, reproducibility seed for nodes_sim=='uniform', clustering and dropout.}

\item{solver:}{str, type of 'weak' learner; currently in ('ridge', 'lasso')}

\item{activation:}{str, activation function: currently 'relu', 'relu6', 'sigmoid', 'tanh'}
}
\value{
An object of class LSBoostClassifier
}
\description{
LSBoost classifier
}
\examples{

library(datasets)

X <- as.matrix(iris[, 1:4])
y <- as.integer(iris[, 5]) - 1L

n <- dim(X)[1]
p <- dim(X)[2]
set.seed(21341)
train_index <- sample(x = 1:n, size = floor(0.8*n), replace = TRUE)
test_index <- -train_index
X_train <- as.matrix(X[train_index, ])
y_train <- as.integer(y[train_index])
X_test <- as.matrix(X[test_index, ])
y_test <- as.integer(y[test_index])

obj <- mlsauce::LSBoostClassifier()

print(obj$get_params())

obj$fit(X_train, y_train)

print(obj$score(X_test, y_test))

}
