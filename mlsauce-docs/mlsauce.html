<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 14.4.0"/>
    <title>mlsauce API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! theme.css */:root{--pdoc-background:#212529;}.pdoc{--text:#f7f7f7;--muted:#9d9d9d;--link:#58a6ff;--link-hover:#3989ff;--code:#333;--active:#555;--accent:#343434;--accent2:#555;--nav-hover:rgba(0, 0, 0, 0.1);--name:#77C1FF;--def:#0cdd0c;--annotation:#00c037;}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#49483e}.pdoc-code{background:#272822; color:#f8f8f2}.pdoc-code .c{color:#75715e}.pdoc-code .err{color:#960050; background-color:#1e0010}.pdoc-code .esc{color:#f8f8f2}.pdoc-code .g{color:#f8f8f2}.pdoc-code .k{color:#66d9ef}.pdoc-code .l{color:#ae81ff}.pdoc-code .n{color:#f8f8f2}.pdoc-code .o{color:#f92672}.pdoc-code .x{color:#f8f8f2}.pdoc-code .p{color:#f8f8f2}.pdoc-code .ch{color:#75715e}.pdoc-code .cm{color:#75715e}.pdoc-code .cp{color:#75715e}.pdoc-code .cpf{color:#75715e}.pdoc-code .c1{color:#75715e}.pdoc-code .cs{color:#75715e}.pdoc-code .gd{color:#f92672}.pdoc-code .ge{color:#f8f8f2; font-style:italic}.pdoc-code .gr{color:#f8f8f2}.pdoc-code .gh{color:#f8f8f2}.pdoc-code .gi{color:#a6e22e}.pdoc-code .go{color:#66d9ef}.pdoc-code .gp{color:#f92672; font-weight:bold}.pdoc-code .gs{color:#f8f8f2; font-weight:bold}.pdoc-code .gu{color:#75715e}.pdoc-code .gt{color:#f8f8f2}.pdoc-code .kc{color:#66d9ef}.pdoc-code .kd{color:#66d9ef}.pdoc-code .kn{color:#f92672}.pdoc-code .kp{color:#66d9ef}.pdoc-code .kr{color:#66d9ef}.pdoc-code .kt{color:#66d9ef}.pdoc-code .ld{color:#e6db74}.pdoc-code .m{color:#ae81ff}.pdoc-code .s{color:#e6db74}.pdoc-code .na{color:#a6e22e}.pdoc-code .nb{color:#f8f8f2}.pdoc-code .nc{color:#a6e22e}.pdoc-code .no{color:#66d9ef}.pdoc-code .nd{color:#a6e22e}.pdoc-code .ni{color:#f8f8f2}.pdoc-code .ne{color:#a6e22e}.pdoc-code .nf{color:#a6e22e}.pdoc-code .nl{color:#f8f8f2}.pdoc-code .nn{color:#f8f8f2}.pdoc-code .nx{color:#a6e22e}.pdoc-code .py{color:#f8f8f2}.pdoc-code .nt{color:#f92672}.pdoc-code .nv{color:#f8f8f2}.pdoc-code .ow{color:#f92672}.pdoc-code .w{color:#f8f8f2}.pdoc-code .mb{color:#ae81ff}.pdoc-code .mf{color:#ae81ff}.pdoc-code .mh{color:#ae81ff}.pdoc-code .mi{color:#ae81ff}.pdoc-code .mo{color:#ae81ff}.pdoc-code .sa{color:#e6db74}.pdoc-code .sb{color:#e6db74}.pdoc-code .sc{color:#e6db74}.pdoc-code .dl{color:#e6db74}.pdoc-code .sd{color:#e6db74}.pdoc-code .s2{color:#e6db74}.pdoc-code .se{color:#ae81ff}.pdoc-code .sh{color:#e6db74}.pdoc-code .si{color:#e6db74}.pdoc-code .sx{color:#e6db74}.pdoc-code .sr{color:#e6db74}.pdoc-code .s1{color:#e6db74}.pdoc-code .ss{color:#e6db74}.pdoc-code .bp{color:#f8f8f2}.pdoc-code .fm{color:#a6e22e}.pdoc-code .vc{color:#f8f8f2}.pdoc-code .vg{color:#f8f8f2}.pdoc-code .vi{color:#f8f8f2}.pdoc-code .vm{color:#f8f8f2}</style>
    <style>/*! theme.css */:root{--pdoc-background:#212529;}.pdoc{--text:#f7f7f7;--muted:#9d9d9d;--link:#58a6ff;--link-hover:#3989ff;--code:#333;--active:#555;--accent:#343434;--accent2:#555;--nav-hover:rgba(0, 0, 0, 0.1);--name:#77C1FF;--def:#0cdd0c;--annotation:#00c037;}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#49483e}.pdoc-code{background:#272822; color:#f8f8f2}.pdoc-code .c{color:#75715e}.pdoc-code .err{color:#960050; background-color:#1e0010}.pdoc-code .esc{color:#f8f8f2}.pdoc-code .g{color:#f8f8f2}.pdoc-code .k{color:#66d9ef}.pdoc-code .l{color:#ae81ff}.pdoc-code .n{color:#f8f8f2}.pdoc-code .o{color:#f92672}.pdoc-code .x{color:#f8f8f2}.pdoc-code .p{color:#f8f8f2}.pdoc-code .ch{color:#75715e}.pdoc-code .cm{color:#75715e}.pdoc-code .cp{color:#75715e}.pdoc-code .cpf{color:#75715e}.pdoc-code .c1{color:#75715e}.pdoc-code .cs{color:#75715e}.pdoc-code .gd{color:#f92672}.pdoc-code .ge{color:#f8f8f2; font-style:italic}.pdoc-code .gr{color:#f8f8f2}.pdoc-code .gh{color:#f8f8f2}.pdoc-code .gi{color:#a6e22e}.pdoc-code .go{color:#66d9ef}.pdoc-code .gp{color:#f92672; font-weight:bold}.pdoc-code .gs{color:#f8f8f2; font-weight:bold}.pdoc-code .gu{color:#75715e}.pdoc-code .gt{color:#f8f8f2}.pdoc-code .kc{color:#66d9ef}.pdoc-code .kd{color:#66d9ef}.pdoc-code .kn{color:#f92672}.pdoc-code .kp{color:#66d9ef}.pdoc-code .kr{color:#66d9ef}.pdoc-code .kt{color:#66d9ef}.pdoc-code .ld{color:#e6db74}.pdoc-code .m{color:#ae81ff}.pdoc-code .s{color:#e6db74}.pdoc-code .na{color:#a6e22e}.pdoc-code .nb{color:#f8f8f2}.pdoc-code .nc{color:#a6e22e}.pdoc-code .no{color:#66d9ef}.pdoc-code .nd{color:#a6e22e}.pdoc-code .ni{color:#f8f8f2}.pdoc-code .ne{color:#a6e22e}.pdoc-code .nf{color:#a6e22e}.pdoc-code .nl{color:#f8f8f2}.pdoc-code .nn{color:#f8f8f2}.pdoc-code .nx{color:#a6e22e}.pdoc-code .py{color:#f8f8f2}.pdoc-code .nt{color:#f92672}.pdoc-code .nv{color:#f8f8f2}.pdoc-code .ow{color:#f92672}.pdoc-code .w{color:#f8f8f2}.pdoc-code .mb{color:#ae81ff}.pdoc-code .mf{color:#ae81ff}.pdoc-code .mh{color:#ae81ff}.pdoc-code .mi{color:#ae81ff}.pdoc-code .mo{color:#ae81ff}.pdoc-code .sa{color:#e6db74}.pdoc-code .sb{color:#e6db74}.pdoc-code .sc{color:#e6db74}.pdoc-code .dl{color:#e6db74}.pdoc-code .sd{color:#e6db74}.pdoc-code .s2{color:#e6db74}.pdoc-code .se{color:#ae81ff}.pdoc-code .sh{color:#e6db74}.pdoc-code .si{color:#e6db74}.pdoc-code .sx{color:#e6db74}.pdoc-code .sr{color:#e6db74}.pdoc-code .s1{color:#e6db74}.pdoc-code .ss{color:#e6db74}.pdoc-code .bp{color:#f8f8f2}.pdoc-code .fm{color:#a6e22e}.pdoc-code .vc{color:#f8f8f2}.pdoc-code .vg{color:#f8f8f2}.pdoc-code .vi{color:#f8f8f2}.pdoc-code .vm{color:#f8f8f2}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>

            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>            
                <ul class="memberlist">
            <li>
                    <a class="class" href="#AdaOpt">AdaOpt</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#LSBoostClassifier">LSBoostClassifier</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#StumpClassifier">StumpClassifier</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#ElasticNetRegressor">ElasticNetRegressor</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#LassoRegressor">LassoRegressor</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#LSBoostRegressor">LSBoostRegressor</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
                    <a class="class" href="#RidgeRegressor">RidgeRegressor</a>
                            <ul class="memberlist">
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                        <li>
                        </li>
                </ul>

                
            </li>
            <li>
            </li>
            <li>
            </li>
            <li>
            </li>
            <li>
            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
mlsauce    </h1>

                
                        <input id="mod-mlsauce-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-mlsauce-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="kn">import</span> <span class="nn">sys</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a><span class="kn">import</span> <span class="nn">logging</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a><span class="kn">from</span> <span class="nn">._config</span> <span class="kn">import</span> <span class="n">get_config</span><span class="p">,</span> <span class="n">set_config</span><span class="p">,</span> <span class="n">config_context</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a><span class="c1"># PEP0440 compatible formatted version, see:</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a><span class="c1"># https://www.python.org/dev/peps/pep-0440/</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">12</span></a><span class="c1">#</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">13</span></a><span class="c1"># Generic release markers:</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">14</span></a><span class="c1">#   X.Y</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos">15</span></a><span class="c1">#   X.Y.Z   # For bugfix releases</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos">16</span></a><span class="c1">#</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos">17</span></a><span class="c1"># Admissible pre-release markers:</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos">18</span></a><span class="c1">#   X.YaN   # Alpha release</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos">19</span></a><span class="c1">#   X.YbN   # Beta release</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos">20</span></a><span class="c1">#   X.YrcN  # Release Candidate</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">21</span></a><span class="c1">#   X.Y     # Final release</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">22</span></a><span class="c1">#</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos">23</span></a><span class="c1"># Dev branch marker is: &#39;X.Y.dev&#39; or &#39;X.Y.devN&#39; where N is an integer.</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos">24</span></a><span class="c1"># &#39;X.Y.dev0&#39; is the canonical version of &#39;X.Y.dev&#39;</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos">25</span></a><span class="c1">#</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos">26</span></a><span class="c1"># __version__ = &quot;0.10.0&quot;</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos">27</span></a>
</span><span id="L-28"><a href="#L-28"><span class="linenos">28</span></a>
</span><span id="L-29"><a href="#L-29"><span class="linenos">29</span></a><span class="c1"># On OSX, we can get a runtime error due to multiple OpenMP libraries loaded</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos">30</span></a><span class="c1"># simultaneously. This can happen for instance when calling BLAS inside a</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos">31</span></a><span class="c1"># prange. Setting the following environment variable allows multiple OpenMP</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos">32</span></a><span class="c1"># libraries to be loaded. It should not degrade performances since we manually</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos">33</span></a><span class="c1"># take care of potential over-subcription performance issues, in sections of</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos">34</span></a><span class="c1"># the code where nested OpenMP loops can happen, by dynamically reconfiguring</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos">35</span></a><span class="c1"># the inner OpenMP runtime to temporarily disable it while under the scope of</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos">36</span></a><span class="c1"># the outer OpenMP parallel section.</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos">37</span></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;KMP_DUPLICATE_LIB_OK&quot;</span><span class="p">,</span> <span class="s2">&quot;True&quot;</span><span class="p">)</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos">38</span></a>
</span><span id="L-39"><a href="#L-39"><span class="linenos">39</span></a><span class="c1"># Workaround issue discovered in intel-openmp 2019.5:</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos">40</span></a><span class="c1"># https://github.com/ContinuumIO/anaconda-issues/issues/11294</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos">41</span></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;KMP_INIT_AT_FORK&quot;</span><span class="p">,</span> <span class="s2">&quot;FALSE&quot;</span><span class="p">)</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos">42</span></a>
</span><span id="L-43"><a href="#L-43"><span class="linenos">43</span></a><span class="k">try</span><span class="p">:</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos">44</span></a>    <span class="c1"># This variable is injected in the __builtins__ by the build</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos">45</span></a>    <span class="c1"># process. It is used to enable importing subpackages of mlsauce when</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos">46</span></a>    <span class="c1"># the binaries are not built</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos">47</span></a>    <span class="c1"># mypy error: Cannot determine type of &#39;__MLSAUCE_SETUP__&#39;</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos">48</span></a>    <span class="n">__MLSAUCE_SETUP__</span>  <span class="c1"># type: ignore</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos">49</span></a><span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos">50</span></a>    <span class="n">__MLSAUCE_SETUP__</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos">51</span></a>
</span><span id="L-52"><a href="#L-52"><span class="linenos">52</span></a><span class="k">if</span> <span class="n">__MLSAUCE_SETUP__</span><span class="p">:</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos">53</span></a>    <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Partial import of mlsauce during the build process.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos">54</span></a>    <span class="c1"># We are not importing the rest of scikit-learn during the build</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos">55</span></a>    <span class="c1"># process, as it may not be compiled yet</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos">56</span></a>
</span><span id="L-57"><a href="#L-57"><span class="linenos">57</span></a><span class="k">else</span><span class="p">:</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos">58</span></a>    <span class="kn">from</span> <span class="nn">.adaopt</span> <span class="kn">import</span> <span class="n">AdaOpt</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos">59</span></a>    <span class="kn">from</span> <span class="nn">.booster</span> <span class="kn">import</span> <span class="n">LSBoostClassifier</span><span class="p">,</span> <span class="n">LSBoostRegressor</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos">60</span></a>    <span class="kn">from</span> <span class="nn">.datasets</span> <span class="kn">import</span> <span class="n">download</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos">61</span></a>    <span class="kn">from</span> <span class="nn">.elasticnet</span> <span class="kn">import</span> <span class="n">ElasticNetRegressor</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos">62</span></a>    <span class="kn">from</span> <span class="nn">.lasso</span> <span class="kn">import</span> <span class="n">LassoRegressor</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos">63</span></a>    <span class="kn">from</span> <span class="nn">.ridge</span> <span class="kn">import</span> <span class="n">RidgeRegressor</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos">64</span></a>    <span class="kn">from</span> <span class="nn">.stump</span> <span class="kn">import</span> <span class="n">StumpClassifier</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos">65</span></a>
</span><span id="L-66"><a href="#L-66"><span class="linenos">66</span></a>    <span class="c1"># from .encoders import corrtarget_encoder</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos">67</span></a>
</span><span id="L-68"><a href="#L-68"><span class="linenos">68</span></a>    <span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos">69</span></a>        <span class="s2">&quot;AdaOpt&quot;</span><span class="p">,</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos">70</span></a>        <span class="s2">&quot;LSBoostClassifier&quot;</span><span class="p">,</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos">71</span></a>        <span class="s2">&quot;StumpClassifier&quot;</span><span class="p">,</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos">72</span></a>        <span class="s2">&quot;ElasticNetRegressor&quot;</span><span class="p">,</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos">73</span></a>        <span class="s2">&quot;LassoRegressor&quot;</span><span class="p">,</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos">74</span></a>        <span class="s2">&quot;LSBoostRegressor&quot;</span><span class="p">,</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos">75</span></a>        <span class="s2">&quot;RidgeRegressor&quot;</span><span class="p">,</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos">76</span></a>        <span class="c1"># Other imports</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos">77</span></a>        <span class="c1"># &quot;corrtarget_encoder&quot;,</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos">78</span></a>        <span class="s2">&quot;download&quot;</span><span class="p">,</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos">79</span></a>        <span class="c1"># Non-modules:</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos">80</span></a>        <span class="s2">&quot;get_config&quot;</span><span class="p">,</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos">81</span></a>        <span class="s2">&quot;set_config&quot;</span><span class="p">,</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos">82</span></a>        <span class="s2">&quot;config_context&quot;</span><span class="p">,</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos">83</span></a>    <span class="p">]</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos">84</span></a>
</span><span id="L-85"><a href="#L-85"><span class="linenos">85</span></a>
</span><span id="L-86"><a href="#L-86"><span class="linenos">86</span></a><span class="k">def</span> <span class="nf">setup_module</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos">87</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Fixture for the tests to assure globally controllable seeding of RNGs&quot;&quot;&quot;</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos">88</span></a>    <span class="kn">import</span> <span class="nn">os</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos">89</span></a>    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos">90</span></a>    <span class="kn">import</span> <span class="nn">random</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos">91</span></a>
</span><span id="L-92"><a href="#L-92"><span class="linenos">92</span></a>    <span class="c1"># Check if a random seed exists in the environment, if not create one.</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos">93</span></a>    <span class="n">_random_seed</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;MLSAUCE_SEED&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos">94</span></a>    <span class="k">if</span> <span class="n">_random_seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos">95</span></a>        <span class="n">_random_seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos">96</span></a>    <span class="n">_random_seed</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">_random_seed</span><span class="p">)</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos">97</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;I: Seeding RNGs with </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">_random_seed</span><span class="p">)</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos">98</span></a>    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">_random_seed</span><span class="p">)</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos">99</span></a>    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">_random_seed</span><span class="p">)</span>
</span></pre></div>


            </section>
                <section id="AdaOpt">
                            <input id="AdaOpt-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">AdaOpt</span><wbr>(<span class="base">sklearn.base.BaseEstimator</span>, <span class="base">sklearn.base.ClassifierMixin</span>):

                <label class="view-source-button" for="AdaOpt-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AdaOpt"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AdaOpt-19"><a href="#AdaOpt-19"><span class="linenos"> 19</span></a><span class="k">class</span> <span class="nc">AdaOpt</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
</span><span id="AdaOpt-20"><a href="#AdaOpt-20"><span class="linenos"> 20</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;AdaOpt classifier.</span>
</span><span id="AdaOpt-21"><a href="#AdaOpt-21"><span class="linenos"> 21</span></a>
</span><span id="AdaOpt-22"><a href="#AdaOpt-22"><span class="linenos"> 22</span></a><span class="sd">    Attributes:</span>
</span><span id="AdaOpt-23"><a href="#AdaOpt-23"><span class="linenos"> 23</span></a>
</span><span id="AdaOpt-24"><a href="#AdaOpt-24"><span class="linenos"> 24</span></a><span class="sd">        n_iterations: int</span>
</span><span id="AdaOpt-25"><a href="#AdaOpt-25"><span class="linenos"> 25</span></a><span class="sd">            number of iterations of the optimizer at training time.</span>
</span><span id="AdaOpt-26"><a href="#AdaOpt-26"><span class="linenos"> 26</span></a>
</span><span id="AdaOpt-27"><a href="#AdaOpt-27"><span class="linenos"> 27</span></a><span class="sd">        learning_rate: float</span>
</span><span id="AdaOpt-28"><a href="#AdaOpt-28"><span class="linenos"> 28</span></a><span class="sd">            controls the speed of the optimizer at training time.</span>
</span><span id="AdaOpt-29"><a href="#AdaOpt-29"><span class="linenos"> 29</span></a>
</span><span id="AdaOpt-30"><a href="#AdaOpt-30"><span class="linenos"> 30</span></a><span class="sd">        reg_lambda: float</span>
</span><span id="AdaOpt-31"><a href="#AdaOpt-31"><span class="linenos"> 31</span></a><span class="sd">            L2 regularization parameter for successive errors in the optimizer</span>
</span><span id="AdaOpt-32"><a href="#AdaOpt-32"><span class="linenos"> 32</span></a><span class="sd">            (at training time).</span>
</span><span id="AdaOpt-33"><a href="#AdaOpt-33"><span class="linenos"> 33</span></a>
</span><span id="AdaOpt-34"><a href="#AdaOpt-34"><span class="linenos"> 34</span></a><span class="sd">        reg_alpha: float</span>
</span><span id="AdaOpt-35"><a href="#AdaOpt-35"><span class="linenos"> 35</span></a><span class="sd">            L1 regularization parameter for successive errors in the optimizer</span>
</span><span id="AdaOpt-36"><a href="#AdaOpt-36"><span class="linenos"> 36</span></a><span class="sd">            (at training time).</span>
</span><span id="AdaOpt-37"><a href="#AdaOpt-37"><span class="linenos"> 37</span></a>
</span><span id="AdaOpt-38"><a href="#AdaOpt-38"><span class="linenos"> 38</span></a><span class="sd">        eta: float</span>
</span><span id="AdaOpt-39"><a href="#AdaOpt-39"><span class="linenos"> 39</span></a><span class="sd">            controls the slope in gradient descent (at training time).</span>
</span><span id="AdaOpt-40"><a href="#AdaOpt-40"><span class="linenos"> 40</span></a>
</span><span id="AdaOpt-41"><a href="#AdaOpt-41"><span class="linenos"> 41</span></a><span class="sd">        gamma: float</span>
</span><span id="AdaOpt-42"><a href="#AdaOpt-42"><span class="linenos"> 42</span></a><span class="sd">            controls the step size in gradient descent (at training time).</span>
</span><span id="AdaOpt-43"><a href="#AdaOpt-43"><span class="linenos"> 43</span></a>
</span><span id="AdaOpt-44"><a href="#AdaOpt-44"><span class="linenos"> 44</span></a><span class="sd">        k: int</span>
</span><span id="AdaOpt-45"><a href="#AdaOpt-45"><span class="linenos"> 45</span></a><span class="sd">            number of nearest neighbors selected at test time for classification.</span>
</span><span id="AdaOpt-46"><a href="#AdaOpt-46"><span class="linenos"> 46</span></a>
</span><span id="AdaOpt-47"><a href="#AdaOpt-47"><span class="linenos"> 47</span></a><span class="sd">        tolerance: float</span>
</span><span id="AdaOpt-48"><a href="#AdaOpt-48"><span class="linenos"> 48</span></a><span class="sd">            controls early stopping in gradient descent (at training time).</span>
</span><span id="AdaOpt-49"><a href="#AdaOpt-49"><span class="linenos"> 49</span></a>
</span><span id="AdaOpt-50"><a href="#AdaOpt-50"><span class="linenos"> 50</span></a><span class="sd">        n_clusters: int</span>
</span><span id="AdaOpt-51"><a href="#AdaOpt-51"><span class="linenos"> 51</span></a><span class="sd">            number of clusters, if MiniBatch k-means is used at test time</span>
</span><span id="AdaOpt-52"><a href="#AdaOpt-52"><span class="linenos"> 52</span></a><span class="sd">            (for faster prediction).</span>
</span><span id="AdaOpt-53"><a href="#AdaOpt-53"><span class="linenos"> 53</span></a>
</span><span id="AdaOpt-54"><a href="#AdaOpt-54"><span class="linenos"> 54</span></a><span class="sd">        batch_size: int</span>
</span><span id="AdaOpt-55"><a href="#AdaOpt-55"><span class="linenos"> 55</span></a><span class="sd">            size of the batch, if MiniBatch k-means is used at test time</span>
</span><span id="AdaOpt-56"><a href="#AdaOpt-56"><span class="linenos"> 56</span></a><span class="sd">            (for faster prediction).</span>
</span><span id="AdaOpt-57"><a href="#AdaOpt-57"><span class="linenos"> 57</span></a>
</span><span id="AdaOpt-58"><a href="#AdaOpt-58"><span class="linenos"> 58</span></a><span class="sd">        row_sample: float</span>
</span><span id="AdaOpt-59"><a href="#AdaOpt-59"><span class="linenos"> 59</span></a><span class="sd">            percentage of rows chosen from training set (by stratified subsampling,</span>
</span><span id="AdaOpt-60"><a href="#AdaOpt-60"><span class="linenos"> 60</span></a><span class="sd">            for faster prediction).</span>
</span><span id="AdaOpt-61"><a href="#AdaOpt-61"><span class="linenos"> 61</span></a>
</span><span id="AdaOpt-62"><a href="#AdaOpt-62"><span class="linenos"> 62</span></a><span class="sd">        type_dist: str</span>
</span><span id="AdaOpt-63"><a href="#AdaOpt-63"><span class="linenos"> 63</span></a><span class="sd">            distance used for finding the nearest neighbors; currently `euclidean-f`</span>
</span><span id="AdaOpt-64"><a href="#AdaOpt-64"><span class="linenos"> 64</span></a><span class="sd">            (euclidean distances calculated as whole), `euclidean` (euclidean distances</span>
</span><span id="AdaOpt-65"><a href="#AdaOpt-65"><span class="linenos"> 65</span></a><span class="sd">            calculated row by row), `cosine` (cosine distance).</span>
</span><span id="AdaOpt-66"><a href="#AdaOpt-66"><span class="linenos"> 66</span></a>
</span><span id="AdaOpt-67"><a href="#AdaOpt-67"><span class="linenos"> 67</span></a><span class="sd">        n_jobs: int</span>
</span><span id="AdaOpt-68"><a href="#AdaOpt-68"><span class="linenos"> 68</span></a><span class="sd">            number of cpus for parallel processing (default: None)</span>
</span><span id="AdaOpt-69"><a href="#AdaOpt-69"><span class="linenos"> 69</span></a>
</span><span id="AdaOpt-70"><a href="#AdaOpt-70"><span class="linenos"> 70</span></a><span class="sd">        verbose: int</span>
</span><span id="AdaOpt-71"><a href="#AdaOpt-71"><span class="linenos"> 71</span></a><span class="sd">            progress bar for parallel processing (yes = 1) or not (no = 0)</span>
</span><span id="AdaOpt-72"><a href="#AdaOpt-72"><span class="linenos"> 72</span></a>
</span><span id="AdaOpt-73"><a href="#AdaOpt-73"><span class="linenos"> 73</span></a><span class="sd">        cache: boolean</span>
</span><span id="AdaOpt-74"><a href="#AdaOpt-74"><span class="linenos"> 74</span></a><span class="sd">            if the nearest neighbors are cached or not, for faster retrieval in</span>
</span><span id="AdaOpt-75"><a href="#AdaOpt-75"><span class="linenos"> 75</span></a><span class="sd">            subsequent calls.</span>
</span><span id="AdaOpt-76"><a href="#AdaOpt-76"><span class="linenos"> 76</span></a>
</span><span id="AdaOpt-77"><a href="#AdaOpt-77"><span class="linenos"> 77</span></a><span class="sd">        n_clusters_input: int</span>
</span><span id="AdaOpt-78"><a href="#AdaOpt-78"><span class="linenos"> 78</span></a><span class="sd">            number of clusters (a priori) for clustering the features</span>
</span><span id="AdaOpt-79"><a href="#AdaOpt-79"><span class="linenos"> 79</span></a>
</span><span id="AdaOpt-80"><a href="#AdaOpt-80"><span class="linenos"> 80</span></a><span class="sd">        clustering_method: str</span>
</span><span id="AdaOpt-81"><a href="#AdaOpt-81"><span class="linenos"> 81</span></a><span class="sd">            clustering method: currently &#39;kmeans&#39;, &#39;gmm&#39;</span>
</span><span id="AdaOpt-82"><a href="#AdaOpt-82"><span class="linenos"> 82</span></a>
</span><span id="AdaOpt-83"><a href="#AdaOpt-83"><span class="linenos"> 83</span></a><span class="sd">        cluster_scaling: str</span>
</span><span id="AdaOpt-84"><a href="#AdaOpt-84"><span class="linenos"> 84</span></a><span class="sd">            scaling method for clustering: currently &#39;standard&#39;, &#39;robust&#39;, &#39;minmax&#39;</span>
</span><span id="AdaOpt-85"><a href="#AdaOpt-85"><span class="linenos"> 85</span></a>
</span><span id="AdaOpt-86"><a href="#AdaOpt-86"><span class="linenos"> 86</span></a><span class="sd">        seed: int</span>
</span><span id="AdaOpt-87"><a href="#AdaOpt-87"><span class="linenos"> 87</span></a><span class="sd">            reproducibility seed for nodes_sim==&#39;uniform&#39;, clustering and dropout.</span>
</span><span id="AdaOpt-88"><a href="#AdaOpt-88"><span class="linenos"> 88</span></a>
</span><span id="AdaOpt-89"><a href="#AdaOpt-89"><span class="linenos"> 89</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="AdaOpt-90"><a href="#AdaOpt-90"><span class="linenos"> 90</span></a>
</span><span id="AdaOpt-91"><a href="#AdaOpt-91"><span class="linenos"> 91</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="AdaOpt-92"><a href="#AdaOpt-92"><span class="linenos"> 92</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AdaOpt-93"><a href="#AdaOpt-93"><span class="linenos"> 93</span></a>        <span class="n">n_iterations</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
</span><span id="AdaOpt-94"><a href="#AdaOpt-94"><span class="linenos"> 94</span></a>        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
</span><span id="AdaOpt-95"><a href="#AdaOpt-95"><span class="linenos"> 95</span></a>        <span class="n">reg_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="AdaOpt-96"><a href="#AdaOpt-96"><span class="linenos"> 96</span></a>        <span class="n">reg_alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
</span><span id="AdaOpt-97"><a href="#AdaOpt-97"><span class="linenos"> 97</span></a>        <span class="n">eta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
</span><span id="AdaOpt-98"><a href="#AdaOpt-98"><span class="linenos"> 98</span></a>        <span class="n">gamma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
</span><span id="AdaOpt-99"><a href="#AdaOpt-99"><span class="linenos"> 99</span></a>        <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span><span id="AdaOpt-100"><a href="#AdaOpt-100"><span class="linenos">100</span></a>        <span class="n">tolerance</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="AdaOpt-101"><a href="#AdaOpt-101"><span class="linenos">101</span></a>        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="AdaOpt-102"><a href="#AdaOpt-102"><span class="linenos">102</span></a>        <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="AdaOpt-103"><a href="#AdaOpt-103"><span class="linenos">103</span></a>        <span class="n">row_sample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
</span><span id="AdaOpt-104"><a href="#AdaOpt-104"><span class="linenos">104</span></a>        <span class="n">type_dist</span><span class="o">=</span><span class="s2">&quot;euclidean-f&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-105"><a href="#AdaOpt-105"><span class="linenos">105</span></a>        <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="AdaOpt-106"><a href="#AdaOpt-106"><span class="linenos">106</span></a>        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="AdaOpt-107"><a href="#AdaOpt-107"><span class="linenos">107</span></a>        <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="AdaOpt-108"><a href="#AdaOpt-108"><span class="linenos">108</span></a>        <span class="n">n_clusters_input</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="AdaOpt-109"><a href="#AdaOpt-109"><span class="linenos">109</span></a>        <span class="n">clustering_method</span><span class="o">=</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-110"><a href="#AdaOpt-110"><span class="linenos">110</span></a>        <span class="n">cluster_scaling</span><span class="o">=</span><span class="s2">&quot;standard&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-111"><a href="#AdaOpt-111"><span class="linenos">111</span></a>        <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
</span><span id="AdaOpt-112"><a href="#AdaOpt-112"><span class="linenos">112</span></a>    <span class="p">):</span>
</span><span id="AdaOpt-113"><a href="#AdaOpt-113"><span class="linenos">113</span></a>        <span class="k">if</span> <span class="n">n_clusters_input</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="AdaOpt-114"><a href="#AdaOpt-114"><span class="linenos">114</span></a>            <span class="k">assert</span> <span class="n">clustering_method</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="AdaOpt-115"><a href="#AdaOpt-115"><span class="linenos">115</span></a>                <span class="s2">&quot;kmeans&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-116"><a href="#AdaOpt-116"><span class="linenos">116</span></a>                <span class="s2">&quot;gmm&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-117"><a href="#AdaOpt-117"><span class="linenos">117</span></a>            <span class="p">),</span> <span class="s2">&quot;`clustering_method` must be in (&#39;kmeans&#39;, &#39;gmm&#39;)&quot;</span>
</span><span id="AdaOpt-118"><a href="#AdaOpt-118"><span class="linenos">118</span></a>            <span class="k">assert</span> <span class="n">cluster_scaling</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="AdaOpt-119"><a href="#AdaOpt-119"><span class="linenos">119</span></a>                <span class="s2">&quot;standard&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-120"><a href="#AdaOpt-120"><span class="linenos">120</span></a>                <span class="s2">&quot;robust&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-121"><a href="#AdaOpt-121"><span class="linenos">121</span></a>                <span class="s2">&quot;minmax&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-122"><a href="#AdaOpt-122"><span class="linenos">122</span></a>            <span class="p">),</span> <span class="s2">&quot;`cluster_scaling` must be in (&#39;standard&#39;, &#39;robust&#39;, &#39;minmax&#39;)&quot;</span>
</span><span id="AdaOpt-123"><a href="#AdaOpt-123"><span class="linenos">123</span></a>
</span><span id="AdaOpt-124"><a href="#AdaOpt-124"><span class="linenos">124</span></a>        <span class="k">assert</span> <span class="n">type_dist</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="AdaOpt-125"><a href="#AdaOpt-125"><span class="linenos">125</span></a>            <span class="s2">&quot;euclidean&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-126"><a href="#AdaOpt-126"><span class="linenos">126</span></a>            <span class="s2">&quot;manhattan&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-127"><a href="#AdaOpt-127"><span class="linenos">127</span></a>            <span class="s2">&quot;euclidean-f&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-128"><a href="#AdaOpt-128"><span class="linenos">128</span></a>            <span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-129"><a href="#AdaOpt-129"><span class="linenos">129</span></a>        <span class="p">),</span> <span class="s2">&quot;must have: `type_dist` in (&#39;euclidean&#39;, &#39;manhattan&#39;, &#39;euclidean-f&#39;, &#39;cosine&#39;) &quot;</span>
</span><span id="AdaOpt-130"><a href="#AdaOpt-130"><span class="linenos">130</span></a>
</span><span id="AdaOpt-131"><a href="#AdaOpt-131"><span class="linenos">131</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iterations</span> <span class="o">=</span> <span class="n">n_iterations</span>
</span><span id="AdaOpt-132"><a href="#AdaOpt-132"><span class="linenos">132</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="AdaOpt-133"><a href="#AdaOpt-133"><span class="linenos">133</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">reg_lambda</span>
</span><span id="AdaOpt-134"><a href="#AdaOpt-134"><span class="linenos">134</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reg_alpha</span> <span class="o">=</span> <span class="n">reg_alpha</span>
</span><span id="AdaOpt-135"><a href="#AdaOpt-135"><span class="linenos">135</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
</span><span id="AdaOpt-136"><a href="#AdaOpt-136"><span class="linenos">136</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
</span><span id="AdaOpt-137"><a href="#AdaOpt-137"><span class="linenos">137</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
</span><span id="AdaOpt-138"><a href="#AdaOpt-138"><span class="linenos">138</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="n">tolerance</span>
</span><span id="AdaOpt-139"><a href="#AdaOpt-139"><span class="linenos">139</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
</span><span id="AdaOpt-140"><a href="#AdaOpt-140"><span class="linenos">140</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</span><span id="AdaOpt-141"><a href="#AdaOpt-141"><span class="linenos">141</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span> <span class="o">=</span> <span class="n">row_sample</span>
</span><span id="AdaOpt-142"><a href="#AdaOpt-142"><span class="linenos">142</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="o">=</span> <span class="n">type_dist</span>
</span><span id="AdaOpt-143"><a href="#AdaOpt-143"><span class="linenos">143</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
</span><span id="AdaOpt-144"><a href="#AdaOpt-144"><span class="linenos">144</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="n">cache</span>
</span><span id="AdaOpt-145"><a href="#AdaOpt-145"><span class="linenos">145</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
</span><span id="AdaOpt-146"><a href="#AdaOpt-146"><span class="linenos">146</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters_input</span> <span class="o">=</span> <span class="n">n_clusters_input</span>
</span><span id="AdaOpt-147"><a href="#AdaOpt-147"><span class="linenos">147</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span> <span class="o">=</span> <span class="n">clustering_method</span>
</span><span id="AdaOpt-148"><a href="#AdaOpt-148"><span class="linenos">148</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span> <span class="o">=</span> <span class="n">cluster_scaling</span>
</span><span id="AdaOpt-149"><a href="#AdaOpt-149"><span class="linenos">149</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="AdaOpt-150"><a href="#AdaOpt-150"><span class="linenos">150</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
</span><span id="AdaOpt-151"><a href="#AdaOpt-151"><span class="linenos">151</span></a>
</span><span id="AdaOpt-152"><a href="#AdaOpt-152"><span class="linenos">152</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="AdaOpt-153"><a href="#AdaOpt-153"><span class="linenos">153</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit AdaOpt to training data (X, y)</span>
</span><span id="AdaOpt-154"><a href="#AdaOpt-154"><span class="linenos">154</span></a>
</span><span id="AdaOpt-155"><a href="#AdaOpt-155"><span class="linenos">155</span></a><span class="sd">        Args:</span>
</span><span id="AdaOpt-156"><a href="#AdaOpt-156"><span class="linenos">156</span></a>
</span><span id="AdaOpt-157"><a href="#AdaOpt-157"><span class="linenos">157</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="AdaOpt-158"><a href="#AdaOpt-158"><span class="linenos">158</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="AdaOpt-159"><a href="#AdaOpt-159"><span class="linenos">159</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="AdaOpt-160"><a href="#AdaOpt-160"><span class="linenos">160</span></a>
</span><span id="AdaOpt-161"><a href="#AdaOpt-161"><span class="linenos">161</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="AdaOpt-162"><a href="#AdaOpt-162"><span class="linenos">162</span></a><span class="sd">                Target values.</span>
</span><span id="AdaOpt-163"><a href="#AdaOpt-163"><span class="linenos">163</span></a>
</span><span id="AdaOpt-164"><a href="#AdaOpt-164"><span class="linenos">164</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="AdaOpt-165"><a href="#AdaOpt-165"><span class="linenos">165</span></a>
</span><span id="AdaOpt-166"><a href="#AdaOpt-166"><span class="linenos">166</span></a><span class="sd">        Returns:</span>
</span><span id="AdaOpt-167"><a href="#AdaOpt-167"><span class="linenos">167</span></a>
</span><span id="AdaOpt-168"><a href="#AdaOpt-168"><span class="linenos">168</span></a><span class="sd">            self: object.</span>
</span><span id="AdaOpt-169"><a href="#AdaOpt-169"><span class="linenos">169</span></a>
</span><span id="AdaOpt-170"><a href="#AdaOpt-170"><span class="linenos">170</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AdaOpt-171"><a href="#AdaOpt-171"><span class="linenos">171</span></a>
</span><span id="AdaOpt-172"><a href="#AdaOpt-172"><span class="linenos">172</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters_input</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="AdaOpt-173"><a href="#AdaOpt-173"><span class="linenos">173</span></a>            <span class="n">clustered_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="AdaOpt-174"><a href="#AdaOpt-174"><span class="linenos">174</span></a>                <span class="n">cluster</span><span class="p">(</span>
</span><span id="AdaOpt-175"><a href="#AdaOpt-175"><span class="linenos">175</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="AdaOpt-176"><a href="#AdaOpt-176"><span class="linenos">176</span></a>                    <span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters_input</span><span class="p">,</span>
</span><span id="AdaOpt-177"><a href="#AdaOpt-177"><span class="linenos">177</span></a>                    <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span><span class="p">,</span>
</span><span id="AdaOpt-178"><a href="#AdaOpt-178"><span class="linenos">178</span></a>                    <span class="n">type_scaling</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span><span class="p">,</span>
</span><span id="AdaOpt-179"><a href="#AdaOpt-179"><span class="linenos">179</span></a>                    <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="AdaOpt-180"><a href="#AdaOpt-180"><span class="linenos">180</span></a>                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="AdaOpt-181"><a href="#AdaOpt-181"><span class="linenos">181</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-182"><a href="#AdaOpt-182"><span class="linenos">182</span></a>            <span class="p">)</span>
</span><span id="AdaOpt-183"><a href="#AdaOpt-183"><span class="linenos">183</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">clustered_X</span><span class="p">))</span>
</span><span id="AdaOpt-184"><a href="#AdaOpt-184"><span class="linenos">184</span></a>
</span><span id="AdaOpt-185"><a href="#AdaOpt-185"><span class="linenos">185</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="AdaOpt-186"><a href="#AdaOpt-186"><span class="linenos">186</span></a>            <span class="n">index_subsample</span> <span class="o">=</span> <span class="n">subsample</span><span class="p">(</span>
</span><span id="AdaOpt-187"><a href="#AdaOpt-187"><span class="linenos">187</span></a>                <span class="n">y</span><span class="p">,</span> <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span>
</span><span id="AdaOpt-188"><a href="#AdaOpt-188"><span class="linenos">188</span></a>            <span class="p">)</span>
</span><span id="AdaOpt-189"><a href="#AdaOpt-189"><span class="linenos">189</span></a>            <span class="n">y_</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">index_subsample</span><span class="p">]</span>
</span><span id="AdaOpt-190"><a href="#AdaOpt-190"><span class="linenos">190</span></a>            <span class="n">X_</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">index_subsample</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="AdaOpt-191"><a href="#AdaOpt-191"><span class="linenos">191</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AdaOpt-192"><a href="#AdaOpt-192"><span class="linenos">192</span></a>            <span class="n">y_</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="AdaOpt-193"><a href="#AdaOpt-193"><span class="linenos">193</span></a>            <span class="n">X_</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="AdaOpt-194"><a href="#AdaOpt-194"><span class="linenos">194</span></a>
</span><span id="AdaOpt-195"><a href="#AdaOpt-195"><span class="linenos">195</span></a>        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_</span><span class="o">.</span><span class="n">shape</span>
</span><span id="AdaOpt-196"><a href="#AdaOpt-196"><span class="linenos">196</span></a>
</span><span id="AdaOpt-197"><a href="#AdaOpt-197"><span class="linenos">197</span></a>        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_</span><span class="p">))</span>
</span><span id="AdaOpt-198"><a href="#AdaOpt-198"><span class="linenos">198</span></a>
</span><span id="AdaOpt-199"><a href="#AdaOpt-199"><span class="linenos">199</span></a>        <span class="k">assert</span> <span class="n">n</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_</span><span class="p">),</span> <span class="s2">&quot;must have X.shape[0] == len(y)&quot;</span>
</span><span id="AdaOpt-200"><a href="#AdaOpt-200"><span class="linenos">200</span></a>
</span><span id="AdaOpt-201"><a href="#AdaOpt-201"><span class="linenos">201</span></a>        <span class="n">res</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">fit_adaopt</span><span class="p">(</span>
</span><span id="AdaOpt-202"><a href="#AdaOpt-202"><span class="linenos">202</span></a>            <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X_</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
</span><span id="AdaOpt-203"><a href="#AdaOpt-203"><span class="linenos">203</span></a>            <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
</span><span id="AdaOpt-204"><a href="#AdaOpt-204"><span class="linenos">204</span></a>            <span class="n">n_iterations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iterations</span><span class="p">,</span>
</span><span id="AdaOpt-205"><a href="#AdaOpt-205"><span class="linenos">205</span></a>            <span class="n">n_X</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
</span><span id="AdaOpt-206"><a href="#AdaOpt-206"><span class="linenos">206</span></a>            <span class="n">p_X</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
</span><span id="AdaOpt-207"><a href="#AdaOpt-207"><span class="linenos">207</span></a>            <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
</span><span id="AdaOpt-208"><a href="#AdaOpt-208"><span class="linenos">208</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="AdaOpt-209"><a href="#AdaOpt-209"><span class="linenos">209</span></a>            <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="AdaOpt-210"><a href="#AdaOpt-210"><span class="linenos">210</span></a>            <span class="n">reg_alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_alpha</span><span class="p">,</span>
</span><span id="AdaOpt-211"><a href="#AdaOpt-211"><span class="linenos">211</span></a>            <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">,</span>
</span><span id="AdaOpt-212"><a href="#AdaOpt-212"><span class="linenos">212</span></a>            <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
</span><span id="AdaOpt-213"><a href="#AdaOpt-213"><span class="linenos">213</span></a>            <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="AdaOpt-214"><a href="#AdaOpt-214"><span class="linenos">214</span></a>        <span class="p">)</span>
</span><span id="AdaOpt-215"><a href="#AdaOpt-215"><span class="linenos">215</span></a>
</span><span id="AdaOpt-216"><a href="#AdaOpt-216"><span class="linenos">216</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;probs&quot;</span><span class="p">]</span>
</span><span id="AdaOpt-217"><a href="#AdaOpt-217"><span class="linenos">217</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">training_accuracy</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;training_accuracy&quot;</span><span class="p">]</span>
</span><span id="AdaOpt-218"><a href="#AdaOpt-218"><span class="linenos">218</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;alphas&quot;</span><span class="p">]</span>
</span><span id="AdaOpt-219"><a href="#AdaOpt-219"><span class="linenos">219</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iterations</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;n_iterations&quot;</span><span class="p">]</span>
</span><span id="AdaOpt-220"><a href="#AdaOpt-220"><span class="linenos">220</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">&quot;scaled_X_train&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="AdaOpt-221"><a href="#AdaOpt-221"><span class="linenos">221</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c1"># for compatibility with sklearn</span>
</span><span id="AdaOpt-222"><a href="#AdaOpt-222"><span class="linenos">222</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="AdaOpt-223"><a href="#AdaOpt-223"><span class="linenos">223</span></a>
</span><span id="AdaOpt-224"><a href="#AdaOpt-224"><span class="linenos">224</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="AdaOpt-225"><a href="#AdaOpt-225"><span class="linenos">225</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="AdaOpt-226"><a href="#AdaOpt-226"><span class="linenos">226</span></a>
</span><span id="AdaOpt-227"><a href="#AdaOpt-227"><span class="linenos">227</span></a><span class="sd">        Args:</span>
</span><span id="AdaOpt-228"><a href="#AdaOpt-228"><span class="linenos">228</span></a>
</span><span id="AdaOpt-229"><a href="#AdaOpt-229"><span class="linenos">229</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="AdaOpt-230"><a href="#AdaOpt-230"><span class="linenos">230</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="AdaOpt-231"><a href="#AdaOpt-231"><span class="linenos">231</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="AdaOpt-232"><a href="#AdaOpt-232"><span class="linenos">232</span></a>
</span><span id="AdaOpt-233"><a href="#AdaOpt-233"><span class="linenos">233</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="AdaOpt-234"><a href="#AdaOpt-234"><span class="linenos">234</span></a>
</span><span id="AdaOpt-235"><a href="#AdaOpt-235"><span class="linenos">235</span></a><span class="sd">        Returns:</span>
</span><span id="AdaOpt-236"><a href="#AdaOpt-236"><span class="linenos">236</span></a>
</span><span id="AdaOpt-237"><a href="#AdaOpt-237"><span class="linenos">237</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="AdaOpt-238"><a href="#AdaOpt-238"><span class="linenos">238</span></a>
</span><span id="AdaOpt-239"><a href="#AdaOpt-239"><span class="linenos">239</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AdaOpt-240"><a href="#AdaOpt-240"><span class="linenos">240</span></a>
</span><span id="AdaOpt-241"><a href="#AdaOpt-241"><span class="linenos">241</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="AdaOpt-242"><a href="#AdaOpt-242"><span class="linenos">242</span></a>
</span><span id="AdaOpt-243"><a href="#AdaOpt-243"><span class="linenos">243</span></a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="AdaOpt-244"><a href="#AdaOpt-244"><span class="linenos">244</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict probabilities for test data X.</span>
</span><span id="AdaOpt-245"><a href="#AdaOpt-245"><span class="linenos">245</span></a>
</span><span id="AdaOpt-246"><a href="#AdaOpt-246"><span class="linenos">246</span></a><span class="sd">        Args:</span>
</span><span id="AdaOpt-247"><a href="#AdaOpt-247"><span class="linenos">247</span></a>
</span><span id="AdaOpt-248"><a href="#AdaOpt-248"><span class="linenos">248</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="AdaOpt-249"><a href="#AdaOpt-249"><span class="linenos">249</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="AdaOpt-250"><a href="#AdaOpt-250"><span class="linenos">250</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="AdaOpt-251"><a href="#AdaOpt-251"><span class="linenos">251</span></a>
</span><span id="AdaOpt-252"><a href="#AdaOpt-252"><span class="linenos">252</span></a><span class="sd">            **kwargs: additional parameters to be passed to</span>
</span><span id="AdaOpt-253"><a href="#AdaOpt-253"><span class="linenos">253</span></a><span class="sd">                self.cook_test_set</span>
</span><span id="AdaOpt-254"><a href="#AdaOpt-254"><span class="linenos">254</span></a>
</span><span id="AdaOpt-255"><a href="#AdaOpt-255"><span class="linenos">255</span></a><span class="sd">        Returns:</span>
</span><span id="AdaOpt-256"><a href="#AdaOpt-256"><span class="linenos">256</span></a>
</span><span id="AdaOpt-257"><a href="#AdaOpt-257"><span class="linenos">257</span></a><span class="sd">            probability estimates for test data: {array-like}</span>
</span><span id="AdaOpt-258"><a href="#AdaOpt-258"><span class="linenos">258</span></a>
</span><span id="AdaOpt-259"><a href="#AdaOpt-259"><span class="linenos">259</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AdaOpt-260"><a href="#AdaOpt-260"><span class="linenos">260</span></a>
</span><span id="AdaOpt-261"><a href="#AdaOpt-261"><span class="linenos">261</span></a>        <span class="n">n_train</span><span class="p">,</span> <span class="n">p_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="o">.</span><span class="n">shape</span>
</span><span id="AdaOpt-262"><a href="#AdaOpt-262"><span class="linenos">262</span></a>
</span><span id="AdaOpt-263"><a href="#AdaOpt-263"><span class="linenos">263</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters_input</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="AdaOpt-264"><a href="#AdaOpt-264"><span class="linenos">264</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="AdaOpt-265"><a href="#AdaOpt-265"><span class="linenos">265</span></a>                <span class="p">(</span>
</span><span id="AdaOpt-266"><a href="#AdaOpt-266"><span class="linenos">266</span></a>                    <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
</span><span id="AdaOpt-267"><a href="#AdaOpt-267"><span class="linenos">267</span></a>                    <span class="n">cluster</span><span class="p">(</span>
</span><span id="AdaOpt-268"><a href="#AdaOpt-268"><span class="linenos">268</span></a>                        <span class="n">X</span><span class="p">,</span>
</span><span id="AdaOpt-269"><a href="#AdaOpt-269"><span class="linenos">269</span></a>                        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="AdaOpt-270"><a href="#AdaOpt-270"><span class="linenos">270</span></a>                        <span class="n">scaler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span>
</span><span id="AdaOpt-271"><a href="#AdaOpt-271"><span class="linenos">271</span></a>                        <span class="n">label_encoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span>
</span><span id="AdaOpt-272"><a href="#AdaOpt-272"><span class="linenos">272</span></a>                        <span class="n">clusterer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span><span class="p">,</span>
</span><span id="AdaOpt-273"><a href="#AdaOpt-273"><span class="linenos">273</span></a>                        <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="AdaOpt-274"><a href="#AdaOpt-274"><span class="linenos">274</span></a>                    <span class="p">),</span>
</span><span id="AdaOpt-275"><a href="#AdaOpt-275"><span class="linenos">275</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-276"><a href="#AdaOpt-276"><span class="linenos">276</span></a>            <span class="p">)</span>
</span><span id="AdaOpt-277"><a href="#AdaOpt-277"><span class="linenos">277</span></a>
</span><span id="AdaOpt-278"><a href="#AdaOpt-278"><span class="linenos">278</span></a>        <span class="n">n_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="AdaOpt-279"><a href="#AdaOpt-279"><span class="linenos">279</span></a>
</span><span id="AdaOpt-280"><a href="#AdaOpt-280"><span class="linenos">280</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AdaOpt-281"><a href="#AdaOpt-281"><span class="linenos">281</span></a>            <span class="k">return</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">predict_proba_adaopt</span><span class="p">(</span>
</span><span id="AdaOpt-282"><a href="#AdaOpt-282"><span class="linenos">282</span></a>                <span class="n">X_test</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
</span><span id="AdaOpt-283"><a href="#AdaOpt-283"><span class="linenos">283</span></a>                <span class="n">scaled_X_train</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
</span><span id="AdaOpt-284"><a href="#AdaOpt-284"><span class="linenos">284</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
</span><span id="AdaOpt-285"><a href="#AdaOpt-285"><span class="linenos">285</span></a>                <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
</span><span id="AdaOpt-286"><a href="#AdaOpt-286"><span class="linenos">286</span></a>                <span class="n">n_test</span><span class="o">=</span><span class="n">n_test</span><span class="p">,</span>
</span><span id="AdaOpt-287"><a href="#AdaOpt-287"><span class="linenos">287</span></a>                <span class="n">n_train</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span>
</span><span id="AdaOpt-288"><a href="#AdaOpt-288"><span class="linenos">288</span></a>                <span class="n">probs_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span><span class="p">,</span>
</span><span id="AdaOpt-289"><a href="#AdaOpt-289"><span class="linenos">289</span></a>                <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span>
</span><span id="AdaOpt-290"><a href="#AdaOpt-290"><span class="linenos">290</span></a>                <span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span>
</span><span id="AdaOpt-291"><a href="#AdaOpt-291"><span class="linenos">291</span></a>                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
</span><span id="AdaOpt-292"><a href="#AdaOpt-292"><span class="linenos">292</span></a>                <span class="n">type_dist</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span><span class="p">,</span>
</span><span id="AdaOpt-293"><a href="#AdaOpt-293"><span class="linenos">293</span></a>                <span class="n">cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">,</span>
</span><span id="AdaOpt-294"><a href="#AdaOpt-294"><span class="linenos">294</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="AdaOpt-295"><a href="#AdaOpt-295"><span class="linenos">295</span></a>            <span class="p">)</span>
</span><span id="AdaOpt-296"><a href="#AdaOpt-296"><span class="linenos">296</span></a>
</span><span id="AdaOpt-297"><a href="#AdaOpt-297"><span class="linenos">297</span></a>        <span class="c1"># parallel: self.n_jobs is not None</span>
</span><span id="AdaOpt-298"><a href="#AdaOpt-298"><span class="linenos">298</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="AdaOpt-299"><a href="#AdaOpt-299"><span class="linenos">299</span></a>            <span class="s2">&quot;euclidean&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-300"><a href="#AdaOpt-300"><span class="linenos">300</span></a>            <span class="s2">&quot;manhattan&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-301"><a href="#AdaOpt-301"><span class="linenos">301</span></a>            <span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
</span><span id="AdaOpt-302"><a href="#AdaOpt-302"><span class="linenos">302</span></a>        <span class="p">),</span> <span class="s2">&quot;must have: `self.type_dist` in (&#39;euclidean&#39;, &#39;manhattan&#39;, &#39;cosine&#39;) &quot;</span>
</span><span id="AdaOpt-303"><a href="#AdaOpt-303"><span class="linenos">303</span></a>
</span><span id="AdaOpt-304"><a href="#AdaOpt-304"><span class="linenos">304</span></a>        <span class="n">scaled_X_test</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
</span><span id="AdaOpt-305"><a href="#AdaOpt-305"><span class="linenos">305</span></a>
</span><span id="AdaOpt-306"><a href="#AdaOpt-306"><span class="linenos">306</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="o">==</span> <span class="s2">&quot;euclidean&quot;</span><span class="p">:</span>
</span><span id="AdaOpt-307"><a href="#AdaOpt-307"><span class="linenos">307</span></a>
</span><span id="AdaOpt-308"><a href="#AdaOpt-308"><span class="linenos">308</span></a>            <span class="nd">@delayed</span>
</span><span id="AdaOpt-309"><a href="#AdaOpt-309"><span class="linenos">309</span></a>            <span class="nd">@wrap_non_picklable_objects</span>
</span><span id="AdaOpt-310"><a href="#AdaOpt-310"><span class="linenos">310</span></a>            <span class="k">def</span> <span class="nf">multiproc_func</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
</span><span id="AdaOpt-311"><a href="#AdaOpt-311"><span class="linenos">311</span></a>                <span class="n">dists_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">distance_to_mat_euclidean2</span><span class="p">(</span>
</span><span id="AdaOpt-312"><a href="#AdaOpt-312"><span class="linenos">312</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scaled_X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)[</span>
</span><span id="AdaOpt-313"><a href="#AdaOpt-313"><span class="linenos">313</span></a>                        <span class="n">i</span><span class="p">,</span> <span class="p">:</span>
</span><span id="AdaOpt-314"><a href="#AdaOpt-314"><span class="linenos">314</span></a>                    <span class="p">],</span>
</span><span id="AdaOpt-315"><a href="#AdaOpt-315"><span class="linenos">315</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
</span><span id="AdaOpt-316"><a href="#AdaOpt-316"><span class="linenos">316</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
</span><span id="AdaOpt-317"><a href="#AdaOpt-317"><span class="linenos">317</span></a>                    <span class="p">),</span>
</span><span id="AdaOpt-318"><a href="#AdaOpt-318"><span class="linenos">318</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span>
</span><span id="AdaOpt-319"><a href="#AdaOpt-319"><span class="linenos">319</span></a>                    <span class="n">n_train</span><span class="p">,</span>
</span><span id="AdaOpt-320"><a href="#AdaOpt-320"><span class="linenos">320</span></a>                    <span class="n">p_train</span><span class="p">,</span>
</span><span id="AdaOpt-321"><a href="#AdaOpt-321"><span class="linenos">321</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-322"><a href="#AdaOpt-322"><span class="linenos">322</span></a>
</span><span id="AdaOpt-323"><a href="#AdaOpt-323"><span class="linenos">323</span></a>                <span class="n">kmin_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">find_kmin_x</span><span class="p">(</span>
</span><span id="AdaOpt-324"><a href="#AdaOpt-324"><span class="linenos">324</span></a>                    <span class="n">dists_test_i</span><span class="p">,</span> <span class="n">n_x</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span>
</span><span id="AdaOpt-325"><a href="#AdaOpt-325"><span class="linenos">325</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-326"><a href="#AdaOpt-326"><span class="linenos">326</span></a>
</span><span id="AdaOpt-327"><a href="#AdaOpt-327"><span class="linenos">327</span></a>                <span class="n">weights_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_weights</span><span class="p">(</span><span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="AdaOpt-328"><a href="#AdaOpt-328"><span class="linenos">328</span></a>
</span><span id="AdaOpt-329"><a href="#AdaOpt-329"><span class="linenos">329</span></a>                <span class="n">probs_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_probs</span><span class="p">(</span>
</span><span id="AdaOpt-330"><a href="#AdaOpt-330"><span class="linenos">330</span></a>                    <span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span>
</span><span id="AdaOpt-331"><a href="#AdaOpt-331"><span class="linenos">331</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-332"><a href="#AdaOpt-332"><span class="linenos">332</span></a>
</span><span id="AdaOpt-333"><a href="#AdaOpt-333"><span class="linenos">333</span></a>                <span class="k">return</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">average_probs</span><span class="p">(</span>
</span><span id="AdaOpt-334"><a href="#AdaOpt-334"><span class="linenos">334</span></a>                    <span class="n">probs</span><span class="o">=</span><span class="n">probs_test_i</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights_test_i</span>
</span><span id="AdaOpt-335"><a href="#AdaOpt-335"><span class="linenos">335</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-336"><a href="#AdaOpt-336"><span class="linenos">336</span></a>
</span><span id="AdaOpt-337"><a href="#AdaOpt-337"><span class="linenos">337</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="o">==</span> <span class="s2">&quot;manhattan&quot;</span><span class="p">:</span>
</span><span id="AdaOpt-338"><a href="#AdaOpt-338"><span class="linenos">338</span></a>
</span><span id="AdaOpt-339"><a href="#AdaOpt-339"><span class="linenos">339</span></a>            <span class="nd">@delayed</span>
</span><span id="AdaOpt-340"><a href="#AdaOpt-340"><span class="linenos">340</span></a>            <span class="nd">@wrap_non_picklable_objects</span>
</span><span id="AdaOpt-341"><a href="#AdaOpt-341"><span class="linenos">341</span></a>            <span class="k">def</span> <span class="nf">multiproc_func</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
</span><span id="AdaOpt-342"><a href="#AdaOpt-342"><span class="linenos">342</span></a>                <span class="n">dists_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">distance_to_mat_manhattan2</span><span class="p">(</span>
</span><span id="AdaOpt-343"><a href="#AdaOpt-343"><span class="linenos">343</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scaled_X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)[</span>
</span><span id="AdaOpt-344"><a href="#AdaOpt-344"><span class="linenos">344</span></a>                        <span class="n">i</span><span class="p">,</span> <span class="p">:</span>
</span><span id="AdaOpt-345"><a href="#AdaOpt-345"><span class="linenos">345</span></a>                    <span class="p">],</span>
</span><span id="AdaOpt-346"><a href="#AdaOpt-346"><span class="linenos">346</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
</span><span id="AdaOpt-347"><a href="#AdaOpt-347"><span class="linenos">347</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
</span><span id="AdaOpt-348"><a href="#AdaOpt-348"><span class="linenos">348</span></a>                    <span class="p">),</span>
</span><span id="AdaOpt-349"><a href="#AdaOpt-349"><span class="linenos">349</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span>
</span><span id="AdaOpt-350"><a href="#AdaOpt-350"><span class="linenos">350</span></a>                    <span class="n">n_train</span><span class="p">,</span>
</span><span id="AdaOpt-351"><a href="#AdaOpt-351"><span class="linenos">351</span></a>                    <span class="n">p_train</span><span class="p">,</span>
</span><span id="AdaOpt-352"><a href="#AdaOpt-352"><span class="linenos">352</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-353"><a href="#AdaOpt-353"><span class="linenos">353</span></a>
</span><span id="AdaOpt-354"><a href="#AdaOpt-354"><span class="linenos">354</span></a>                <span class="n">kmin_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">find_kmin_x</span><span class="p">(</span>
</span><span id="AdaOpt-355"><a href="#AdaOpt-355"><span class="linenos">355</span></a>                    <span class="n">dists_test_i</span><span class="p">,</span> <span class="n">n_x</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span>
</span><span id="AdaOpt-356"><a href="#AdaOpt-356"><span class="linenos">356</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-357"><a href="#AdaOpt-357"><span class="linenos">357</span></a>
</span><span id="AdaOpt-358"><a href="#AdaOpt-358"><span class="linenos">358</span></a>                <span class="n">weights_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_weights</span><span class="p">(</span><span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="AdaOpt-359"><a href="#AdaOpt-359"><span class="linenos">359</span></a>
</span><span id="AdaOpt-360"><a href="#AdaOpt-360"><span class="linenos">360</span></a>                <span class="n">probs_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_probs</span><span class="p">(</span>
</span><span id="AdaOpt-361"><a href="#AdaOpt-361"><span class="linenos">361</span></a>                    <span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span>
</span><span id="AdaOpt-362"><a href="#AdaOpt-362"><span class="linenos">362</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-363"><a href="#AdaOpt-363"><span class="linenos">363</span></a>
</span><span id="AdaOpt-364"><a href="#AdaOpt-364"><span class="linenos">364</span></a>                <span class="k">return</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">average_probs</span><span class="p">(</span>
</span><span id="AdaOpt-365"><a href="#AdaOpt-365"><span class="linenos">365</span></a>                    <span class="n">probs</span><span class="o">=</span><span class="n">probs_test_i</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights_test_i</span>
</span><span id="AdaOpt-366"><a href="#AdaOpt-366"><span class="linenos">366</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-367"><a href="#AdaOpt-367"><span class="linenos">367</span></a>
</span><span id="AdaOpt-368"><a href="#AdaOpt-368"><span class="linenos">368</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
</span><span id="AdaOpt-369"><a href="#AdaOpt-369"><span class="linenos">369</span></a>
</span><span id="AdaOpt-370"><a href="#AdaOpt-370"><span class="linenos">370</span></a>            <span class="nd">@delayed</span>
</span><span id="AdaOpt-371"><a href="#AdaOpt-371"><span class="linenos">371</span></a>            <span class="nd">@wrap_non_picklable_objects</span>
</span><span id="AdaOpt-372"><a href="#AdaOpt-372"><span class="linenos">372</span></a>            <span class="k">def</span> <span class="nf">multiproc_func</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span><span id="AdaOpt-373"><a href="#AdaOpt-373"><span class="linenos">373</span></a>                <span class="n">dists_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">distance_to_mat_cosine2</span><span class="p">(</span>
</span><span id="AdaOpt-374"><a href="#AdaOpt-374"><span class="linenos">374</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scaled_X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)[</span>
</span><span id="AdaOpt-375"><a href="#AdaOpt-375"><span class="linenos">375</span></a>                        <span class="n">i</span><span class="p">,</span> <span class="p">:</span>
</span><span id="AdaOpt-376"><a href="#AdaOpt-376"><span class="linenos">376</span></a>                    <span class="p">],</span>
</span><span id="AdaOpt-377"><a href="#AdaOpt-377"><span class="linenos">377</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
</span><span id="AdaOpt-378"><a href="#AdaOpt-378"><span class="linenos">378</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
</span><span id="AdaOpt-379"><a href="#AdaOpt-379"><span class="linenos">379</span></a>                    <span class="p">),</span>
</span><span id="AdaOpt-380"><a href="#AdaOpt-380"><span class="linenos">380</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span>
</span><span id="AdaOpt-381"><a href="#AdaOpt-381"><span class="linenos">381</span></a>                    <span class="n">n_train</span><span class="p">,</span>
</span><span id="AdaOpt-382"><a href="#AdaOpt-382"><span class="linenos">382</span></a>                    <span class="n">p_train</span><span class="p">,</span>
</span><span id="AdaOpt-383"><a href="#AdaOpt-383"><span class="linenos">383</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-384"><a href="#AdaOpt-384"><span class="linenos">384</span></a>
</span><span id="AdaOpt-385"><a href="#AdaOpt-385"><span class="linenos">385</span></a>                <span class="n">kmin_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">find_kmin_x</span><span class="p">(</span>
</span><span id="AdaOpt-386"><a href="#AdaOpt-386"><span class="linenos">386</span></a>                    <span class="n">dists_test_i</span><span class="p">,</span> <span class="n">n_x</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span>
</span><span id="AdaOpt-387"><a href="#AdaOpt-387"><span class="linenos">387</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-388"><a href="#AdaOpt-388"><span class="linenos">388</span></a>
</span><span id="AdaOpt-389"><a href="#AdaOpt-389"><span class="linenos">389</span></a>                <span class="n">weights_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_weights</span><span class="p">(</span><span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="AdaOpt-390"><a href="#AdaOpt-390"><span class="linenos">390</span></a>
</span><span id="AdaOpt-391"><a href="#AdaOpt-391"><span class="linenos">391</span></a>                <span class="n">probs_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_probs</span><span class="p">(</span>
</span><span id="AdaOpt-392"><a href="#AdaOpt-392"><span class="linenos">392</span></a>                    <span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span>
</span><span id="AdaOpt-393"><a href="#AdaOpt-393"><span class="linenos">393</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-394"><a href="#AdaOpt-394"><span class="linenos">394</span></a>
</span><span id="AdaOpt-395"><a href="#AdaOpt-395"><span class="linenos">395</span></a>                <span class="k">return</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">average_probs</span><span class="p">(</span>
</span><span id="AdaOpt-396"><a href="#AdaOpt-396"><span class="linenos">396</span></a>                    <span class="n">probs</span><span class="o">=</span><span class="n">probs_test_i</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights_test_i</span>
</span><span id="AdaOpt-397"><a href="#AdaOpt-397"><span class="linenos">397</span></a>                <span class="p">)</span>
</span><span id="AdaOpt-398"><a href="#AdaOpt-398"><span class="linenos">398</span></a>
</span><span id="AdaOpt-399"><a href="#AdaOpt-399"><span class="linenos">399</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="AdaOpt-400"><a href="#AdaOpt-400"><span class="linenos">400</span></a>            <span class="n">res</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">prefer</span><span class="o">=</span><span class="s2">&quot;threads&quot;</span><span class="p">)(</span>
</span><span id="AdaOpt-401"><a href="#AdaOpt-401"><span class="linenos">401</span></a>                <span class="p">(</span><span class="n">multiproc_func</span><span class="p">)(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_test</span><span class="p">))</span>
</span><span id="AdaOpt-402"><a href="#AdaOpt-402"><span class="linenos">402</span></a>            <span class="p">)</span>
</span><span id="AdaOpt-403"><a href="#AdaOpt-403"><span class="linenos">403</span></a>
</span><span id="AdaOpt-404"><a href="#AdaOpt-404"><span class="linenos">404</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AdaOpt-405"><a href="#AdaOpt-405"><span class="linenos">405</span></a>            <span class="n">res</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">prefer</span><span class="o">=</span><span class="s2">&quot;threads&quot;</span><span class="p">)(</span>
</span><span id="AdaOpt-406"><a href="#AdaOpt-406"><span class="linenos">406</span></a>                <span class="p">(</span><span class="n">multiproc_func</span><span class="p">)(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span>
</span><span id="AdaOpt-407"><a href="#AdaOpt-407"><span class="linenos">407</span></a>            <span class="p">)</span>
</span><span id="AdaOpt-408"><a href="#AdaOpt-408"><span class="linenos">408</span></a>
</span><span id="AdaOpt-409"><a href="#AdaOpt-409"><span class="linenos">409</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>AdaOpt classifier.</p>

<p>Attributes:</p>

<pre><code>n_iterations: int
    number of iterations of the optimizer at training time.

learning_rate: float
    controls the speed of the optimizer at training time.

reg_lambda: float
    L2 regularization parameter for successive errors in the optimizer
    (at training time).

reg_alpha: float
    L1 regularization parameter for successive errors in the optimizer
    (at training time).

eta: float
    controls the slope in gradient descent (at training time).

gamma: float
    controls the step size in gradient descent (at training time).

k: int
    number of nearest neighbors selected at test time for classification.

tolerance: float
    controls early stopping in gradient descent (at training time).

n_clusters: int
    number of clusters, if MiniBatch k-means is used at test time
    (for faster prediction).

batch_size: int
    size of the batch, if MiniBatch k-means is used at test time
    (for faster prediction).

row_sample: float
    percentage of rows chosen from training set (by stratified subsampling,
    for faster prediction).

type_dist: str
    distance used for finding the nearest neighbors; currently `euclidean-f`
    (euclidean distances calculated as whole), `euclidean` (euclidean distances
    calculated row by row), `cosine` (cosine distance).

n_jobs: int
    number of cpus for parallel processing (default: None)

verbose: int
    progress bar for parallel processing (yes = 1) or not (no = 0)

cache: boolean
    if the nearest neighbors are cached or not, for faster retrieval in
    subsequent calls.

n_clusters_input: int
    number of clusters (a priori) for clustering the features

clustering_method: str
    clustering method: currently 'kmeans', 'gmm'

cluster_scaling: str
    scaling method for clustering: currently 'standard', 'robust', 'minmax'

seed: int
    reproducibility seed for nodes_sim=='uniform', clustering and dropout.
</code></pre>
</div>


                                <div id="AdaOpt.fit" class="classattr">
                                            <input id="AdaOpt.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="AdaOpt.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AdaOpt.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AdaOpt.fit-152"><a href="#AdaOpt.fit-152"><span class="linenos">152</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="AdaOpt.fit-153"><a href="#AdaOpt.fit-153"><span class="linenos">153</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit AdaOpt to training data (X, y)</span>
</span><span id="AdaOpt.fit-154"><a href="#AdaOpt.fit-154"><span class="linenos">154</span></a>
</span><span id="AdaOpt.fit-155"><a href="#AdaOpt.fit-155"><span class="linenos">155</span></a><span class="sd">        Args:</span>
</span><span id="AdaOpt.fit-156"><a href="#AdaOpt.fit-156"><span class="linenos">156</span></a>
</span><span id="AdaOpt.fit-157"><a href="#AdaOpt.fit-157"><span class="linenos">157</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="AdaOpt.fit-158"><a href="#AdaOpt.fit-158"><span class="linenos">158</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="AdaOpt.fit-159"><a href="#AdaOpt.fit-159"><span class="linenos">159</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="AdaOpt.fit-160"><a href="#AdaOpt.fit-160"><span class="linenos">160</span></a>
</span><span id="AdaOpt.fit-161"><a href="#AdaOpt.fit-161"><span class="linenos">161</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="AdaOpt.fit-162"><a href="#AdaOpt.fit-162"><span class="linenos">162</span></a><span class="sd">                Target values.</span>
</span><span id="AdaOpt.fit-163"><a href="#AdaOpt.fit-163"><span class="linenos">163</span></a>
</span><span id="AdaOpt.fit-164"><a href="#AdaOpt.fit-164"><span class="linenos">164</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="AdaOpt.fit-165"><a href="#AdaOpt.fit-165"><span class="linenos">165</span></a>
</span><span id="AdaOpt.fit-166"><a href="#AdaOpt.fit-166"><span class="linenos">166</span></a><span class="sd">        Returns:</span>
</span><span id="AdaOpt.fit-167"><a href="#AdaOpt.fit-167"><span class="linenos">167</span></a>
</span><span id="AdaOpt.fit-168"><a href="#AdaOpt.fit-168"><span class="linenos">168</span></a><span class="sd">            self: object.</span>
</span><span id="AdaOpt.fit-169"><a href="#AdaOpt.fit-169"><span class="linenos">169</span></a>
</span><span id="AdaOpt.fit-170"><a href="#AdaOpt.fit-170"><span class="linenos">170</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AdaOpt.fit-171"><a href="#AdaOpt.fit-171"><span class="linenos">171</span></a>
</span><span id="AdaOpt.fit-172"><a href="#AdaOpt.fit-172"><span class="linenos">172</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters_input</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="AdaOpt.fit-173"><a href="#AdaOpt.fit-173"><span class="linenos">173</span></a>            <span class="n">clustered_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="AdaOpt.fit-174"><a href="#AdaOpt.fit-174"><span class="linenos">174</span></a>                <span class="n">cluster</span><span class="p">(</span>
</span><span id="AdaOpt.fit-175"><a href="#AdaOpt.fit-175"><span class="linenos">175</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="AdaOpt.fit-176"><a href="#AdaOpt.fit-176"><span class="linenos">176</span></a>                    <span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters_input</span><span class="p">,</span>
</span><span id="AdaOpt.fit-177"><a href="#AdaOpt.fit-177"><span class="linenos">177</span></a>                    <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span><span class="p">,</span>
</span><span id="AdaOpt.fit-178"><a href="#AdaOpt.fit-178"><span class="linenos">178</span></a>                    <span class="n">type_scaling</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span><span class="p">,</span>
</span><span id="AdaOpt.fit-179"><a href="#AdaOpt.fit-179"><span class="linenos">179</span></a>                    <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="AdaOpt.fit-180"><a href="#AdaOpt.fit-180"><span class="linenos">180</span></a>                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="AdaOpt.fit-181"><a href="#AdaOpt.fit-181"><span class="linenos">181</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.fit-182"><a href="#AdaOpt.fit-182"><span class="linenos">182</span></a>            <span class="p">)</span>
</span><span id="AdaOpt.fit-183"><a href="#AdaOpt.fit-183"><span class="linenos">183</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">clustered_X</span><span class="p">))</span>
</span><span id="AdaOpt.fit-184"><a href="#AdaOpt.fit-184"><span class="linenos">184</span></a>
</span><span id="AdaOpt.fit-185"><a href="#AdaOpt.fit-185"><span class="linenos">185</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="AdaOpt.fit-186"><a href="#AdaOpt.fit-186"><span class="linenos">186</span></a>            <span class="n">index_subsample</span> <span class="o">=</span> <span class="n">subsample</span><span class="p">(</span>
</span><span id="AdaOpt.fit-187"><a href="#AdaOpt.fit-187"><span class="linenos">187</span></a>                <span class="n">y</span><span class="p">,</span> <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span>
</span><span id="AdaOpt.fit-188"><a href="#AdaOpt.fit-188"><span class="linenos">188</span></a>            <span class="p">)</span>
</span><span id="AdaOpt.fit-189"><a href="#AdaOpt.fit-189"><span class="linenos">189</span></a>            <span class="n">y_</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">index_subsample</span><span class="p">]</span>
</span><span id="AdaOpt.fit-190"><a href="#AdaOpt.fit-190"><span class="linenos">190</span></a>            <span class="n">X_</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">index_subsample</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="AdaOpt.fit-191"><a href="#AdaOpt.fit-191"><span class="linenos">191</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AdaOpt.fit-192"><a href="#AdaOpt.fit-192"><span class="linenos">192</span></a>            <span class="n">y_</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="AdaOpt.fit-193"><a href="#AdaOpt.fit-193"><span class="linenos">193</span></a>            <span class="n">X_</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="AdaOpt.fit-194"><a href="#AdaOpt.fit-194"><span class="linenos">194</span></a>
</span><span id="AdaOpt.fit-195"><a href="#AdaOpt.fit-195"><span class="linenos">195</span></a>        <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X_</span><span class="o">.</span><span class="n">shape</span>
</span><span id="AdaOpt.fit-196"><a href="#AdaOpt.fit-196"><span class="linenos">196</span></a>
</span><span id="AdaOpt.fit-197"><a href="#AdaOpt.fit-197"><span class="linenos">197</span></a>        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_</span><span class="p">))</span>
</span><span id="AdaOpt.fit-198"><a href="#AdaOpt.fit-198"><span class="linenos">198</span></a>
</span><span id="AdaOpt.fit-199"><a href="#AdaOpt.fit-199"><span class="linenos">199</span></a>        <span class="k">assert</span> <span class="n">n</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_</span><span class="p">),</span> <span class="s2">&quot;must have X.shape[0] == len(y)&quot;</span>
</span><span id="AdaOpt.fit-200"><a href="#AdaOpt.fit-200"><span class="linenos">200</span></a>
</span><span id="AdaOpt.fit-201"><a href="#AdaOpt.fit-201"><span class="linenos">201</span></a>        <span class="n">res</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">fit_adaopt</span><span class="p">(</span>
</span><span id="AdaOpt.fit-202"><a href="#AdaOpt.fit-202"><span class="linenos">202</span></a>            <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X_</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
</span><span id="AdaOpt.fit-203"><a href="#AdaOpt.fit-203"><span class="linenos">203</span></a>            <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
</span><span id="AdaOpt.fit-204"><a href="#AdaOpt.fit-204"><span class="linenos">204</span></a>            <span class="n">n_iterations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iterations</span><span class="p">,</span>
</span><span id="AdaOpt.fit-205"><a href="#AdaOpt.fit-205"><span class="linenos">205</span></a>            <span class="n">n_X</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
</span><span id="AdaOpt.fit-206"><a href="#AdaOpt.fit-206"><span class="linenos">206</span></a>            <span class="n">p_X</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
</span><span id="AdaOpt.fit-207"><a href="#AdaOpt.fit-207"><span class="linenos">207</span></a>            <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
</span><span id="AdaOpt.fit-208"><a href="#AdaOpt.fit-208"><span class="linenos">208</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="AdaOpt.fit-209"><a href="#AdaOpt.fit-209"><span class="linenos">209</span></a>            <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="AdaOpt.fit-210"><a href="#AdaOpt.fit-210"><span class="linenos">210</span></a>            <span class="n">reg_alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_alpha</span><span class="p">,</span>
</span><span id="AdaOpt.fit-211"><a href="#AdaOpt.fit-211"><span class="linenos">211</span></a>            <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="p">,</span>
</span><span id="AdaOpt.fit-212"><a href="#AdaOpt.fit-212"><span class="linenos">212</span></a>            <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
</span><span id="AdaOpt.fit-213"><a href="#AdaOpt.fit-213"><span class="linenos">213</span></a>            <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="AdaOpt.fit-214"><a href="#AdaOpt.fit-214"><span class="linenos">214</span></a>        <span class="p">)</span>
</span><span id="AdaOpt.fit-215"><a href="#AdaOpt.fit-215"><span class="linenos">215</span></a>
</span><span id="AdaOpt.fit-216"><a href="#AdaOpt.fit-216"><span class="linenos">216</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;probs&quot;</span><span class="p">]</span>
</span><span id="AdaOpt.fit-217"><a href="#AdaOpt.fit-217"><span class="linenos">217</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">training_accuracy</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;training_accuracy&quot;</span><span class="p">]</span>
</span><span id="AdaOpt.fit-218"><a href="#AdaOpt.fit-218"><span class="linenos">218</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;alphas&quot;</span><span class="p">]</span>
</span><span id="AdaOpt.fit-219"><a href="#AdaOpt.fit-219"><span class="linenos">219</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_iterations</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;n_iterations&quot;</span><span class="p">]</span>
</span><span id="AdaOpt.fit-220"><a href="#AdaOpt.fit-220"><span class="linenos">220</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">&quot;scaled_X_train&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="AdaOpt.fit-221"><a href="#AdaOpt.fit-221"><span class="linenos">221</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c1"># for compatibility with sklearn</span>
</span><span id="AdaOpt.fit-222"><a href="#AdaOpt.fit-222"><span class="linenos">222</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit AdaOpt to training data (X, y)</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

y: array-like, shape = [n_samples]
    Target values.

**kwargs: additional parameters to be passed to self.cook_training_set.
</code></pre>

<p>Returns:</p>

<pre><code>self: object.
</code></pre>
</div>


                                </div>
                                <div id="AdaOpt.predict" class="classattr">
                                            <input id="AdaOpt.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="AdaOpt.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AdaOpt.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AdaOpt.predict-224"><a href="#AdaOpt.predict-224"><span class="linenos">224</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="AdaOpt.predict-225"><a href="#AdaOpt.predict-225"><span class="linenos">225</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="AdaOpt.predict-226"><a href="#AdaOpt.predict-226"><span class="linenos">226</span></a>
</span><span id="AdaOpt.predict-227"><a href="#AdaOpt.predict-227"><span class="linenos">227</span></a><span class="sd">        Args:</span>
</span><span id="AdaOpt.predict-228"><a href="#AdaOpt.predict-228"><span class="linenos">228</span></a>
</span><span id="AdaOpt.predict-229"><a href="#AdaOpt.predict-229"><span class="linenos">229</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="AdaOpt.predict-230"><a href="#AdaOpt.predict-230"><span class="linenos">230</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="AdaOpt.predict-231"><a href="#AdaOpt.predict-231"><span class="linenos">231</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="AdaOpt.predict-232"><a href="#AdaOpt.predict-232"><span class="linenos">232</span></a>
</span><span id="AdaOpt.predict-233"><a href="#AdaOpt.predict-233"><span class="linenos">233</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="AdaOpt.predict-234"><a href="#AdaOpt.predict-234"><span class="linenos">234</span></a>
</span><span id="AdaOpt.predict-235"><a href="#AdaOpt.predict-235"><span class="linenos">235</span></a><span class="sd">        Returns:</span>
</span><span id="AdaOpt.predict-236"><a href="#AdaOpt.predict-236"><span class="linenos">236</span></a>
</span><span id="AdaOpt.predict-237"><a href="#AdaOpt.predict-237"><span class="linenos">237</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="AdaOpt.predict-238"><a href="#AdaOpt.predict-238"><span class="linenos">238</span></a>
</span><span id="AdaOpt.predict-239"><a href="#AdaOpt.predict-239"><span class="linenos">239</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AdaOpt.predict-240"><a href="#AdaOpt.predict-240"><span class="linenos">240</span></a>
</span><span id="AdaOpt.predict-241"><a href="#AdaOpt.predict-241"><span class="linenos">241</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to `predict_proba`
</code></pre>

<p>Returns:</p>

<pre><code>model predictions: {array-like}
</code></pre>
</div>


                                </div>
                                <div id="AdaOpt.predict_proba" class="classattr">
                                            <input id="AdaOpt.predict_proba-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict_proba</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="AdaOpt.predict_proba-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AdaOpt.predict_proba"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AdaOpt.predict_proba-243"><a href="#AdaOpt.predict_proba-243"><span class="linenos">243</span></a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="AdaOpt.predict_proba-244"><a href="#AdaOpt.predict_proba-244"><span class="linenos">244</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict probabilities for test data X.</span>
</span><span id="AdaOpt.predict_proba-245"><a href="#AdaOpt.predict_proba-245"><span class="linenos">245</span></a>
</span><span id="AdaOpt.predict_proba-246"><a href="#AdaOpt.predict_proba-246"><span class="linenos">246</span></a><span class="sd">        Args:</span>
</span><span id="AdaOpt.predict_proba-247"><a href="#AdaOpt.predict_proba-247"><span class="linenos">247</span></a>
</span><span id="AdaOpt.predict_proba-248"><a href="#AdaOpt.predict_proba-248"><span class="linenos">248</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="AdaOpt.predict_proba-249"><a href="#AdaOpt.predict_proba-249"><span class="linenos">249</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="AdaOpt.predict_proba-250"><a href="#AdaOpt.predict_proba-250"><span class="linenos">250</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="AdaOpt.predict_proba-251"><a href="#AdaOpt.predict_proba-251"><span class="linenos">251</span></a>
</span><span id="AdaOpt.predict_proba-252"><a href="#AdaOpt.predict_proba-252"><span class="linenos">252</span></a><span class="sd">            **kwargs: additional parameters to be passed to</span>
</span><span id="AdaOpt.predict_proba-253"><a href="#AdaOpt.predict_proba-253"><span class="linenos">253</span></a><span class="sd">                self.cook_test_set</span>
</span><span id="AdaOpt.predict_proba-254"><a href="#AdaOpt.predict_proba-254"><span class="linenos">254</span></a>
</span><span id="AdaOpt.predict_proba-255"><a href="#AdaOpt.predict_proba-255"><span class="linenos">255</span></a><span class="sd">        Returns:</span>
</span><span id="AdaOpt.predict_proba-256"><a href="#AdaOpt.predict_proba-256"><span class="linenos">256</span></a>
</span><span id="AdaOpt.predict_proba-257"><a href="#AdaOpt.predict_proba-257"><span class="linenos">257</span></a><span class="sd">            probability estimates for test data: {array-like}</span>
</span><span id="AdaOpt.predict_proba-258"><a href="#AdaOpt.predict_proba-258"><span class="linenos">258</span></a>
</span><span id="AdaOpt.predict_proba-259"><a href="#AdaOpt.predict_proba-259"><span class="linenos">259</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AdaOpt.predict_proba-260"><a href="#AdaOpt.predict_proba-260"><span class="linenos">260</span></a>
</span><span id="AdaOpt.predict_proba-261"><a href="#AdaOpt.predict_proba-261"><span class="linenos">261</span></a>        <span class="n">n_train</span><span class="p">,</span> <span class="n">p_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="o">.</span><span class="n">shape</span>
</span><span id="AdaOpt.predict_proba-262"><a href="#AdaOpt.predict_proba-262"><span class="linenos">262</span></a>
</span><span id="AdaOpt.predict_proba-263"><a href="#AdaOpt.predict_proba-263"><span class="linenos">263</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters_input</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="AdaOpt.predict_proba-264"><a href="#AdaOpt.predict_proba-264"><span class="linenos">264</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-265"><a href="#AdaOpt.predict_proba-265"><span class="linenos">265</span></a>                <span class="p">(</span>
</span><span id="AdaOpt.predict_proba-266"><a href="#AdaOpt.predict_proba-266"><span class="linenos">266</span></a>                    <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
</span><span id="AdaOpt.predict_proba-267"><a href="#AdaOpt.predict_proba-267"><span class="linenos">267</span></a>                    <span class="n">cluster</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-268"><a href="#AdaOpt.predict_proba-268"><span class="linenos">268</span></a>                        <span class="n">X</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-269"><a href="#AdaOpt.predict_proba-269"><span class="linenos">269</span></a>                        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-270"><a href="#AdaOpt.predict_proba-270"><span class="linenos">270</span></a>                        <span class="n">scaler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-271"><a href="#AdaOpt.predict_proba-271"><span class="linenos">271</span></a>                        <span class="n">label_encoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-272"><a href="#AdaOpt.predict_proba-272"><span class="linenos">272</span></a>                        <span class="n">clusterer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-273"><a href="#AdaOpt.predict_proba-273"><span class="linenos">273</span></a>                        <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-274"><a href="#AdaOpt.predict_proba-274"><span class="linenos">274</span></a>                    <span class="p">),</span>
</span><span id="AdaOpt.predict_proba-275"><a href="#AdaOpt.predict_proba-275"><span class="linenos">275</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-276"><a href="#AdaOpt.predict_proba-276"><span class="linenos">276</span></a>            <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-277"><a href="#AdaOpt.predict_proba-277"><span class="linenos">277</span></a>
</span><span id="AdaOpt.predict_proba-278"><a href="#AdaOpt.predict_proba-278"><span class="linenos">278</span></a>        <span class="n">n_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="AdaOpt.predict_proba-279"><a href="#AdaOpt.predict_proba-279"><span class="linenos">279</span></a>
</span><span id="AdaOpt.predict_proba-280"><a href="#AdaOpt.predict_proba-280"><span class="linenos">280</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AdaOpt.predict_proba-281"><a href="#AdaOpt.predict_proba-281"><span class="linenos">281</span></a>            <span class="k">return</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">predict_proba_adaopt</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-282"><a href="#AdaOpt.predict_proba-282"><span class="linenos">282</span></a>                <span class="n">X_test</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
</span><span id="AdaOpt.predict_proba-283"><a href="#AdaOpt.predict_proba-283"><span class="linenos">283</span></a>                <span class="n">scaled_X_train</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-284"><a href="#AdaOpt.predict_proba-284"><span class="linenos">284</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
</span><span id="AdaOpt.predict_proba-285"><a href="#AdaOpt.predict_proba-285"><span class="linenos">285</span></a>                <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
</span><span id="AdaOpt.predict_proba-286"><a href="#AdaOpt.predict_proba-286"><span class="linenos">286</span></a>                <span class="n">n_test</span><span class="o">=</span><span class="n">n_test</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-287"><a href="#AdaOpt.predict_proba-287"><span class="linenos">287</span></a>                <span class="n">n_train</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-288"><a href="#AdaOpt.predict_proba-288"><span class="linenos">288</span></a>                <span class="n">probs_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-289"><a href="#AdaOpt.predict_proba-289"><span class="linenos">289</span></a>                <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-290"><a href="#AdaOpt.predict_proba-290"><span class="linenos">290</span></a>                <span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-291"><a href="#AdaOpt.predict_proba-291"><span class="linenos">291</span></a>                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-292"><a href="#AdaOpt.predict_proba-292"><span class="linenos">292</span></a>                <span class="n">type_dist</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-293"><a href="#AdaOpt.predict_proba-293"><span class="linenos">293</span></a>                <span class="n">cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-294"><a href="#AdaOpt.predict_proba-294"><span class="linenos">294</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-295"><a href="#AdaOpt.predict_proba-295"><span class="linenos">295</span></a>            <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-296"><a href="#AdaOpt.predict_proba-296"><span class="linenos">296</span></a>
</span><span id="AdaOpt.predict_proba-297"><a href="#AdaOpt.predict_proba-297"><span class="linenos">297</span></a>        <span class="c1"># parallel: self.n_jobs is not None</span>
</span><span id="AdaOpt.predict_proba-298"><a href="#AdaOpt.predict_proba-298"><span class="linenos">298</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="AdaOpt.predict_proba-299"><a href="#AdaOpt.predict_proba-299"><span class="linenos">299</span></a>            <span class="s2">&quot;euclidean&quot;</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-300"><a href="#AdaOpt.predict_proba-300"><span class="linenos">300</span></a>            <span class="s2">&quot;manhattan&quot;</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-301"><a href="#AdaOpt.predict_proba-301"><span class="linenos">301</span></a>            <span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-302"><a href="#AdaOpt.predict_proba-302"><span class="linenos">302</span></a>        <span class="p">),</span> <span class="s2">&quot;must have: `self.type_dist` in (&#39;euclidean&#39;, &#39;manhattan&#39;, &#39;cosine&#39;) &quot;</span>
</span><span id="AdaOpt.predict_proba-303"><a href="#AdaOpt.predict_proba-303"><span class="linenos">303</span></a>
</span><span id="AdaOpt.predict_proba-304"><a href="#AdaOpt.predict_proba-304"><span class="linenos">304</span></a>        <span class="n">scaled_X_test</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
</span><span id="AdaOpt.predict_proba-305"><a href="#AdaOpt.predict_proba-305"><span class="linenos">305</span></a>
</span><span id="AdaOpt.predict_proba-306"><a href="#AdaOpt.predict_proba-306"><span class="linenos">306</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="o">==</span> <span class="s2">&quot;euclidean&quot;</span><span class="p">:</span>
</span><span id="AdaOpt.predict_proba-307"><a href="#AdaOpt.predict_proba-307"><span class="linenos">307</span></a>
</span><span id="AdaOpt.predict_proba-308"><a href="#AdaOpt.predict_proba-308"><span class="linenos">308</span></a>            <span class="nd">@delayed</span>
</span><span id="AdaOpt.predict_proba-309"><a href="#AdaOpt.predict_proba-309"><span class="linenos">309</span></a>            <span class="nd">@wrap_non_picklable_objects</span>
</span><span id="AdaOpt.predict_proba-310"><a href="#AdaOpt.predict_proba-310"><span class="linenos">310</span></a>            <span class="k">def</span> <span class="nf">multiproc_func</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
</span><span id="AdaOpt.predict_proba-311"><a href="#AdaOpt.predict_proba-311"><span class="linenos">311</span></a>                <span class="n">dists_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">distance_to_mat_euclidean2</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-312"><a href="#AdaOpt.predict_proba-312"><span class="linenos">312</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scaled_X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)[</span>
</span><span id="AdaOpt.predict_proba-313"><a href="#AdaOpt.predict_proba-313"><span class="linenos">313</span></a>                        <span class="n">i</span><span class="p">,</span> <span class="p">:</span>
</span><span id="AdaOpt.predict_proba-314"><a href="#AdaOpt.predict_proba-314"><span class="linenos">314</span></a>                    <span class="p">],</span>
</span><span id="AdaOpt.predict_proba-315"><a href="#AdaOpt.predict_proba-315"><span class="linenos">315</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-316"><a href="#AdaOpt.predict_proba-316"><span class="linenos">316</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
</span><span id="AdaOpt.predict_proba-317"><a href="#AdaOpt.predict_proba-317"><span class="linenos">317</span></a>                    <span class="p">),</span>
</span><span id="AdaOpt.predict_proba-318"><a href="#AdaOpt.predict_proba-318"><span class="linenos">318</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span>
</span><span id="AdaOpt.predict_proba-319"><a href="#AdaOpt.predict_proba-319"><span class="linenos">319</span></a>                    <span class="n">n_train</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-320"><a href="#AdaOpt.predict_proba-320"><span class="linenos">320</span></a>                    <span class="n">p_train</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-321"><a href="#AdaOpt.predict_proba-321"><span class="linenos">321</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-322"><a href="#AdaOpt.predict_proba-322"><span class="linenos">322</span></a>
</span><span id="AdaOpt.predict_proba-323"><a href="#AdaOpt.predict_proba-323"><span class="linenos">323</span></a>                <span class="n">kmin_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">find_kmin_x</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-324"><a href="#AdaOpt.predict_proba-324"><span class="linenos">324</span></a>                    <span class="n">dists_test_i</span><span class="p">,</span> <span class="n">n_x</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span>
</span><span id="AdaOpt.predict_proba-325"><a href="#AdaOpt.predict_proba-325"><span class="linenos">325</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-326"><a href="#AdaOpt.predict_proba-326"><span class="linenos">326</span></a>
</span><span id="AdaOpt.predict_proba-327"><a href="#AdaOpt.predict_proba-327"><span class="linenos">327</span></a>                <span class="n">weights_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_weights</span><span class="p">(</span><span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="AdaOpt.predict_proba-328"><a href="#AdaOpt.predict_proba-328"><span class="linenos">328</span></a>
</span><span id="AdaOpt.predict_proba-329"><a href="#AdaOpt.predict_proba-329"><span class="linenos">329</span></a>                <span class="n">probs_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_probs</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-330"><a href="#AdaOpt.predict_proba-330"><span class="linenos">330</span></a>                    <span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span>
</span><span id="AdaOpt.predict_proba-331"><a href="#AdaOpt.predict_proba-331"><span class="linenos">331</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-332"><a href="#AdaOpt.predict_proba-332"><span class="linenos">332</span></a>
</span><span id="AdaOpt.predict_proba-333"><a href="#AdaOpt.predict_proba-333"><span class="linenos">333</span></a>                <span class="k">return</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">average_probs</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-334"><a href="#AdaOpt.predict_proba-334"><span class="linenos">334</span></a>                    <span class="n">probs</span><span class="o">=</span><span class="n">probs_test_i</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights_test_i</span>
</span><span id="AdaOpt.predict_proba-335"><a href="#AdaOpt.predict_proba-335"><span class="linenos">335</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-336"><a href="#AdaOpt.predict_proba-336"><span class="linenos">336</span></a>
</span><span id="AdaOpt.predict_proba-337"><a href="#AdaOpt.predict_proba-337"><span class="linenos">337</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="o">==</span> <span class="s2">&quot;manhattan&quot;</span><span class="p">:</span>
</span><span id="AdaOpt.predict_proba-338"><a href="#AdaOpt.predict_proba-338"><span class="linenos">338</span></a>
</span><span id="AdaOpt.predict_proba-339"><a href="#AdaOpt.predict_proba-339"><span class="linenos">339</span></a>            <span class="nd">@delayed</span>
</span><span id="AdaOpt.predict_proba-340"><a href="#AdaOpt.predict_proba-340"><span class="linenos">340</span></a>            <span class="nd">@wrap_non_picklable_objects</span>
</span><span id="AdaOpt.predict_proba-341"><a href="#AdaOpt.predict_proba-341"><span class="linenos">341</span></a>            <span class="k">def</span> <span class="nf">multiproc_func</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
</span><span id="AdaOpt.predict_proba-342"><a href="#AdaOpt.predict_proba-342"><span class="linenos">342</span></a>                <span class="n">dists_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">distance_to_mat_manhattan2</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-343"><a href="#AdaOpt.predict_proba-343"><span class="linenos">343</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scaled_X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)[</span>
</span><span id="AdaOpt.predict_proba-344"><a href="#AdaOpt.predict_proba-344"><span class="linenos">344</span></a>                        <span class="n">i</span><span class="p">,</span> <span class="p">:</span>
</span><span id="AdaOpt.predict_proba-345"><a href="#AdaOpt.predict_proba-345"><span class="linenos">345</span></a>                    <span class="p">],</span>
</span><span id="AdaOpt.predict_proba-346"><a href="#AdaOpt.predict_proba-346"><span class="linenos">346</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-347"><a href="#AdaOpt.predict_proba-347"><span class="linenos">347</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
</span><span id="AdaOpt.predict_proba-348"><a href="#AdaOpt.predict_proba-348"><span class="linenos">348</span></a>                    <span class="p">),</span>
</span><span id="AdaOpt.predict_proba-349"><a href="#AdaOpt.predict_proba-349"><span class="linenos">349</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span>
</span><span id="AdaOpt.predict_proba-350"><a href="#AdaOpt.predict_proba-350"><span class="linenos">350</span></a>                    <span class="n">n_train</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-351"><a href="#AdaOpt.predict_proba-351"><span class="linenos">351</span></a>                    <span class="n">p_train</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-352"><a href="#AdaOpt.predict_proba-352"><span class="linenos">352</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-353"><a href="#AdaOpt.predict_proba-353"><span class="linenos">353</span></a>
</span><span id="AdaOpt.predict_proba-354"><a href="#AdaOpt.predict_proba-354"><span class="linenos">354</span></a>                <span class="n">kmin_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">find_kmin_x</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-355"><a href="#AdaOpt.predict_proba-355"><span class="linenos">355</span></a>                    <span class="n">dists_test_i</span><span class="p">,</span> <span class="n">n_x</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span>
</span><span id="AdaOpt.predict_proba-356"><a href="#AdaOpt.predict_proba-356"><span class="linenos">356</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-357"><a href="#AdaOpt.predict_proba-357"><span class="linenos">357</span></a>
</span><span id="AdaOpt.predict_proba-358"><a href="#AdaOpt.predict_proba-358"><span class="linenos">358</span></a>                <span class="n">weights_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_weights</span><span class="p">(</span><span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="AdaOpt.predict_proba-359"><a href="#AdaOpt.predict_proba-359"><span class="linenos">359</span></a>
</span><span id="AdaOpt.predict_proba-360"><a href="#AdaOpt.predict_proba-360"><span class="linenos">360</span></a>                <span class="n">probs_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_probs</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-361"><a href="#AdaOpt.predict_proba-361"><span class="linenos">361</span></a>                    <span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span>
</span><span id="AdaOpt.predict_proba-362"><a href="#AdaOpt.predict_proba-362"><span class="linenos">362</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-363"><a href="#AdaOpt.predict_proba-363"><span class="linenos">363</span></a>
</span><span id="AdaOpt.predict_proba-364"><a href="#AdaOpt.predict_proba-364"><span class="linenos">364</span></a>                <span class="k">return</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">average_probs</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-365"><a href="#AdaOpt.predict_proba-365"><span class="linenos">365</span></a>                    <span class="n">probs</span><span class="o">=</span><span class="n">probs_test_i</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights_test_i</span>
</span><span id="AdaOpt.predict_proba-366"><a href="#AdaOpt.predict_proba-366"><span class="linenos">366</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-367"><a href="#AdaOpt.predict_proba-367"><span class="linenos">367</span></a>
</span><span id="AdaOpt.predict_proba-368"><a href="#AdaOpt.predict_proba-368"><span class="linenos">368</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">type_dist</span> <span class="o">==</span> <span class="s2">&quot;cosine&quot;</span><span class="p">:</span>
</span><span id="AdaOpt.predict_proba-369"><a href="#AdaOpt.predict_proba-369"><span class="linenos">369</span></a>
</span><span id="AdaOpt.predict_proba-370"><a href="#AdaOpt.predict_proba-370"><span class="linenos">370</span></a>            <span class="nd">@delayed</span>
</span><span id="AdaOpt.predict_proba-371"><a href="#AdaOpt.predict_proba-371"><span class="linenos">371</span></a>            <span class="nd">@wrap_non_picklable_objects</span>
</span><span id="AdaOpt.predict_proba-372"><a href="#AdaOpt.predict_proba-372"><span class="linenos">372</span></a>            <span class="k">def</span> <span class="nf">multiproc_func</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span><span id="AdaOpt.predict_proba-373"><a href="#AdaOpt.predict_proba-373"><span class="linenos">373</span></a>                <span class="n">dists_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">distance_to_mat_cosine2</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-374"><a href="#AdaOpt.predict_proba-374"><span class="linenos">374</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">scaled_X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)[</span>
</span><span id="AdaOpt.predict_proba-375"><a href="#AdaOpt.predict_proba-375"><span class="linenos">375</span></a>                        <span class="n">i</span><span class="p">,</span> <span class="p">:</span>
</span><span id="AdaOpt.predict_proba-376"><a href="#AdaOpt.predict_proba-376"><span class="linenos">376</span></a>                    <span class="p">],</span>
</span><span id="AdaOpt.predict_proba-377"><a href="#AdaOpt.predict_proba-377"><span class="linenos">377</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-378"><a href="#AdaOpt.predict_proba-378"><span class="linenos">378</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">scaled_X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
</span><span id="AdaOpt.predict_proba-379"><a href="#AdaOpt.predict_proba-379"><span class="linenos">379</span></a>                    <span class="p">),</span>
</span><span id="AdaOpt.predict_proba-380"><a href="#AdaOpt.predict_proba-380"><span class="linenos">380</span></a>                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span>
</span><span id="AdaOpt.predict_proba-381"><a href="#AdaOpt.predict_proba-381"><span class="linenos">381</span></a>                    <span class="n">n_train</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-382"><a href="#AdaOpt.predict_proba-382"><span class="linenos">382</span></a>                    <span class="n">p_train</span><span class="p">,</span>
</span><span id="AdaOpt.predict_proba-383"><a href="#AdaOpt.predict_proba-383"><span class="linenos">383</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-384"><a href="#AdaOpt.predict_proba-384"><span class="linenos">384</span></a>
</span><span id="AdaOpt.predict_proba-385"><a href="#AdaOpt.predict_proba-385"><span class="linenos">385</span></a>                <span class="n">kmin_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">find_kmin_x</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-386"><a href="#AdaOpt.predict_proba-386"><span class="linenos">386</span></a>                    <span class="n">dists_test_i</span><span class="p">,</span> <span class="n">n_x</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cache</span>
</span><span id="AdaOpt.predict_proba-387"><a href="#AdaOpt.predict_proba-387"><span class="linenos">387</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-388"><a href="#AdaOpt.predict_proba-388"><span class="linenos">388</span></a>
</span><span id="AdaOpt.predict_proba-389"><a href="#AdaOpt.predict_proba-389"><span class="linenos">389</span></a>                <span class="n">weights_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_weights</span><span class="p">(</span><span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="AdaOpt.predict_proba-390"><a href="#AdaOpt.predict_proba-390"><span class="linenos">390</span></a>
</span><span id="AdaOpt.predict_proba-391"><a href="#AdaOpt.predict_proba-391"><span class="linenos">391</span></a>                <span class="n">probs_test_i</span> <span class="o">=</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">calculate_probs</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-392"><a href="#AdaOpt.predict_proba-392"><span class="linenos">392</span></a>                    <span class="n">kmin_test_i</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">probs_training</span>
</span><span id="AdaOpt.predict_proba-393"><a href="#AdaOpt.predict_proba-393"><span class="linenos">393</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-394"><a href="#AdaOpt.predict_proba-394"><span class="linenos">394</span></a>
</span><span id="AdaOpt.predict_proba-395"><a href="#AdaOpt.predict_proba-395"><span class="linenos">395</span></a>                <span class="k">return</span> <span class="n">adaoptc</span><span class="o">.</span><span class="n">average_probs</span><span class="p">(</span>
</span><span id="AdaOpt.predict_proba-396"><a href="#AdaOpt.predict_proba-396"><span class="linenos">396</span></a>                    <span class="n">probs</span><span class="o">=</span><span class="n">probs_test_i</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights_test_i</span>
</span><span id="AdaOpt.predict_proba-397"><a href="#AdaOpt.predict_proba-397"><span class="linenos">397</span></a>                <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-398"><a href="#AdaOpt.predict_proba-398"><span class="linenos">398</span></a>
</span><span id="AdaOpt.predict_proba-399"><a href="#AdaOpt.predict_proba-399"><span class="linenos">399</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="AdaOpt.predict_proba-400"><a href="#AdaOpt.predict_proba-400"><span class="linenos">400</span></a>            <span class="n">res</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">prefer</span><span class="o">=</span><span class="s2">&quot;threads&quot;</span><span class="p">)(</span>
</span><span id="AdaOpt.predict_proba-401"><a href="#AdaOpt.predict_proba-401"><span class="linenos">401</span></a>                <span class="p">(</span><span class="n">multiproc_func</span><span class="p">)(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_test</span><span class="p">))</span>
</span><span id="AdaOpt.predict_proba-402"><a href="#AdaOpt.predict_proba-402"><span class="linenos">402</span></a>            <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-403"><a href="#AdaOpt.predict_proba-403"><span class="linenos">403</span></a>
</span><span id="AdaOpt.predict_proba-404"><a href="#AdaOpt.predict_proba-404"><span class="linenos">404</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="AdaOpt.predict_proba-405"><a href="#AdaOpt.predict_proba-405"><span class="linenos">405</span></a>            <span class="n">res</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">prefer</span><span class="o">=</span><span class="s2">&quot;threads&quot;</span><span class="p">)(</span>
</span><span id="AdaOpt.predict_proba-406"><a href="#AdaOpt.predict_proba-406"><span class="linenos">406</span></a>                <span class="p">(</span><span class="n">multiproc_func</span><span class="p">)(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span>
</span><span id="AdaOpt.predict_proba-407"><a href="#AdaOpt.predict_proba-407"><span class="linenos">407</span></a>            <span class="p">)</span>
</span><span id="AdaOpt.predict_proba-408"><a href="#AdaOpt.predict_proba-408"><span class="linenos">408</span></a>
</span><span id="AdaOpt.predict_proba-409"><a href="#AdaOpt.predict_proba-409"><span class="linenos">409</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict probabilities for test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to
    self.cook_test_set
</code></pre>

<p>Returns:</p>

<pre><code>probability estimates for test data: {array-like}
</code></pre>
</div>


                                </div>
                        
                </section>
                <section id="LSBoostClassifier">
                            <input id="LSBoostClassifier-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">LSBoostClassifier</span><wbr>(<span class="base">sklearn.base.BaseEstimator</span>, <span class="base">sklearn.base.ClassifierMixin</span>):

                <label class="view-source-button" for="LSBoostClassifier-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LSBoostClassifier"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LSBoostClassifier-17"><a href="#LSBoostClassifier-17"><span class="linenos"> 17</span></a><span class="k">class</span> <span class="nc">LSBoostClassifier</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
</span><span id="LSBoostClassifier-18"><a href="#LSBoostClassifier-18"><span class="linenos"> 18</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;LSBoost classifier.</span>
</span><span id="LSBoostClassifier-19"><a href="#LSBoostClassifier-19"><span class="linenos"> 19</span></a>
</span><span id="LSBoostClassifier-20"><a href="#LSBoostClassifier-20"><span class="linenos"> 20</span></a><span class="sd">    Attributes:</span>
</span><span id="LSBoostClassifier-21"><a href="#LSBoostClassifier-21"><span class="linenos"> 21</span></a>
</span><span id="LSBoostClassifier-22"><a href="#LSBoostClassifier-22"><span class="linenos"> 22</span></a><span class="sd">        n_estimators: int</span>
</span><span id="LSBoostClassifier-23"><a href="#LSBoostClassifier-23"><span class="linenos"> 23</span></a><span class="sd">            number of boosting iterations.</span>
</span><span id="LSBoostClassifier-24"><a href="#LSBoostClassifier-24"><span class="linenos"> 24</span></a>
</span><span id="LSBoostClassifier-25"><a href="#LSBoostClassifier-25"><span class="linenos"> 25</span></a><span class="sd">        learning_rate: float</span>
</span><span id="LSBoostClassifier-26"><a href="#LSBoostClassifier-26"><span class="linenos"> 26</span></a><span class="sd">            controls the learning speed at training time.</span>
</span><span id="LSBoostClassifier-27"><a href="#LSBoostClassifier-27"><span class="linenos"> 27</span></a>
</span><span id="LSBoostClassifier-28"><a href="#LSBoostClassifier-28"><span class="linenos"> 28</span></a><span class="sd">        n_hidden_features: int</span>
</span><span id="LSBoostClassifier-29"><a href="#LSBoostClassifier-29"><span class="linenos"> 29</span></a><span class="sd">            number of nodes in successive hidden layers.</span>
</span><span id="LSBoostClassifier-30"><a href="#LSBoostClassifier-30"><span class="linenos"> 30</span></a>
</span><span id="LSBoostClassifier-31"><a href="#LSBoostClassifier-31"><span class="linenos"> 31</span></a><span class="sd">        reg_lambda: float</span>
</span><span id="LSBoostClassifier-32"><a href="#LSBoostClassifier-32"><span class="linenos"> 32</span></a><span class="sd">            L2 regularization parameter for successive errors in the optimizer</span>
</span><span id="LSBoostClassifier-33"><a href="#LSBoostClassifier-33"><span class="linenos"> 33</span></a><span class="sd">            (at training time).</span>
</span><span id="LSBoostClassifier-34"><a href="#LSBoostClassifier-34"><span class="linenos"> 34</span></a>
</span><span id="LSBoostClassifier-35"><a href="#LSBoostClassifier-35"><span class="linenos"> 35</span></a><span class="sd">        alpha: float</span>
</span><span id="LSBoostClassifier-36"><a href="#LSBoostClassifier-36"><span class="linenos"> 36</span></a><span class="sd">            compromise between L1 and L2 regularization (must be in [0, 1]),</span>
</span><span id="LSBoostClassifier-37"><a href="#LSBoostClassifier-37"><span class="linenos"> 37</span></a><span class="sd">            for `solver` == &#39;enet&#39;.</span>
</span><span id="LSBoostClassifier-38"><a href="#LSBoostClassifier-38"><span class="linenos"> 38</span></a>
</span><span id="LSBoostClassifier-39"><a href="#LSBoostClassifier-39"><span class="linenos"> 39</span></a><span class="sd">        row_sample: float</span>
</span><span id="LSBoostClassifier-40"><a href="#LSBoostClassifier-40"><span class="linenos"> 40</span></a><span class="sd">            percentage of rows chosen from the training set.</span>
</span><span id="LSBoostClassifier-41"><a href="#LSBoostClassifier-41"><span class="linenos"> 41</span></a>
</span><span id="LSBoostClassifier-42"><a href="#LSBoostClassifier-42"><span class="linenos"> 42</span></a><span class="sd">        col_sample: float</span>
</span><span id="LSBoostClassifier-43"><a href="#LSBoostClassifier-43"><span class="linenos"> 43</span></a><span class="sd">            percentage of columns chosen from the training set.</span>
</span><span id="LSBoostClassifier-44"><a href="#LSBoostClassifier-44"><span class="linenos"> 44</span></a>
</span><span id="LSBoostClassifier-45"><a href="#LSBoostClassifier-45"><span class="linenos"> 45</span></a><span class="sd">        dropout: float</span>
</span><span id="LSBoostClassifier-46"><a href="#LSBoostClassifier-46"><span class="linenos"> 46</span></a><span class="sd">            percentage of nodes dropped from the training set.</span>
</span><span id="LSBoostClassifier-47"><a href="#LSBoostClassifier-47"><span class="linenos"> 47</span></a>
</span><span id="LSBoostClassifier-48"><a href="#LSBoostClassifier-48"><span class="linenos"> 48</span></a><span class="sd">        tolerance: float</span>
</span><span id="LSBoostClassifier-49"><a href="#LSBoostClassifier-49"><span class="linenos"> 49</span></a><span class="sd">            controls early stopping in gradient descent (at training time).</span>
</span><span id="LSBoostClassifier-50"><a href="#LSBoostClassifier-50"><span class="linenos"> 50</span></a>
</span><span id="LSBoostClassifier-51"><a href="#LSBoostClassifier-51"><span class="linenos"> 51</span></a><span class="sd">        direct_link: bool</span>
</span><span id="LSBoostClassifier-52"><a href="#LSBoostClassifier-52"><span class="linenos"> 52</span></a><span class="sd">            indicates whether the original features are included (True) in model&#39;s</span>
</span><span id="LSBoostClassifier-53"><a href="#LSBoostClassifier-53"><span class="linenos"> 53</span></a><span class="sd">            fitting or not (False).</span>
</span><span id="LSBoostClassifier-54"><a href="#LSBoostClassifier-54"><span class="linenos"> 54</span></a>
</span><span id="LSBoostClassifier-55"><a href="#LSBoostClassifier-55"><span class="linenos"> 55</span></a><span class="sd">        verbose: int</span>
</span><span id="LSBoostClassifier-56"><a href="#LSBoostClassifier-56"><span class="linenos"> 56</span></a><span class="sd">            progress bar (yes = 1) or not (no = 0) (currently).</span>
</span><span id="LSBoostClassifier-57"><a href="#LSBoostClassifier-57"><span class="linenos"> 57</span></a>
</span><span id="LSBoostClassifier-58"><a href="#LSBoostClassifier-58"><span class="linenos"> 58</span></a><span class="sd">        seed: int</span>
</span><span id="LSBoostClassifier-59"><a href="#LSBoostClassifier-59"><span class="linenos"> 59</span></a><span class="sd">            reproducibility seed for nodes_sim==&#39;uniform&#39;, clustering and dropout.</span>
</span><span id="LSBoostClassifier-60"><a href="#LSBoostClassifier-60"><span class="linenos"> 60</span></a>
</span><span id="LSBoostClassifier-61"><a href="#LSBoostClassifier-61"><span class="linenos"> 61</span></a><span class="sd">        backend: str</span>
</span><span id="LSBoostClassifier-62"><a href="#LSBoostClassifier-62"><span class="linenos"> 62</span></a><span class="sd">            type of backend; must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)</span>
</span><span id="LSBoostClassifier-63"><a href="#LSBoostClassifier-63"><span class="linenos"> 63</span></a>
</span><span id="LSBoostClassifier-64"><a href="#LSBoostClassifier-64"><span class="linenos"> 64</span></a><span class="sd">        solver: str</span>
</span><span id="LSBoostClassifier-65"><a href="#LSBoostClassifier-65"><span class="linenos"> 65</span></a><span class="sd">            type of &#39;weak&#39; learner; currently in (&#39;ridge&#39;, &#39;lasso&#39;, &#39;enet&#39;).</span>
</span><span id="LSBoostClassifier-66"><a href="#LSBoostClassifier-66"><span class="linenos"> 66</span></a><span class="sd">            &#39;enet&#39; is a combination of &#39;ridge&#39; and &#39;lasso&#39; called Elastic Net.</span>
</span><span id="LSBoostClassifier-67"><a href="#LSBoostClassifier-67"><span class="linenos"> 67</span></a>
</span><span id="LSBoostClassifier-68"><a href="#LSBoostClassifier-68"><span class="linenos"> 68</span></a><span class="sd">        activation: str</span>
</span><span id="LSBoostClassifier-69"><a href="#LSBoostClassifier-69"><span class="linenos"> 69</span></a><span class="sd">            activation function: currently &#39;relu&#39;, &#39;relu6&#39;, &#39;sigmoid&#39;, &#39;tanh&#39;</span>
</span><span id="LSBoostClassifier-70"><a href="#LSBoostClassifier-70"><span class="linenos"> 70</span></a>
</span><span id="LSBoostClassifier-71"><a href="#LSBoostClassifier-71"><span class="linenos"> 71</span></a><span class="sd">        n_clusters: int</span>
</span><span id="LSBoostClassifier-72"><a href="#LSBoostClassifier-72"><span class="linenos"> 72</span></a><span class="sd">            number of clusters for clustering the features</span>
</span><span id="LSBoostClassifier-73"><a href="#LSBoostClassifier-73"><span class="linenos"> 73</span></a>
</span><span id="LSBoostClassifier-74"><a href="#LSBoostClassifier-74"><span class="linenos"> 74</span></a><span class="sd">        clustering_method: str</span>
</span><span id="LSBoostClassifier-75"><a href="#LSBoostClassifier-75"><span class="linenos"> 75</span></a><span class="sd">            clustering method: currently &#39;kmeans&#39;, &#39;gmm&#39;</span>
</span><span id="LSBoostClassifier-76"><a href="#LSBoostClassifier-76"><span class="linenos"> 76</span></a>
</span><span id="LSBoostClassifier-77"><a href="#LSBoostClassifier-77"><span class="linenos"> 77</span></a><span class="sd">        cluster_scaling: str</span>
</span><span id="LSBoostClassifier-78"><a href="#LSBoostClassifier-78"><span class="linenos"> 78</span></a><span class="sd">            scaling method for clustering: currently &#39;standard&#39;, &#39;robust&#39;, &#39;minmax&#39;</span>
</span><span id="LSBoostClassifier-79"><a href="#LSBoostClassifier-79"><span class="linenos"> 79</span></a>
</span><span id="LSBoostClassifier-80"><a href="#LSBoostClassifier-80"><span class="linenos"> 80</span></a><span class="sd">        degree: int</span>
</span><span id="LSBoostClassifier-81"><a href="#LSBoostClassifier-81"><span class="linenos"> 81</span></a><span class="sd">            degree of features interactions to include in the model</span>
</span><span id="LSBoostClassifier-82"><a href="#LSBoostClassifier-82"><span class="linenos"> 82</span></a>
</span><span id="LSBoostClassifier-83"><a href="#LSBoostClassifier-83"><span class="linenos"> 83</span></a><span class="sd">        weights_distr: str</span>
</span><span id="LSBoostClassifier-84"><a href="#LSBoostClassifier-84"><span class="linenos"> 84</span></a><span class="sd">            distribution of weights for constructing the model&#39;s hidden layer;</span>
</span><span id="LSBoostClassifier-85"><a href="#LSBoostClassifier-85"><span class="linenos"> 85</span></a><span class="sd">            currently &#39;uniform&#39;, &#39;gaussian&#39;</span>
</span><span id="LSBoostClassifier-86"><a href="#LSBoostClassifier-86"><span class="linenos"> 86</span></a>
</span><span id="LSBoostClassifier-87"><a href="#LSBoostClassifier-87"><span class="linenos"> 87</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="LSBoostClassifier-88"><a href="#LSBoostClassifier-88"><span class="linenos"> 88</span></a>
</span><span id="LSBoostClassifier-89"><a href="#LSBoostClassifier-89"><span class="linenos"> 89</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="LSBoostClassifier-90"><a href="#LSBoostClassifier-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LSBoostClassifier-91"><a href="#LSBoostClassifier-91"><span class="linenos"> 91</span></a>        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="LSBoostClassifier-92"><a href="#LSBoostClassifier-92"><span class="linenos"> 92</span></a>        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="LSBoostClassifier-93"><a href="#LSBoostClassifier-93"><span class="linenos"> 93</span></a>        <span class="n">n_hidden_features</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="LSBoostClassifier-94"><a href="#LSBoostClassifier-94"><span class="linenos"> 94</span></a>        <span class="n">reg_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="LSBoostClassifier-95"><a href="#LSBoostClassifier-95"><span class="linenos"> 95</span></a>        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
</span><span id="LSBoostClassifier-96"><a href="#LSBoostClassifier-96"><span class="linenos"> 96</span></a>        <span class="n">row_sample</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LSBoostClassifier-97"><a href="#LSBoostClassifier-97"><span class="linenos"> 97</span></a>        <span class="n">col_sample</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LSBoostClassifier-98"><a href="#LSBoostClassifier-98"><span class="linenos"> 98</span></a>        <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="LSBoostClassifier-99"><a href="#LSBoostClassifier-99"><span class="linenos"> 99</span></a>        <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
</span><span id="LSBoostClassifier-100"><a href="#LSBoostClassifier-100"><span class="linenos">100</span></a>        <span class="n">direct_link</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LSBoostClassifier-101"><a href="#LSBoostClassifier-101"><span class="linenos">101</span></a>        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LSBoostClassifier-102"><a href="#LSBoostClassifier-102"><span class="linenos">102</span></a>        <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
</span><span id="LSBoostClassifier-103"><a href="#LSBoostClassifier-103"><span class="linenos">103</span></a>        <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-104"><a href="#LSBoostClassifier-104"><span class="linenos">104</span></a>        <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;ridge&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-105"><a href="#LSBoostClassifier-105"><span class="linenos">105</span></a>        <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-106"><a href="#LSBoostClassifier-106"><span class="linenos">106</span></a>        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="LSBoostClassifier-107"><a href="#LSBoostClassifier-107"><span class="linenos">107</span></a>        <span class="n">clustering_method</span><span class="o">=</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-108"><a href="#LSBoostClassifier-108"><span class="linenos">108</span></a>        <span class="n">cluster_scaling</span><span class="o">=</span><span class="s2">&quot;standard&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-109"><a href="#LSBoostClassifier-109"><span class="linenos">109</span></a>        <span class="n">degree</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="LSBoostClassifier-110"><a href="#LSBoostClassifier-110"><span class="linenos">110</span></a>        <span class="n">weights_distr</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-111"><a href="#LSBoostClassifier-111"><span class="linenos">111</span></a>    <span class="p">):</span>
</span><span id="LSBoostClassifier-112"><a href="#LSBoostClassifier-112"><span class="linenos">112</span></a>        <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostClassifier-113"><a href="#LSBoostClassifier-113"><span class="linenos">113</span></a>            <span class="k">assert</span> <span class="n">clustering_method</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostClassifier-114"><a href="#LSBoostClassifier-114"><span class="linenos">114</span></a>                <span class="s2">&quot;kmeans&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-115"><a href="#LSBoostClassifier-115"><span class="linenos">115</span></a>                <span class="s2">&quot;gmm&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-116"><a href="#LSBoostClassifier-116"><span class="linenos">116</span></a>            <span class="p">),</span> <span class="s2">&quot;`clustering_method` must be in (&#39;kmeans&#39;, &#39;gmm&#39;)&quot;</span>
</span><span id="LSBoostClassifier-117"><a href="#LSBoostClassifier-117"><span class="linenos">117</span></a>            <span class="k">assert</span> <span class="n">cluster_scaling</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostClassifier-118"><a href="#LSBoostClassifier-118"><span class="linenos">118</span></a>                <span class="s2">&quot;standard&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-119"><a href="#LSBoostClassifier-119"><span class="linenos">119</span></a>                <span class="s2">&quot;robust&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-120"><a href="#LSBoostClassifier-120"><span class="linenos">120</span></a>                <span class="s2">&quot;minmax&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-121"><a href="#LSBoostClassifier-121"><span class="linenos">121</span></a>            <span class="p">),</span> <span class="s2">&quot;`cluster_scaling` must be in (&#39;standard&#39;, &#39;robust&#39;, &#39;minmax&#39;)&quot;</span>
</span><span id="LSBoostClassifier-122"><a href="#LSBoostClassifier-122"><span class="linenos">122</span></a>
</span><span id="LSBoostClassifier-123"><a href="#LSBoostClassifier-123"><span class="linenos">123</span></a>        <span class="k">assert</span> <span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostClassifier-124"><a href="#LSBoostClassifier-124"><span class="linenos">124</span></a>            <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-125"><a href="#LSBoostClassifier-125"><span class="linenos">125</span></a>            <span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-126"><a href="#LSBoostClassifier-126"><span class="linenos">126</span></a>            <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-127"><a href="#LSBoostClassifier-127"><span class="linenos">127</span></a>        <span class="p">),</span> <span class="s2">&quot;`backend` must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)&quot;</span>
</span><span id="LSBoostClassifier-128"><a href="#LSBoostClassifier-128"><span class="linenos">128</span></a>
</span><span id="LSBoostClassifier-129"><a href="#LSBoostClassifier-129"><span class="linenos">129</span></a>        <span class="k">assert</span> <span class="n">solver</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostClassifier-130"><a href="#LSBoostClassifier-130"><span class="linenos">130</span></a>            <span class="s2">&quot;ridge&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-131"><a href="#LSBoostClassifier-131"><span class="linenos">131</span></a>            <span class="s2">&quot;lasso&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-132"><a href="#LSBoostClassifier-132"><span class="linenos">132</span></a>            <span class="s2">&quot;enet&quot;</span><span class="p">,</span>
</span><span id="LSBoostClassifier-133"><a href="#LSBoostClassifier-133"><span class="linenos">133</span></a>        <span class="p">),</span> <span class="s2">&quot;`solver` must be in (&#39;ridge&#39;, &#39;lasso&#39;, &#39;enet&#39;)&quot;</span>
</span><span id="LSBoostClassifier-134"><a href="#LSBoostClassifier-134"><span class="linenos">134</span></a>
</span><span id="LSBoostClassifier-135"><a href="#LSBoostClassifier-135"><span class="linenos">135</span></a>        <span class="n">sys_platform</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>
</span><span id="LSBoostClassifier-136"><a href="#LSBoostClassifier-136"><span class="linenos">136</span></a>
</span><span id="LSBoostClassifier-137"><a href="#LSBoostClassifier-137"><span class="linenos">137</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">sys_platform</span> <span class="o">==</span> <span class="s2">&quot;Windows&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="s2">&quot;tpu&quot;</span><span class="p">)):</span>
</span><span id="LSBoostClassifier-138"><a href="#LSBoostClassifier-138"><span class="linenos">138</span></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span id="LSBoostClassifier-139"><a href="#LSBoostClassifier-139"><span class="linenos">139</span></a>                <span class="s2">&quot;No GPU/TPU computing on Windows yet, backend set to &#39;cpu&#39;&quot;</span>
</span><span id="LSBoostClassifier-140"><a href="#LSBoostClassifier-140"><span class="linenos">140</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier-141"><a href="#LSBoostClassifier-141"><span class="linenos">141</span></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
</span><span id="LSBoostClassifier-142"><a href="#LSBoostClassifier-142"><span class="linenos">142</span></a>
</span><span id="LSBoostClassifier-143"><a href="#LSBoostClassifier-143"><span class="linenos">143</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
</span><span id="LSBoostClassifier-144"><a href="#LSBoostClassifier-144"><span class="linenos">144</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="LSBoostClassifier-145"><a href="#LSBoostClassifier-145"><span class="linenos">145</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span> <span class="o">=</span> <span class="n">n_hidden_features</span>
</span><span id="LSBoostClassifier-146"><a href="#LSBoostClassifier-146"><span class="linenos">146</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">reg_lambda</span>
</span><span id="LSBoostClassifier-147"><a href="#LSBoostClassifier-147"><span class="linenos">147</span></a>        <span class="k">assert</span> <span class="n">alpha</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;`alpha` must be in [0, 1]&quot;</span>
</span><span id="LSBoostClassifier-148"><a href="#LSBoostClassifier-148"><span class="linenos">148</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span><span id="LSBoostClassifier-149"><a href="#LSBoostClassifier-149"><span class="linenos">149</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span> <span class="o">=</span> <span class="n">row_sample</span>
</span><span id="LSBoostClassifier-150"><a href="#LSBoostClassifier-150"><span class="linenos">150</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span> <span class="o">=</span> <span class="n">col_sample</span>
</span><span id="LSBoostClassifier-151"><a href="#LSBoostClassifier-151"><span class="linenos">151</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
</span><span id="LSBoostClassifier-152"><a href="#LSBoostClassifier-152"><span class="linenos">152</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="n">tolerance</span>
</span><span id="LSBoostClassifier-153"><a href="#LSBoostClassifier-153"><span class="linenos">153</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span> <span class="o">=</span> <span class="n">direct_link</span>
</span><span id="LSBoostClassifier-154"><a href="#LSBoostClassifier-154"><span class="linenos">154</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
</span><span id="LSBoostClassifier-155"><a href="#LSBoostClassifier-155"><span class="linenos">155</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
</span><span id="LSBoostClassifier-156"><a href="#LSBoostClassifier-156"><span class="linenos">156</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span>
</span><span id="LSBoostClassifier-157"><a href="#LSBoostClassifier-157"><span class="linenos">157</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LSBoostClassifier-158"><a href="#LSBoostClassifier-158"><span class="linenos">158</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
</span><span id="LSBoostClassifier-159"><a href="#LSBoostClassifier-159"><span class="linenos">159</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
</span><span id="LSBoostClassifier-160"><a href="#LSBoostClassifier-160"><span class="linenos">160</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
</span><span id="LSBoostClassifier-161"><a href="#LSBoostClassifier-161"><span class="linenos">161</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span> <span class="o">=</span> <span class="n">clustering_method</span>
</span><span id="LSBoostClassifier-162"><a href="#LSBoostClassifier-162"><span class="linenos">162</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span> <span class="o">=</span> <span class="n">cluster_scaling</span>
</span><span id="LSBoostClassifier-163"><a href="#LSBoostClassifier-163"><span class="linenos">163</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="LSBoostClassifier-164"><a href="#LSBoostClassifier-164"><span class="linenos">164</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span>
</span><span id="LSBoostClassifier-165"><a href="#LSBoostClassifier-165"><span class="linenos">165</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LSBoostClassifier-166"><a href="#LSBoostClassifier-166"><span class="linenos">166</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distr</span> <span class="o">=</span> <span class="n">weights_distr</span>
</span><span id="LSBoostClassifier-167"><a href="#LSBoostClassifier-167"><span class="linenos">167</span></a>
</span><span id="LSBoostClassifier-168"><a href="#LSBoostClassifier-168"><span class="linenos">168</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostClassifier-169"><a href="#LSBoostClassifier-169"><span class="linenos">169</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit Booster (classifier) to training data (X, y)</span>
</span><span id="LSBoostClassifier-170"><a href="#LSBoostClassifier-170"><span class="linenos">170</span></a>
</span><span id="LSBoostClassifier-171"><a href="#LSBoostClassifier-171"><span class="linenos">171</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostClassifier-172"><a href="#LSBoostClassifier-172"><span class="linenos">172</span></a>
</span><span id="LSBoostClassifier-173"><a href="#LSBoostClassifier-173"><span class="linenos">173</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostClassifier-174"><a href="#LSBoostClassifier-174"><span class="linenos">174</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostClassifier-175"><a href="#LSBoostClassifier-175"><span class="linenos">175</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostClassifier-176"><a href="#LSBoostClassifier-176"><span class="linenos">176</span></a>
</span><span id="LSBoostClassifier-177"><a href="#LSBoostClassifier-177"><span class="linenos">177</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="LSBoostClassifier-178"><a href="#LSBoostClassifier-178"><span class="linenos">178</span></a><span class="sd">                Target values.</span>
</span><span id="LSBoostClassifier-179"><a href="#LSBoostClassifier-179"><span class="linenos">179</span></a>
</span><span id="LSBoostClassifier-180"><a href="#LSBoostClassifier-180"><span class="linenos">180</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="LSBoostClassifier-181"><a href="#LSBoostClassifier-181"><span class="linenos">181</span></a>
</span><span id="LSBoostClassifier-182"><a href="#LSBoostClassifier-182"><span class="linenos">182</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostClassifier-183"><a href="#LSBoostClassifier-183"><span class="linenos">183</span></a>
</span><span id="LSBoostClassifier-184"><a href="#LSBoostClassifier-184"><span class="linenos">184</span></a><span class="sd">            self: object.</span>
</span><span id="LSBoostClassifier-185"><a href="#LSBoostClassifier-185"><span class="linenos">185</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostClassifier-186"><a href="#LSBoostClassifier-186"><span class="linenos">186</span></a>
</span><span id="LSBoostClassifier-187"><a href="#LSBoostClassifier-187"><span class="linenos">187</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
</span><span id="LSBoostClassifier-188"><a href="#LSBoostClassifier-188"><span class="linenos">188</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
</span><span id="LSBoostClassifier-189"><a href="#LSBoostClassifier-189"><span class="linenos">189</span></a>
</span><span id="LSBoostClassifier-190"><a href="#LSBoostClassifier-190"><span class="linenos">190</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LSBoostClassifier-191"><a href="#LSBoostClassifier-191"><span class="linenos">191</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span>
</span><span id="LSBoostClassifier-192"><a href="#LSBoostClassifier-192"><span class="linenos">192</span></a>                <span class="n">degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="LSBoostClassifier-193"><a href="#LSBoostClassifier-193"><span class="linenos">193</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier-194"><a href="#LSBoostClassifier-194"><span class="linenos">194</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LSBoostClassifier-195"><a href="#LSBoostClassifier-195"><span class="linenos">195</span></a>
</span><span id="LSBoostClassifier-196"><a href="#LSBoostClassifier-196"><span class="linenos">196</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostClassifier-197"><a href="#LSBoostClassifier-197"><span class="linenos">197</span></a>            <span class="n">clustered_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="LSBoostClassifier-198"><a href="#LSBoostClassifier-198"><span class="linenos">198</span></a>                <span class="n">cluster</span><span class="p">(</span>
</span><span id="LSBoostClassifier-199"><a href="#LSBoostClassifier-199"><span class="linenos">199</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostClassifier-200"><a href="#LSBoostClassifier-200"><span class="linenos">200</span></a>                    <span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span>
</span><span id="LSBoostClassifier-201"><a href="#LSBoostClassifier-201"><span class="linenos">201</span></a>                    <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span><span class="p">,</span>
</span><span id="LSBoostClassifier-202"><a href="#LSBoostClassifier-202"><span class="linenos">202</span></a>                    <span class="n">type_scaling</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span><span class="p">,</span>
</span><span id="LSBoostClassifier-203"><a href="#LSBoostClassifier-203"><span class="linenos">203</span></a>                    <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="LSBoostClassifier-204"><a href="#LSBoostClassifier-204"><span class="linenos">204</span></a>                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostClassifier-205"><a href="#LSBoostClassifier-205"><span class="linenos">205</span></a>                <span class="p">)</span>
</span><span id="LSBoostClassifier-206"><a href="#LSBoostClassifier-206"><span class="linenos">206</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier-207"><a href="#LSBoostClassifier-207"><span class="linenos">207</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">clustered_X</span><span class="p">))</span>
</span><span id="LSBoostClassifier-208"><a href="#LSBoostClassifier-208"><span class="linenos">208</span></a>
</span><span id="LSBoostClassifier-209"><a href="#LSBoostClassifier-209"><span class="linenos">209</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="LSBoostClassifier-210"><a href="#LSBoostClassifier-210"><span class="linenos">210</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">boosterc</span><span class="o">.</span><span class="n">fit_booster_classifier</span><span class="p">(</span>
</span><span id="LSBoostClassifier-211"><a href="#LSBoostClassifier-211"><span class="linenos">211</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostClassifier-212"><a href="#LSBoostClassifier-212"><span class="linenos">212</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostClassifier-213"><a href="#LSBoostClassifier-213"><span class="linenos">213</span></a>                <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="LSBoostClassifier-214"><a href="#LSBoostClassifier-214"><span class="linenos">214</span></a>                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LSBoostClassifier-215"><a href="#LSBoostClassifier-215"><span class="linenos">215</span></a>                <span class="n">n_hidden_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span><span class="p">,</span>
</span><span id="LSBoostClassifier-216"><a href="#LSBoostClassifier-216"><span class="linenos">216</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LSBoostClassifier-217"><a href="#LSBoostClassifier-217"><span class="linenos">217</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="LSBoostClassifier-218"><a href="#LSBoostClassifier-218"><span class="linenos">218</span></a>                <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span>
</span><span id="LSBoostClassifier-219"><a href="#LSBoostClassifier-219"><span class="linenos">219</span></a>                <span class="n">col_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span><span class="p">,</span>
</span><span id="LSBoostClassifier-220"><a href="#LSBoostClassifier-220"><span class="linenos">220</span></a>                <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="LSBoostClassifier-221"><a href="#LSBoostClassifier-221"><span class="linenos">221</span></a>                <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="LSBoostClassifier-222"><a href="#LSBoostClassifier-222"><span class="linenos">222</span></a>                <span class="n">direct_link</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span><span class="p">,</span>
</span><span id="LSBoostClassifier-223"><a href="#LSBoostClassifier-223"><span class="linenos">223</span></a>                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="LSBoostClassifier-224"><a href="#LSBoostClassifier-224"><span class="linenos">224</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostClassifier-225"><a href="#LSBoostClassifier-225"><span class="linenos">225</span></a>                <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span>
</span><span id="LSBoostClassifier-226"><a href="#LSBoostClassifier-226"><span class="linenos">226</span></a>                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
</span><span id="LSBoostClassifier-227"><a href="#LSBoostClassifier-227"><span class="linenos">227</span></a>                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
</span><span id="LSBoostClassifier-228"><a href="#LSBoostClassifier-228"><span class="linenos">228</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier-229"><a href="#LSBoostClassifier-229"><span class="linenos">229</span></a>        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="LSBoostClassifier-230"><a href="#LSBoostClassifier-230"><span class="linenos">230</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">_boosterc</span><span class="o">.</span><span class="n">fit_booster_classifier</span><span class="p">(</span>
</span><span id="LSBoostClassifier-231"><a href="#LSBoostClassifier-231"><span class="linenos">231</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostClassifier-232"><a href="#LSBoostClassifier-232"><span class="linenos">232</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostClassifier-233"><a href="#LSBoostClassifier-233"><span class="linenos">233</span></a>                <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="LSBoostClassifier-234"><a href="#LSBoostClassifier-234"><span class="linenos">234</span></a>                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LSBoostClassifier-235"><a href="#LSBoostClassifier-235"><span class="linenos">235</span></a>                <span class="n">n_hidden_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span><span class="p">,</span>
</span><span id="LSBoostClassifier-236"><a href="#LSBoostClassifier-236"><span class="linenos">236</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LSBoostClassifier-237"><a href="#LSBoostClassifier-237"><span class="linenos">237</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="LSBoostClassifier-238"><a href="#LSBoostClassifier-238"><span class="linenos">238</span></a>                <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span>
</span><span id="LSBoostClassifier-239"><a href="#LSBoostClassifier-239"><span class="linenos">239</span></a>                <span class="n">col_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span><span class="p">,</span>
</span><span id="LSBoostClassifier-240"><a href="#LSBoostClassifier-240"><span class="linenos">240</span></a>                <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="LSBoostClassifier-241"><a href="#LSBoostClassifier-241"><span class="linenos">241</span></a>                <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="LSBoostClassifier-242"><a href="#LSBoostClassifier-242"><span class="linenos">242</span></a>                <span class="n">direct_link</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span><span class="p">,</span>
</span><span id="LSBoostClassifier-243"><a href="#LSBoostClassifier-243"><span class="linenos">243</span></a>                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="LSBoostClassifier-244"><a href="#LSBoostClassifier-244"><span class="linenos">244</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostClassifier-245"><a href="#LSBoostClassifier-245"><span class="linenos">245</span></a>                <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span>
</span><span id="LSBoostClassifier-246"><a href="#LSBoostClassifier-246"><span class="linenos">246</span></a>                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
</span><span id="LSBoostClassifier-247"><a href="#LSBoostClassifier-247"><span class="linenos">247</span></a>                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
</span><span id="LSBoostClassifier-248"><a href="#LSBoostClassifier-248"><span class="linenos">248</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier-249"><a href="#LSBoostClassifier-249"><span class="linenos">249</span></a>
</span><span id="LSBoostClassifier-250"><a href="#LSBoostClassifier-250"><span class="linenos">250</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c1"># for compatibility with sklearn</span>
</span><span id="LSBoostClassifier-251"><a href="#LSBoostClassifier-251"><span class="linenos">251</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span>
</span><span id="LSBoostClassifier-252"><a href="#LSBoostClassifier-252"><span class="linenos">252</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="LSBoostClassifier-253"><a href="#LSBoostClassifier-253"><span class="linenos">253</span></a>
</span><span id="LSBoostClassifier-254"><a href="#LSBoostClassifier-254"><span class="linenos">254</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostClassifier-255"><a href="#LSBoostClassifier-255"><span class="linenos">255</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="LSBoostClassifier-256"><a href="#LSBoostClassifier-256"><span class="linenos">256</span></a>
</span><span id="LSBoostClassifier-257"><a href="#LSBoostClassifier-257"><span class="linenos">257</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostClassifier-258"><a href="#LSBoostClassifier-258"><span class="linenos">258</span></a>
</span><span id="LSBoostClassifier-259"><a href="#LSBoostClassifier-259"><span class="linenos">259</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostClassifier-260"><a href="#LSBoostClassifier-260"><span class="linenos">260</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostClassifier-261"><a href="#LSBoostClassifier-261"><span class="linenos">261</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostClassifier-262"><a href="#LSBoostClassifier-262"><span class="linenos">262</span></a>
</span><span id="LSBoostClassifier-263"><a href="#LSBoostClassifier-263"><span class="linenos">263</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="LSBoostClassifier-264"><a href="#LSBoostClassifier-264"><span class="linenos">264</span></a>
</span><span id="LSBoostClassifier-265"><a href="#LSBoostClassifier-265"><span class="linenos">265</span></a>
</span><span id="LSBoostClassifier-266"><a href="#LSBoostClassifier-266"><span class="linenos">266</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostClassifier-267"><a href="#LSBoostClassifier-267"><span class="linenos">267</span></a>
</span><span id="LSBoostClassifier-268"><a href="#LSBoostClassifier-268"><span class="linenos">268</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="LSBoostClassifier-269"><a href="#LSBoostClassifier-269"><span class="linenos">269</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostClassifier-270"><a href="#LSBoostClassifier-270"><span class="linenos">270</span></a>
</span><span id="LSBoostClassifier-271"><a href="#LSBoostClassifier-271"><span class="linenos">271</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="LSBoostClassifier-272"><a href="#LSBoostClassifier-272"><span class="linenos">272</span></a>
</span><span id="LSBoostClassifier-273"><a href="#LSBoostClassifier-273"><span class="linenos">273</span></a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostClassifier-274"><a href="#LSBoostClassifier-274"><span class="linenos">274</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict probabilities for test data X.</span>
</span><span id="LSBoostClassifier-275"><a href="#LSBoostClassifier-275"><span class="linenos">275</span></a>
</span><span id="LSBoostClassifier-276"><a href="#LSBoostClassifier-276"><span class="linenos">276</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostClassifier-277"><a href="#LSBoostClassifier-277"><span class="linenos">277</span></a>
</span><span id="LSBoostClassifier-278"><a href="#LSBoostClassifier-278"><span class="linenos">278</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostClassifier-279"><a href="#LSBoostClassifier-279"><span class="linenos">279</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostClassifier-280"><a href="#LSBoostClassifier-280"><span class="linenos">280</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostClassifier-281"><a href="#LSBoostClassifier-281"><span class="linenos">281</span></a>
</span><span id="LSBoostClassifier-282"><a href="#LSBoostClassifier-282"><span class="linenos">282</span></a><span class="sd">            **kwargs: additional parameters to be passed to</span>
</span><span id="LSBoostClassifier-283"><a href="#LSBoostClassifier-283"><span class="linenos">283</span></a><span class="sd">                self.cook_test_set</span>
</span><span id="LSBoostClassifier-284"><a href="#LSBoostClassifier-284"><span class="linenos">284</span></a>
</span><span id="LSBoostClassifier-285"><a href="#LSBoostClassifier-285"><span class="linenos">285</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostClassifier-286"><a href="#LSBoostClassifier-286"><span class="linenos">286</span></a>
</span><span id="LSBoostClassifier-287"><a href="#LSBoostClassifier-287"><span class="linenos">287</span></a><span class="sd">            probability estimates for test data: {array-like}</span>
</span><span id="LSBoostClassifier-288"><a href="#LSBoostClassifier-288"><span class="linenos">288</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostClassifier-289"><a href="#LSBoostClassifier-289"><span class="linenos">289</span></a>
</span><span id="LSBoostClassifier-290"><a href="#LSBoostClassifier-290"><span class="linenos">290</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
</span><span id="LSBoostClassifier-291"><a href="#LSBoostClassifier-291"><span class="linenos">291</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
</span><span id="LSBoostClassifier-292"><a href="#LSBoostClassifier-292"><span class="linenos">292</span></a>
</span><span id="LSBoostClassifier-293"><a href="#LSBoostClassifier-293"><span class="linenos">293</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostClassifier-294"><a href="#LSBoostClassifier-294"><span class="linenos">294</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LSBoostClassifier-295"><a href="#LSBoostClassifier-295"><span class="linenos">295</span></a>
</span><span id="LSBoostClassifier-296"><a href="#LSBoostClassifier-296"><span class="linenos">296</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostClassifier-297"><a href="#LSBoostClassifier-297"><span class="linenos">297</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="LSBoostClassifier-298"><a href="#LSBoostClassifier-298"><span class="linenos">298</span></a>                <span class="p">(</span>
</span><span id="LSBoostClassifier-299"><a href="#LSBoostClassifier-299"><span class="linenos">299</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostClassifier-300"><a href="#LSBoostClassifier-300"><span class="linenos">300</span></a>                    <span class="n">cluster</span><span class="p">(</span>
</span><span id="LSBoostClassifier-301"><a href="#LSBoostClassifier-301"><span class="linenos">301</span></a>                        <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostClassifier-302"><a href="#LSBoostClassifier-302"><span class="linenos">302</span></a>                        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="LSBoostClassifier-303"><a href="#LSBoostClassifier-303"><span class="linenos">303</span></a>                        <span class="n">scaler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span>
</span><span id="LSBoostClassifier-304"><a href="#LSBoostClassifier-304"><span class="linenos">304</span></a>                        <span class="n">label_encoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span>
</span><span id="LSBoostClassifier-305"><a href="#LSBoostClassifier-305"><span class="linenos">305</span></a>                        <span class="n">clusterer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span><span class="p">,</span>
</span><span id="LSBoostClassifier-306"><a href="#LSBoostClassifier-306"><span class="linenos">306</span></a>                        <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostClassifier-307"><a href="#LSBoostClassifier-307"><span class="linenos">307</span></a>                    <span class="p">),</span>
</span><span id="LSBoostClassifier-308"><a href="#LSBoostClassifier-308"><span class="linenos">308</span></a>                <span class="p">)</span>
</span><span id="LSBoostClassifier-309"><a href="#LSBoostClassifier-309"><span class="linenos">309</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier-310"><a href="#LSBoostClassifier-310"><span class="linenos">310</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="LSBoostClassifier-311"><a href="#LSBoostClassifier-311"><span class="linenos">311</span></a>            <span class="k">return</span> <span class="n">boosterc</span><span class="o">.</span><span class="n">predict_proba_booster_classifier</span><span class="p">(</span>
</span><span id="LSBoostClassifier-312"><a href="#LSBoostClassifier-312"><span class="linenos">312</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="LSBoostClassifier-313"><a href="#LSBoostClassifier-313"><span class="linenos">313</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier-314"><a href="#LSBoostClassifier-314"><span class="linenos">314</span></a>        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="LSBoostClassifier-315"><a href="#LSBoostClassifier-315"><span class="linenos">315</span></a>            <span class="k">return</span> <span class="n">_boosterc</span><span class="o">.</span><span class="n">predict_proba_booster_classifier</span><span class="p">(</span>
</span><span id="LSBoostClassifier-316"><a href="#LSBoostClassifier-316"><span class="linenos">316</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="LSBoostClassifier-317"><a href="#LSBoostClassifier-317"><span class="linenos">317</span></a>            <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>LSBoost classifier.</p>

<p>Attributes:</p>

<pre><code>n_estimators: int
    number of boosting iterations.

learning_rate: float
    controls the learning speed at training time.

n_hidden_features: int
    number of nodes in successive hidden layers.

reg_lambda: float
    L2 regularization parameter for successive errors in the optimizer
    (at training time).

alpha: float
    compromise between L1 and L2 regularization (must be in [0, 1]),
    for `solver` == 'enet'.

row_sample: float
    percentage of rows chosen from the training set.

col_sample: float
    percentage of columns chosen from the training set.

dropout: float
    percentage of nodes dropped from the training set.

tolerance: float
    controls early stopping in gradient descent (at training time).

direct_link: bool
    indicates whether the original features are included (True) in model's
    fitting or not (False).

verbose: int
    progress bar (yes = 1) or not (no = 0) (currently).

seed: int
    reproducibility seed for nodes_sim=='uniform', clustering and dropout.

backend: str
    type of backend; must be in ('cpu', 'gpu', 'tpu')

solver: str
    type of 'weak' learner; currently in ('ridge', 'lasso', 'enet').
    'enet' is a combination of 'ridge' and 'lasso' called Elastic Net.

activation: str
    activation function: currently 'relu', 'relu6', 'sigmoid', 'tanh'

n_clusters: int
    number of clusters for clustering the features

clustering_method: str
    clustering method: currently 'kmeans', 'gmm'

cluster_scaling: str
    scaling method for clustering: currently 'standard', 'robust', 'minmax'

degree: int
    degree of features interactions to include in the model

weights_distr: str
    distribution of weights for constructing the model's hidden layer;
    currently 'uniform', 'gaussian'
</code></pre>
</div>


                                <div id="LSBoostClassifier.fit" class="classattr">
                                            <input id="LSBoostClassifier.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="LSBoostClassifier.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LSBoostClassifier.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LSBoostClassifier.fit-168"><a href="#LSBoostClassifier.fit-168"><span class="linenos">168</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostClassifier.fit-169"><a href="#LSBoostClassifier.fit-169"><span class="linenos">169</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit Booster (classifier) to training data (X, y)</span>
</span><span id="LSBoostClassifier.fit-170"><a href="#LSBoostClassifier.fit-170"><span class="linenos">170</span></a>
</span><span id="LSBoostClassifier.fit-171"><a href="#LSBoostClassifier.fit-171"><span class="linenos">171</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostClassifier.fit-172"><a href="#LSBoostClassifier.fit-172"><span class="linenos">172</span></a>
</span><span id="LSBoostClassifier.fit-173"><a href="#LSBoostClassifier.fit-173"><span class="linenos">173</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostClassifier.fit-174"><a href="#LSBoostClassifier.fit-174"><span class="linenos">174</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostClassifier.fit-175"><a href="#LSBoostClassifier.fit-175"><span class="linenos">175</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostClassifier.fit-176"><a href="#LSBoostClassifier.fit-176"><span class="linenos">176</span></a>
</span><span id="LSBoostClassifier.fit-177"><a href="#LSBoostClassifier.fit-177"><span class="linenos">177</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="LSBoostClassifier.fit-178"><a href="#LSBoostClassifier.fit-178"><span class="linenos">178</span></a><span class="sd">                Target values.</span>
</span><span id="LSBoostClassifier.fit-179"><a href="#LSBoostClassifier.fit-179"><span class="linenos">179</span></a>
</span><span id="LSBoostClassifier.fit-180"><a href="#LSBoostClassifier.fit-180"><span class="linenos">180</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="LSBoostClassifier.fit-181"><a href="#LSBoostClassifier.fit-181"><span class="linenos">181</span></a>
</span><span id="LSBoostClassifier.fit-182"><a href="#LSBoostClassifier.fit-182"><span class="linenos">182</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostClassifier.fit-183"><a href="#LSBoostClassifier.fit-183"><span class="linenos">183</span></a>
</span><span id="LSBoostClassifier.fit-184"><a href="#LSBoostClassifier.fit-184"><span class="linenos">184</span></a><span class="sd">            self: object.</span>
</span><span id="LSBoostClassifier.fit-185"><a href="#LSBoostClassifier.fit-185"><span class="linenos">185</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostClassifier.fit-186"><a href="#LSBoostClassifier.fit-186"><span class="linenos">186</span></a>
</span><span id="LSBoostClassifier.fit-187"><a href="#LSBoostClassifier.fit-187"><span class="linenos">187</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
</span><span id="LSBoostClassifier.fit-188"><a href="#LSBoostClassifier.fit-188"><span class="linenos">188</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
</span><span id="LSBoostClassifier.fit-189"><a href="#LSBoostClassifier.fit-189"><span class="linenos">189</span></a>
</span><span id="LSBoostClassifier.fit-190"><a href="#LSBoostClassifier.fit-190"><span class="linenos">190</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LSBoostClassifier.fit-191"><a href="#LSBoostClassifier.fit-191"><span class="linenos">191</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span>
</span><span id="LSBoostClassifier.fit-192"><a href="#LSBoostClassifier.fit-192"><span class="linenos">192</span></a>                <span class="n">degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="LSBoostClassifier.fit-193"><a href="#LSBoostClassifier.fit-193"><span class="linenos">193</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier.fit-194"><a href="#LSBoostClassifier.fit-194"><span class="linenos">194</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LSBoostClassifier.fit-195"><a href="#LSBoostClassifier.fit-195"><span class="linenos">195</span></a>
</span><span id="LSBoostClassifier.fit-196"><a href="#LSBoostClassifier.fit-196"><span class="linenos">196</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostClassifier.fit-197"><a href="#LSBoostClassifier.fit-197"><span class="linenos">197</span></a>            <span class="n">clustered_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="LSBoostClassifier.fit-198"><a href="#LSBoostClassifier.fit-198"><span class="linenos">198</span></a>                <span class="n">cluster</span><span class="p">(</span>
</span><span id="LSBoostClassifier.fit-199"><a href="#LSBoostClassifier.fit-199"><span class="linenos">199</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-200"><a href="#LSBoostClassifier.fit-200"><span class="linenos">200</span></a>                    <span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-201"><a href="#LSBoostClassifier.fit-201"><span class="linenos">201</span></a>                    <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-202"><a href="#LSBoostClassifier.fit-202"><span class="linenos">202</span></a>                    <span class="n">type_scaling</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-203"><a href="#LSBoostClassifier.fit-203"><span class="linenos">203</span></a>                    <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-204"><a href="#LSBoostClassifier.fit-204"><span class="linenos">204</span></a>                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-205"><a href="#LSBoostClassifier.fit-205"><span class="linenos">205</span></a>                <span class="p">)</span>
</span><span id="LSBoostClassifier.fit-206"><a href="#LSBoostClassifier.fit-206"><span class="linenos">206</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier.fit-207"><a href="#LSBoostClassifier.fit-207"><span class="linenos">207</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">clustered_X</span><span class="p">))</span>
</span><span id="LSBoostClassifier.fit-208"><a href="#LSBoostClassifier.fit-208"><span class="linenos">208</span></a>
</span><span id="LSBoostClassifier.fit-209"><a href="#LSBoostClassifier.fit-209"><span class="linenos">209</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="LSBoostClassifier.fit-210"><a href="#LSBoostClassifier.fit-210"><span class="linenos">210</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">boosterc</span><span class="o">.</span><span class="n">fit_booster_classifier</span><span class="p">(</span>
</span><span id="LSBoostClassifier.fit-211"><a href="#LSBoostClassifier.fit-211"><span class="linenos">211</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostClassifier.fit-212"><a href="#LSBoostClassifier.fit-212"><span class="linenos">212</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostClassifier.fit-213"><a href="#LSBoostClassifier.fit-213"><span class="linenos">213</span></a>                <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-214"><a href="#LSBoostClassifier.fit-214"><span class="linenos">214</span></a>                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-215"><a href="#LSBoostClassifier.fit-215"><span class="linenos">215</span></a>                <span class="n">n_hidden_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-216"><a href="#LSBoostClassifier.fit-216"><span class="linenos">216</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-217"><a href="#LSBoostClassifier.fit-217"><span class="linenos">217</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-218"><a href="#LSBoostClassifier.fit-218"><span class="linenos">218</span></a>                <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-219"><a href="#LSBoostClassifier.fit-219"><span class="linenos">219</span></a>                <span class="n">col_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-220"><a href="#LSBoostClassifier.fit-220"><span class="linenos">220</span></a>                <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-221"><a href="#LSBoostClassifier.fit-221"><span class="linenos">221</span></a>                <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-222"><a href="#LSBoostClassifier.fit-222"><span class="linenos">222</span></a>                <span class="n">direct_link</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-223"><a href="#LSBoostClassifier.fit-223"><span class="linenos">223</span></a>                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-224"><a href="#LSBoostClassifier.fit-224"><span class="linenos">224</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-225"><a href="#LSBoostClassifier.fit-225"><span class="linenos">225</span></a>                <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-226"><a href="#LSBoostClassifier.fit-226"><span class="linenos">226</span></a>                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-227"><a href="#LSBoostClassifier.fit-227"><span class="linenos">227</span></a>                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-228"><a href="#LSBoostClassifier.fit-228"><span class="linenos">228</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier.fit-229"><a href="#LSBoostClassifier.fit-229"><span class="linenos">229</span></a>        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="LSBoostClassifier.fit-230"><a href="#LSBoostClassifier.fit-230"><span class="linenos">230</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">_boosterc</span><span class="o">.</span><span class="n">fit_booster_classifier</span><span class="p">(</span>
</span><span id="LSBoostClassifier.fit-231"><a href="#LSBoostClassifier.fit-231"><span class="linenos">231</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostClassifier.fit-232"><a href="#LSBoostClassifier.fit-232"><span class="linenos">232</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostClassifier.fit-233"><a href="#LSBoostClassifier.fit-233"><span class="linenos">233</span></a>                <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-234"><a href="#LSBoostClassifier.fit-234"><span class="linenos">234</span></a>                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-235"><a href="#LSBoostClassifier.fit-235"><span class="linenos">235</span></a>                <span class="n">n_hidden_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-236"><a href="#LSBoostClassifier.fit-236"><span class="linenos">236</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-237"><a href="#LSBoostClassifier.fit-237"><span class="linenos">237</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-238"><a href="#LSBoostClassifier.fit-238"><span class="linenos">238</span></a>                <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-239"><a href="#LSBoostClassifier.fit-239"><span class="linenos">239</span></a>                <span class="n">col_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-240"><a href="#LSBoostClassifier.fit-240"><span class="linenos">240</span></a>                <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-241"><a href="#LSBoostClassifier.fit-241"><span class="linenos">241</span></a>                <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-242"><a href="#LSBoostClassifier.fit-242"><span class="linenos">242</span></a>                <span class="n">direct_link</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-243"><a href="#LSBoostClassifier.fit-243"><span class="linenos">243</span></a>                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-244"><a href="#LSBoostClassifier.fit-244"><span class="linenos">244</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-245"><a href="#LSBoostClassifier.fit-245"><span class="linenos">245</span></a>                <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-246"><a href="#LSBoostClassifier.fit-246"><span class="linenos">246</span></a>                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-247"><a href="#LSBoostClassifier.fit-247"><span class="linenos">247</span></a>                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
</span><span id="LSBoostClassifier.fit-248"><a href="#LSBoostClassifier.fit-248"><span class="linenos">248</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier.fit-249"><a href="#LSBoostClassifier.fit-249"><span class="linenos">249</span></a>
</span><span id="LSBoostClassifier.fit-250"><a href="#LSBoostClassifier.fit-250"><span class="linenos">250</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c1"># for compatibility with sklearn</span>
</span><span id="LSBoostClassifier.fit-251"><a href="#LSBoostClassifier.fit-251"><span class="linenos">251</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span>
</span><span id="LSBoostClassifier.fit-252"><a href="#LSBoostClassifier.fit-252"><span class="linenos">252</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit Booster (classifier) to training data (X, y)</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

y: array-like, shape = [n_samples]
    Target values.

**kwargs: additional parameters to be passed to self.cook_training_set.
</code></pre>

<p>Returns:</p>

<pre><code>self: object.
</code></pre>
</div>


                                </div>
                                <div id="LSBoostClassifier.predict" class="classattr">
                                            <input id="LSBoostClassifier.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="LSBoostClassifier.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LSBoostClassifier.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LSBoostClassifier.predict-254"><a href="#LSBoostClassifier.predict-254"><span class="linenos">254</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostClassifier.predict-255"><a href="#LSBoostClassifier.predict-255"><span class="linenos">255</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="LSBoostClassifier.predict-256"><a href="#LSBoostClassifier.predict-256"><span class="linenos">256</span></a>
</span><span id="LSBoostClassifier.predict-257"><a href="#LSBoostClassifier.predict-257"><span class="linenos">257</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostClassifier.predict-258"><a href="#LSBoostClassifier.predict-258"><span class="linenos">258</span></a>
</span><span id="LSBoostClassifier.predict-259"><a href="#LSBoostClassifier.predict-259"><span class="linenos">259</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostClassifier.predict-260"><a href="#LSBoostClassifier.predict-260"><span class="linenos">260</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostClassifier.predict-261"><a href="#LSBoostClassifier.predict-261"><span class="linenos">261</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostClassifier.predict-262"><a href="#LSBoostClassifier.predict-262"><span class="linenos">262</span></a>
</span><span id="LSBoostClassifier.predict-263"><a href="#LSBoostClassifier.predict-263"><span class="linenos">263</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="LSBoostClassifier.predict-264"><a href="#LSBoostClassifier.predict-264"><span class="linenos">264</span></a>
</span><span id="LSBoostClassifier.predict-265"><a href="#LSBoostClassifier.predict-265"><span class="linenos">265</span></a>
</span><span id="LSBoostClassifier.predict-266"><a href="#LSBoostClassifier.predict-266"><span class="linenos">266</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostClassifier.predict-267"><a href="#LSBoostClassifier.predict-267"><span class="linenos">267</span></a>
</span><span id="LSBoostClassifier.predict-268"><a href="#LSBoostClassifier.predict-268"><span class="linenos">268</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="LSBoostClassifier.predict-269"><a href="#LSBoostClassifier.predict-269"><span class="linenos">269</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostClassifier.predict-270"><a href="#LSBoostClassifier.predict-270"><span class="linenos">270</span></a>
</span><span id="LSBoostClassifier.predict-271"><a href="#LSBoostClassifier.predict-271"><span class="linenos">271</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to `predict_proba`
</code></pre>

<p>Returns:</p>

<pre><code>model predictions: {array-like}
</code></pre>
</div>


                                </div>
                                <div id="LSBoostClassifier.predict_proba" class="classattr">
                                            <input id="LSBoostClassifier.predict_proba-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict_proba</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="LSBoostClassifier.predict_proba-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LSBoostClassifier.predict_proba"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LSBoostClassifier.predict_proba-273"><a href="#LSBoostClassifier.predict_proba-273"><span class="linenos">273</span></a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostClassifier.predict_proba-274"><a href="#LSBoostClassifier.predict_proba-274"><span class="linenos">274</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict probabilities for test data X.</span>
</span><span id="LSBoostClassifier.predict_proba-275"><a href="#LSBoostClassifier.predict_proba-275"><span class="linenos">275</span></a>
</span><span id="LSBoostClassifier.predict_proba-276"><a href="#LSBoostClassifier.predict_proba-276"><span class="linenos">276</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostClassifier.predict_proba-277"><a href="#LSBoostClassifier.predict_proba-277"><span class="linenos">277</span></a>
</span><span id="LSBoostClassifier.predict_proba-278"><a href="#LSBoostClassifier.predict_proba-278"><span class="linenos">278</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostClassifier.predict_proba-279"><a href="#LSBoostClassifier.predict_proba-279"><span class="linenos">279</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostClassifier.predict_proba-280"><a href="#LSBoostClassifier.predict_proba-280"><span class="linenos">280</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostClassifier.predict_proba-281"><a href="#LSBoostClassifier.predict_proba-281"><span class="linenos">281</span></a>
</span><span id="LSBoostClassifier.predict_proba-282"><a href="#LSBoostClassifier.predict_proba-282"><span class="linenos">282</span></a><span class="sd">            **kwargs: additional parameters to be passed to</span>
</span><span id="LSBoostClassifier.predict_proba-283"><a href="#LSBoostClassifier.predict_proba-283"><span class="linenos">283</span></a><span class="sd">                self.cook_test_set</span>
</span><span id="LSBoostClassifier.predict_proba-284"><a href="#LSBoostClassifier.predict_proba-284"><span class="linenos">284</span></a>
</span><span id="LSBoostClassifier.predict_proba-285"><a href="#LSBoostClassifier.predict_proba-285"><span class="linenos">285</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostClassifier.predict_proba-286"><a href="#LSBoostClassifier.predict_proba-286"><span class="linenos">286</span></a>
</span><span id="LSBoostClassifier.predict_proba-287"><a href="#LSBoostClassifier.predict_proba-287"><span class="linenos">287</span></a><span class="sd">            probability estimates for test data: {array-like}</span>
</span><span id="LSBoostClassifier.predict_proba-288"><a href="#LSBoostClassifier.predict_proba-288"><span class="linenos">288</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostClassifier.predict_proba-289"><a href="#LSBoostClassifier.predict_proba-289"><span class="linenos">289</span></a>
</span><span id="LSBoostClassifier.predict_proba-290"><a href="#LSBoostClassifier.predict_proba-290"><span class="linenos">290</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
</span><span id="LSBoostClassifier.predict_proba-291"><a href="#LSBoostClassifier.predict_proba-291"><span class="linenos">291</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
</span><span id="LSBoostClassifier.predict_proba-292"><a href="#LSBoostClassifier.predict_proba-292"><span class="linenos">292</span></a>
</span><span id="LSBoostClassifier.predict_proba-293"><a href="#LSBoostClassifier.predict_proba-293"><span class="linenos">293</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostClassifier.predict_proba-294"><a href="#LSBoostClassifier.predict_proba-294"><span class="linenos">294</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LSBoostClassifier.predict_proba-295"><a href="#LSBoostClassifier.predict_proba-295"><span class="linenos">295</span></a>
</span><span id="LSBoostClassifier.predict_proba-296"><a href="#LSBoostClassifier.predict_proba-296"><span class="linenos">296</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostClassifier.predict_proba-297"><a href="#LSBoostClassifier.predict_proba-297"><span class="linenos">297</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="LSBoostClassifier.predict_proba-298"><a href="#LSBoostClassifier.predict_proba-298"><span class="linenos">298</span></a>                <span class="p">(</span>
</span><span id="LSBoostClassifier.predict_proba-299"><a href="#LSBoostClassifier.predict_proba-299"><span class="linenos">299</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostClassifier.predict_proba-300"><a href="#LSBoostClassifier.predict_proba-300"><span class="linenos">300</span></a>                    <span class="n">cluster</span><span class="p">(</span>
</span><span id="LSBoostClassifier.predict_proba-301"><a href="#LSBoostClassifier.predict_proba-301"><span class="linenos">301</span></a>                        <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostClassifier.predict_proba-302"><a href="#LSBoostClassifier.predict_proba-302"><span class="linenos">302</span></a>                        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="LSBoostClassifier.predict_proba-303"><a href="#LSBoostClassifier.predict_proba-303"><span class="linenos">303</span></a>                        <span class="n">scaler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span>
</span><span id="LSBoostClassifier.predict_proba-304"><a href="#LSBoostClassifier.predict_proba-304"><span class="linenos">304</span></a>                        <span class="n">label_encoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span>
</span><span id="LSBoostClassifier.predict_proba-305"><a href="#LSBoostClassifier.predict_proba-305"><span class="linenos">305</span></a>                        <span class="n">clusterer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span><span class="p">,</span>
</span><span id="LSBoostClassifier.predict_proba-306"><a href="#LSBoostClassifier.predict_proba-306"><span class="linenos">306</span></a>                        <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostClassifier.predict_proba-307"><a href="#LSBoostClassifier.predict_proba-307"><span class="linenos">307</span></a>                    <span class="p">),</span>
</span><span id="LSBoostClassifier.predict_proba-308"><a href="#LSBoostClassifier.predict_proba-308"><span class="linenos">308</span></a>                <span class="p">)</span>
</span><span id="LSBoostClassifier.predict_proba-309"><a href="#LSBoostClassifier.predict_proba-309"><span class="linenos">309</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier.predict_proba-310"><a href="#LSBoostClassifier.predict_proba-310"><span class="linenos">310</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="LSBoostClassifier.predict_proba-311"><a href="#LSBoostClassifier.predict_proba-311"><span class="linenos">311</span></a>            <span class="k">return</span> <span class="n">boosterc</span><span class="o">.</span><span class="n">predict_proba_booster_classifier</span><span class="p">(</span>
</span><span id="LSBoostClassifier.predict_proba-312"><a href="#LSBoostClassifier.predict_proba-312"><span class="linenos">312</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="LSBoostClassifier.predict_proba-313"><a href="#LSBoostClassifier.predict_proba-313"><span class="linenos">313</span></a>            <span class="p">)</span>
</span><span id="LSBoostClassifier.predict_proba-314"><a href="#LSBoostClassifier.predict_proba-314"><span class="linenos">314</span></a>        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="LSBoostClassifier.predict_proba-315"><a href="#LSBoostClassifier.predict_proba-315"><span class="linenos">315</span></a>            <span class="k">return</span> <span class="n">_boosterc</span><span class="o">.</span><span class="n">predict_proba_booster_classifier</span><span class="p">(</span>
</span><span id="LSBoostClassifier.predict_proba-316"><a href="#LSBoostClassifier.predict_proba-316"><span class="linenos">316</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="LSBoostClassifier.predict_proba-317"><a href="#LSBoostClassifier.predict_proba-317"><span class="linenos">317</span></a>            <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict probabilities for test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to
    self.cook_test_set
</code></pre>

<p>Returns:</p>

<pre><code>probability estimates for test data: {array-like}
</code></pre>
</div>


                                </div>
                        
                </section>
                <section id="StumpClassifier">
                            <input id="StumpClassifier-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">StumpClassifier</span><wbr>(<span class="base">sklearn.base.BaseEstimator</span>, <span class="base">sklearn.base.ClassifierMixin</span>):

                <label class="view-source-button" for="StumpClassifier-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#StumpClassifier"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="StumpClassifier-12"><a href="#StumpClassifier-12"><span class="linenos"> 12</span></a><span class="k">class</span> <span class="nc">StumpClassifier</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
</span><span id="StumpClassifier-13"><a href="#StumpClassifier-13"><span class="linenos"> 13</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Stump classifier.</span>
</span><span id="StumpClassifier-14"><a href="#StumpClassifier-14"><span class="linenos"> 14</span></a>
</span><span id="StumpClassifier-15"><a href="#StumpClassifier-15"><span class="linenos"> 15</span></a><span class="sd">    Attributes:</span>
</span><span id="StumpClassifier-16"><a href="#StumpClassifier-16"><span class="linenos"> 16</span></a>
</span><span id="StumpClassifier-17"><a href="#StumpClassifier-17"><span class="linenos"> 17</span></a><span class="sd">        bins: int</span>
</span><span id="StumpClassifier-18"><a href="#StumpClassifier-18"><span class="linenos"> 18</span></a><span class="sd">            Number of histogram bins; as in numpy.histogram.</span>
</span><span id="StumpClassifier-19"><a href="#StumpClassifier-19"><span class="linenos"> 19</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="StumpClassifier-20"><a href="#StumpClassifier-20"><span class="linenos"> 20</span></a>
</span><span id="StumpClassifier-21"><a href="#StumpClassifier-21"><span class="linenos"> 21</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">):</span>
</span><span id="StumpClassifier-22"><a href="#StumpClassifier-22"><span class="linenos"> 22</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bins</span> <span class="o">=</span> <span class="n">bins</span>
</span><span id="StumpClassifier-23"><a href="#StumpClassifier-23"><span class="linenos"> 23</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="StumpClassifier-24"><a href="#StumpClassifier-24"><span class="linenos"> 24</span></a>
</span><span id="StumpClassifier-25"><a href="#StumpClassifier-25"><span class="linenos"> 25</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="StumpClassifier-26"><a href="#StumpClassifier-26"><span class="linenos"> 26</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit Stump to training data (X, y)</span>
</span><span id="StumpClassifier-27"><a href="#StumpClassifier-27"><span class="linenos"> 27</span></a>
</span><span id="StumpClassifier-28"><a href="#StumpClassifier-28"><span class="linenos"> 28</span></a><span class="sd">        Args:</span>
</span><span id="StumpClassifier-29"><a href="#StumpClassifier-29"><span class="linenos"> 29</span></a>
</span><span id="StumpClassifier-30"><a href="#StumpClassifier-30"><span class="linenos"> 30</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="StumpClassifier-31"><a href="#StumpClassifier-31"><span class="linenos"> 31</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="StumpClassifier-32"><a href="#StumpClassifier-32"><span class="linenos"> 32</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="StumpClassifier-33"><a href="#StumpClassifier-33"><span class="linenos"> 33</span></a>
</span><span id="StumpClassifier-34"><a href="#StumpClassifier-34"><span class="linenos"> 34</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="StumpClassifier-35"><a href="#StumpClassifier-35"><span class="linenos"> 35</span></a><span class="sd">                Target values.</span>
</span><span id="StumpClassifier-36"><a href="#StumpClassifier-36"><span class="linenos"> 36</span></a>
</span><span id="StumpClassifier-37"><a href="#StumpClassifier-37"><span class="linenos"> 37</span></a><span class="sd">            sample_weight: array_like, shape = [n_samples]</span>
</span><span id="StumpClassifier-38"><a href="#StumpClassifier-38"><span class="linenos"> 38</span></a><span class="sd">                Observations weights.</span>
</span><span id="StumpClassifier-39"><a href="#StumpClassifier-39"><span class="linenos"> 39</span></a>
</span><span id="StumpClassifier-40"><a href="#StumpClassifier-40"><span class="linenos"> 40</span></a><span class="sd">        Returns:</span>
</span><span id="StumpClassifier-41"><a href="#StumpClassifier-41"><span class="linenos"> 41</span></a>
</span><span id="StumpClassifier-42"><a href="#StumpClassifier-42"><span class="linenos"> 42</span></a><span class="sd">            self: object.</span>
</span><span id="StumpClassifier-43"><a href="#StumpClassifier-43"><span class="linenos"> 43</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="StumpClassifier-44"><a href="#StumpClassifier-44"><span class="linenos"> 44</span></a>
</span><span id="StumpClassifier-45"><a href="#StumpClassifier-45"><span class="linenos"> 45</span></a>        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="StumpClassifier-46"><a href="#StumpClassifier-46"><span class="linenos"> 46</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">stumpc</span><span class="o">.</span><span class="n">fit_stump_classifier</span><span class="p">(</span>
</span><span id="StumpClassifier-47"><a href="#StumpClassifier-47"><span class="linenos"> 47</span></a>                <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier-48"><a href="#StumpClassifier-48"><span class="linenos"> 48</span></a>                <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier-49"><a href="#StumpClassifier-49"><span class="linenos"> 49</span></a>                <span class="n">bins</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bins</span><span class="p">,</span>
</span><span id="StumpClassifier-50"><a href="#StumpClassifier-50"><span class="linenos"> 50</span></a>            <span class="p">)</span>
</span><span id="StumpClassifier-51"><a href="#StumpClassifier-51"><span class="linenos"> 51</span></a>
</span><span id="StumpClassifier-52"><a href="#StumpClassifier-52"><span class="linenos"> 52</span></a>            <span class="k">return</span> <span class="bp">self</span>
</span><span id="StumpClassifier-53"><a href="#StumpClassifier-53"><span class="linenos"> 53</span></a>
</span><span id="StumpClassifier-54"><a href="#StumpClassifier-54"><span class="linenos"> 54</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">stumpc</span><span class="o">.</span><span class="n">fit_stump_classifier</span><span class="p">(</span>
</span><span id="StumpClassifier-55"><a href="#StumpClassifier-55"><span class="linenos"> 55</span></a>            <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier-56"><a href="#StumpClassifier-56"><span class="linenos"> 56</span></a>            <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier-57"><a href="#StumpClassifier-57"><span class="linenos"> 57</span></a>            <span class="n">sample_weight</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier-58"><a href="#StumpClassifier-58"><span class="linenos"> 58</span></a>            <span class="n">bins</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bins</span><span class="p">,</span>
</span><span id="StumpClassifier-59"><a href="#StumpClassifier-59"><span class="linenos"> 59</span></a>        <span class="p">)</span>
</span><span id="StumpClassifier-60"><a href="#StumpClassifier-60"><span class="linenos"> 60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c1"># for compatibility with sklearn</span>
</span><span id="StumpClassifier-61"><a href="#StumpClassifier-61"><span class="linenos"> 61</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="StumpClassifier-62"><a href="#StumpClassifier-62"><span class="linenos"> 62</span></a>
</span><span id="StumpClassifier-63"><a href="#StumpClassifier-63"><span class="linenos"> 63</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="StumpClassifier-64"><a href="#StumpClassifier-64"><span class="linenos"> 64</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="StumpClassifier-65"><a href="#StumpClassifier-65"><span class="linenos"> 65</span></a>
</span><span id="StumpClassifier-66"><a href="#StumpClassifier-66"><span class="linenos"> 66</span></a><span class="sd">        Args:</span>
</span><span id="StumpClassifier-67"><a href="#StumpClassifier-67"><span class="linenos"> 67</span></a>
</span><span id="StumpClassifier-68"><a href="#StumpClassifier-68"><span class="linenos"> 68</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="StumpClassifier-69"><a href="#StumpClassifier-69"><span class="linenos"> 69</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="StumpClassifier-70"><a href="#StumpClassifier-70"><span class="linenos"> 70</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="StumpClassifier-71"><a href="#StumpClassifier-71"><span class="linenos"> 71</span></a>
</span><span id="StumpClassifier-72"><a href="#StumpClassifier-72"><span class="linenos"> 72</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="StumpClassifier-73"><a href="#StumpClassifier-73"><span class="linenos"> 73</span></a>
</span><span id="StumpClassifier-74"><a href="#StumpClassifier-74"><span class="linenos"> 74</span></a>
</span><span id="StumpClassifier-75"><a href="#StumpClassifier-75"><span class="linenos"> 75</span></a><span class="sd">        Returns:</span>
</span><span id="StumpClassifier-76"><a href="#StumpClassifier-76"><span class="linenos"> 76</span></a>
</span><span id="StumpClassifier-77"><a href="#StumpClassifier-77"><span class="linenos"> 77</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="StumpClassifier-78"><a href="#StumpClassifier-78"><span class="linenos"> 78</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="StumpClassifier-79"><a href="#StumpClassifier-79"><span class="linenos"> 79</span></a>
</span><span id="StumpClassifier-80"><a href="#StumpClassifier-80"><span class="linenos"> 80</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="StumpClassifier-81"><a href="#StumpClassifier-81"><span class="linenos"> 81</span></a>
</span><span id="StumpClassifier-82"><a href="#StumpClassifier-82"><span class="linenos"> 82</span></a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="StumpClassifier-83"><a href="#StumpClassifier-83"><span class="linenos"> 83</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict probabilities for test data X.</span>
</span><span id="StumpClassifier-84"><a href="#StumpClassifier-84"><span class="linenos"> 84</span></a>
</span><span id="StumpClassifier-85"><a href="#StumpClassifier-85"><span class="linenos"> 85</span></a><span class="sd">        Args:</span>
</span><span id="StumpClassifier-86"><a href="#StumpClassifier-86"><span class="linenos"> 86</span></a>
</span><span id="StumpClassifier-87"><a href="#StumpClassifier-87"><span class="linenos"> 87</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="StumpClassifier-88"><a href="#StumpClassifier-88"><span class="linenos"> 88</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="StumpClassifier-89"><a href="#StumpClassifier-89"><span class="linenos"> 89</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="StumpClassifier-90"><a href="#StumpClassifier-90"><span class="linenos"> 90</span></a>
</span><span id="StumpClassifier-91"><a href="#StumpClassifier-91"><span class="linenos"> 91</span></a><span class="sd">            **kwargs: additional parameters to be passed to</span>
</span><span id="StumpClassifier-92"><a href="#StumpClassifier-92"><span class="linenos"> 92</span></a><span class="sd">                self.cook_test_set</span>
</span><span id="StumpClassifier-93"><a href="#StumpClassifier-93"><span class="linenos"> 93</span></a>
</span><span id="StumpClassifier-94"><a href="#StumpClassifier-94"><span class="linenos"> 94</span></a><span class="sd">        Returns:</span>
</span><span id="StumpClassifier-95"><a href="#StumpClassifier-95"><span class="linenos"> 95</span></a>
</span><span id="StumpClassifier-96"><a href="#StumpClassifier-96"><span class="linenos"> 96</span></a><span class="sd">            probability estimates for test data: {array-like}</span>
</span><span id="StumpClassifier-97"><a href="#StumpClassifier-97"><span class="linenos"> 97</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="StumpClassifier-98"><a href="#StumpClassifier-98"><span class="linenos"> 98</span></a>
</span><span id="StumpClassifier-99"><a href="#StumpClassifier-99"><span class="linenos"> 99</span></a>        <span class="k">return</span> <span class="n">stumpc</span><span class="o">.</span><span class="n">predict_proba_stump_classifier</span><span class="p">(</span>
</span><span id="StumpClassifier-100"><a href="#StumpClassifier-100"><span class="linenos">100</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="StumpClassifier-101"><a href="#StumpClassifier-101"><span class="linenos">101</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Stump classifier.</p>

<p>Attributes:</p>

<pre><code>bins: int
    Number of histogram bins; as in numpy.histogram.
</code></pre>
</div>


                                <div id="StumpClassifier.fit" class="classattr">
                                            <input id="StumpClassifier.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="StumpClassifier.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#StumpClassifier.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="StumpClassifier.fit-25"><a href="#StumpClassifier.fit-25"><span class="linenos">25</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="StumpClassifier.fit-26"><a href="#StumpClassifier.fit-26"><span class="linenos">26</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit Stump to training data (X, y)</span>
</span><span id="StumpClassifier.fit-27"><a href="#StumpClassifier.fit-27"><span class="linenos">27</span></a>
</span><span id="StumpClassifier.fit-28"><a href="#StumpClassifier.fit-28"><span class="linenos">28</span></a><span class="sd">        Args:</span>
</span><span id="StumpClassifier.fit-29"><a href="#StumpClassifier.fit-29"><span class="linenos">29</span></a>
</span><span id="StumpClassifier.fit-30"><a href="#StumpClassifier.fit-30"><span class="linenos">30</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="StumpClassifier.fit-31"><a href="#StumpClassifier.fit-31"><span class="linenos">31</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="StumpClassifier.fit-32"><a href="#StumpClassifier.fit-32"><span class="linenos">32</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="StumpClassifier.fit-33"><a href="#StumpClassifier.fit-33"><span class="linenos">33</span></a>
</span><span id="StumpClassifier.fit-34"><a href="#StumpClassifier.fit-34"><span class="linenos">34</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="StumpClassifier.fit-35"><a href="#StumpClassifier.fit-35"><span class="linenos">35</span></a><span class="sd">                Target values.</span>
</span><span id="StumpClassifier.fit-36"><a href="#StumpClassifier.fit-36"><span class="linenos">36</span></a>
</span><span id="StumpClassifier.fit-37"><a href="#StumpClassifier.fit-37"><span class="linenos">37</span></a><span class="sd">            sample_weight: array_like, shape = [n_samples]</span>
</span><span id="StumpClassifier.fit-38"><a href="#StumpClassifier.fit-38"><span class="linenos">38</span></a><span class="sd">                Observations weights.</span>
</span><span id="StumpClassifier.fit-39"><a href="#StumpClassifier.fit-39"><span class="linenos">39</span></a>
</span><span id="StumpClassifier.fit-40"><a href="#StumpClassifier.fit-40"><span class="linenos">40</span></a><span class="sd">        Returns:</span>
</span><span id="StumpClassifier.fit-41"><a href="#StumpClassifier.fit-41"><span class="linenos">41</span></a>
</span><span id="StumpClassifier.fit-42"><a href="#StumpClassifier.fit-42"><span class="linenos">42</span></a><span class="sd">            self: object.</span>
</span><span id="StumpClassifier.fit-43"><a href="#StumpClassifier.fit-43"><span class="linenos">43</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="StumpClassifier.fit-44"><a href="#StumpClassifier.fit-44"><span class="linenos">44</span></a>
</span><span id="StumpClassifier.fit-45"><a href="#StumpClassifier.fit-45"><span class="linenos">45</span></a>        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="StumpClassifier.fit-46"><a href="#StumpClassifier.fit-46"><span class="linenos">46</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">stumpc</span><span class="o">.</span><span class="n">fit_stump_classifier</span><span class="p">(</span>
</span><span id="StumpClassifier.fit-47"><a href="#StumpClassifier.fit-47"><span class="linenos">47</span></a>                <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier.fit-48"><a href="#StumpClassifier.fit-48"><span class="linenos">48</span></a>                <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier.fit-49"><a href="#StumpClassifier.fit-49"><span class="linenos">49</span></a>                <span class="n">bins</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bins</span><span class="p">,</span>
</span><span id="StumpClassifier.fit-50"><a href="#StumpClassifier.fit-50"><span class="linenos">50</span></a>            <span class="p">)</span>
</span><span id="StumpClassifier.fit-51"><a href="#StumpClassifier.fit-51"><span class="linenos">51</span></a>
</span><span id="StumpClassifier.fit-52"><a href="#StumpClassifier.fit-52"><span class="linenos">52</span></a>            <span class="k">return</span> <span class="bp">self</span>
</span><span id="StumpClassifier.fit-53"><a href="#StumpClassifier.fit-53"><span class="linenos">53</span></a>
</span><span id="StumpClassifier.fit-54"><a href="#StumpClassifier.fit-54"><span class="linenos">54</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">stumpc</span><span class="o">.</span><span class="n">fit_stump_classifier</span><span class="p">(</span>
</span><span id="StumpClassifier.fit-55"><a href="#StumpClassifier.fit-55"><span class="linenos">55</span></a>            <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier.fit-56"><a href="#StumpClassifier.fit-56"><span class="linenos">56</span></a>            <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier.fit-57"><a href="#StumpClassifier.fit-57"><span class="linenos">57</span></a>            <span class="n">sample_weight</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="StumpClassifier.fit-58"><a href="#StumpClassifier.fit-58"><span class="linenos">58</span></a>            <span class="n">bins</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bins</span><span class="p">,</span>
</span><span id="StumpClassifier.fit-59"><a href="#StumpClassifier.fit-59"><span class="linenos">59</span></a>        <span class="p">)</span>
</span><span id="StumpClassifier.fit-60"><a href="#StumpClassifier.fit-60"><span class="linenos">60</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>  <span class="c1"># for compatibility with sklearn</span>
</span><span id="StumpClassifier.fit-61"><a href="#StumpClassifier.fit-61"><span class="linenos">61</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit Stump to training data (X, y)</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

y: array-like, shape = [n_samples]
    Target values.

sample_weight: array_like, shape = [n_samples]
    Observations weights.
</code></pre>

<p>Returns:</p>

<pre><code>self: object.
</code></pre>
</div>


                                </div>
                                <div id="StumpClassifier.predict" class="classattr">
                                            <input id="StumpClassifier.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="StumpClassifier.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#StumpClassifier.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="StumpClassifier.predict-63"><a href="#StumpClassifier.predict-63"><span class="linenos">63</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="StumpClassifier.predict-64"><a href="#StumpClassifier.predict-64"><span class="linenos">64</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="StumpClassifier.predict-65"><a href="#StumpClassifier.predict-65"><span class="linenos">65</span></a>
</span><span id="StumpClassifier.predict-66"><a href="#StumpClassifier.predict-66"><span class="linenos">66</span></a><span class="sd">        Args:</span>
</span><span id="StumpClassifier.predict-67"><a href="#StumpClassifier.predict-67"><span class="linenos">67</span></a>
</span><span id="StumpClassifier.predict-68"><a href="#StumpClassifier.predict-68"><span class="linenos">68</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="StumpClassifier.predict-69"><a href="#StumpClassifier.predict-69"><span class="linenos">69</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="StumpClassifier.predict-70"><a href="#StumpClassifier.predict-70"><span class="linenos">70</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="StumpClassifier.predict-71"><a href="#StumpClassifier.predict-71"><span class="linenos">71</span></a>
</span><span id="StumpClassifier.predict-72"><a href="#StumpClassifier.predict-72"><span class="linenos">72</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="StumpClassifier.predict-73"><a href="#StumpClassifier.predict-73"><span class="linenos">73</span></a>
</span><span id="StumpClassifier.predict-74"><a href="#StumpClassifier.predict-74"><span class="linenos">74</span></a>
</span><span id="StumpClassifier.predict-75"><a href="#StumpClassifier.predict-75"><span class="linenos">75</span></a><span class="sd">        Returns:</span>
</span><span id="StumpClassifier.predict-76"><a href="#StumpClassifier.predict-76"><span class="linenos">76</span></a>
</span><span id="StumpClassifier.predict-77"><a href="#StumpClassifier.predict-77"><span class="linenos">77</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="StumpClassifier.predict-78"><a href="#StumpClassifier.predict-78"><span class="linenos">78</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="StumpClassifier.predict-79"><a href="#StumpClassifier.predict-79"><span class="linenos">79</span></a>
</span><span id="StumpClassifier.predict-80"><a href="#StumpClassifier.predict-80"><span class="linenos">80</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to `predict_proba`
</code></pre>

<p>Returns:</p>

<pre><code>model predictions: {array-like}
</code></pre>
</div>


                                </div>
                                <div id="StumpClassifier.predict_proba" class="classattr">
                                            <input id="StumpClassifier.predict_proba-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict_proba</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="StumpClassifier.predict_proba-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#StumpClassifier.predict_proba"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="StumpClassifier.predict_proba-82"><a href="#StumpClassifier.predict_proba-82"><span class="linenos"> 82</span></a>    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="StumpClassifier.predict_proba-83"><a href="#StumpClassifier.predict_proba-83"><span class="linenos"> 83</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict probabilities for test data X.</span>
</span><span id="StumpClassifier.predict_proba-84"><a href="#StumpClassifier.predict_proba-84"><span class="linenos"> 84</span></a>
</span><span id="StumpClassifier.predict_proba-85"><a href="#StumpClassifier.predict_proba-85"><span class="linenos"> 85</span></a><span class="sd">        Args:</span>
</span><span id="StumpClassifier.predict_proba-86"><a href="#StumpClassifier.predict_proba-86"><span class="linenos"> 86</span></a>
</span><span id="StumpClassifier.predict_proba-87"><a href="#StumpClassifier.predict_proba-87"><span class="linenos"> 87</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="StumpClassifier.predict_proba-88"><a href="#StumpClassifier.predict_proba-88"><span class="linenos"> 88</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="StumpClassifier.predict_proba-89"><a href="#StumpClassifier.predict_proba-89"><span class="linenos"> 89</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="StumpClassifier.predict_proba-90"><a href="#StumpClassifier.predict_proba-90"><span class="linenos"> 90</span></a>
</span><span id="StumpClassifier.predict_proba-91"><a href="#StumpClassifier.predict_proba-91"><span class="linenos"> 91</span></a><span class="sd">            **kwargs: additional parameters to be passed to</span>
</span><span id="StumpClassifier.predict_proba-92"><a href="#StumpClassifier.predict_proba-92"><span class="linenos"> 92</span></a><span class="sd">                self.cook_test_set</span>
</span><span id="StumpClassifier.predict_proba-93"><a href="#StumpClassifier.predict_proba-93"><span class="linenos"> 93</span></a>
</span><span id="StumpClassifier.predict_proba-94"><a href="#StumpClassifier.predict_proba-94"><span class="linenos"> 94</span></a><span class="sd">        Returns:</span>
</span><span id="StumpClassifier.predict_proba-95"><a href="#StumpClassifier.predict_proba-95"><span class="linenos"> 95</span></a>
</span><span id="StumpClassifier.predict_proba-96"><a href="#StumpClassifier.predict_proba-96"><span class="linenos"> 96</span></a><span class="sd">            probability estimates for test data: {array-like}</span>
</span><span id="StumpClassifier.predict_proba-97"><a href="#StumpClassifier.predict_proba-97"><span class="linenos"> 97</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="StumpClassifier.predict_proba-98"><a href="#StumpClassifier.predict_proba-98"><span class="linenos"> 98</span></a>
</span><span id="StumpClassifier.predict_proba-99"><a href="#StumpClassifier.predict_proba-99"><span class="linenos"> 99</span></a>        <span class="k">return</span> <span class="n">stumpc</span><span class="o">.</span><span class="n">predict_proba_stump_classifier</span><span class="p">(</span>
</span><span id="StumpClassifier.predict_proba-100"><a href="#StumpClassifier.predict_proba-100"><span class="linenos">100</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="StumpClassifier.predict_proba-101"><a href="#StumpClassifier.predict_proba-101"><span class="linenos">101</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict probabilities for test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to
    self.cook_test_set
</code></pre>

<p>Returns:</p>

<pre><code>probability estimates for test data: {array-like}
</code></pre>
</div>


                                </div>
                        
                </section>
                <section id="ElasticNetRegressor">
                            <input id="ElasticNetRegressor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ElasticNetRegressor</span><wbr>(<span class="base">sklearn.base.BaseEstimator</span>, <span class="base">sklearn.base.RegressorMixin</span>):

                <label class="view-source-button" for="ElasticNetRegressor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElasticNetRegressor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElasticNetRegressor-17"><a href="#ElasticNetRegressor-17"><span class="linenos">17</span></a><span class="k">class</span> <span class="nc">ElasticNetRegressor</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
</span><span id="ElasticNetRegressor-18"><a href="#ElasticNetRegressor-18"><span class="linenos">18</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Elasticnet.</span>
</span><span id="ElasticNetRegressor-19"><a href="#ElasticNetRegressor-19"><span class="linenos">19</span></a>
</span><span id="ElasticNetRegressor-20"><a href="#ElasticNetRegressor-20"><span class="linenos">20</span></a><span class="sd">    Attributes:</span>
</span><span id="ElasticNetRegressor-21"><a href="#ElasticNetRegressor-21"><span class="linenos">21</span></a>
</span><span id="ElasticNetRegressor-22"><a href="#ElasticNetRegressor-22"><span class="linenos">22</span></a><span class="sd">        reg_lambda: float</span>
</span><span id="ElasticNetRegressor-23"><a href="#ElasticNetRegressor-23"><span class="linenos">23</span></a><span class="sd">            regularization parameter.</span>
</span><span id="ElasticNetRegressor-24"><a href="#ElasticNetRegressor-24"><span class="linenos">24</span></a>
</span><span id="ElasticNetRegressor-25"><a href="#ElasticNetRegressor-25"><span class="linenos">25</span></a><span class="sd">        alpha: float</span>
</span><span id="ElasticNetRegressor-26"><a href="#ElasticNetRegressor-26"><span class="linenos">26</span></a><span class="sd">            compromise between L1 and L2 regularization (must be in [0, 1]),</span>
</span><span id="ElasticNetRegressor-27"><a href="#ElasticNetRegressor-27"><span class="linenos">27</span></a><span class="sd">            for `solver` == &#39;enet&#39;.</span>
</span><span id="ElasticNetRegressor-28"><a href="#ElasticNetRegressor-28"><span class="linenos">28</span></a>
</span><span id="ElasticNetRegressor-29"><a href="#ElasticNetRegressor-29"><span class="linenos">29</span></a><span class="sd">        backend: str</span>
</span><span id="ElasticNetRegressor-30"><a href="#ElasticNetRegressor-30"><span class="linenos">30</span></a><span class="sd">            type of backend; must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)</span>
</span><span id="ElasticNetRegressor-31"><a href="#ElasticNetRegressor-31"><span class="linenos">31</span></a>
</span><span id="ElasticNetRegressor-32"><a href="#ElasticNetRegressor-32"><span class="linenos">32</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ElasticNetRegressor-33"><a href="#ElasticNetRegressor-33"><span class="linenos">33</span></a>
</span><span id="ElasticNetRegressor-34"><a href="#ElasticNetRegressor-34"><span class="linenos">34</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
</span><span id="ElasticNetRegressor-35"><a href="#ElasticNetRegressor-35"><span class="linenos">35</span></a>        <span class="k">assert</span> <span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="ElasticNetRegressor-36"><a href="#ElasticNetRegressor-36"><span class="linenos">36</span></a>            <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="ElasticNetRegressor-37"><a href="#ElasticNetRegressor-37"><span class="linenos">37</span></a>            <span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
</span><span id="ElasticNetRegressor-38"><a href="#ElasticNetRegressor-38"><span class="linenos">38</span></a>            <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
</span><span id="ElasticNetRegressor-39"><a href="#ElasticNetRegressor-39"><span class="linenos">39</span></a>        <span class="p">),</span> <span class="s2">&quot;`backend` must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)&quot;</span>
</span><span id="ElasticNetRegressor-40"><a href="#ElasticNetRegressor-40"><span class="linenos">40</span></a>
</span><span id="ElasticNetRegressor-41"><a href="#ElasticNetRegressor-41"><span class="linenos">41</span></a>        <span class="n">sys_platform</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>
</span><span id="ElasticNetRegressor-42"><a href="#ElasticNetRegressor-42"><span class="linenos">42</span></a>
</span><span id="ElasticNetRegressor-43"><a href="#ElasticNetRegressor-43"><span class="linenos">43</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">sys_platform</span> <span class="o">==</span> <span class="s2">&quot;Windows&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="s2">&quot;tpu&quot;</span><span class="p">)):</span>
</span><span id="ElasticNetRegressor-44"><a href="#ElasticNetRegressor-44"><span class="linenos">44</span></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span id="ElasticNetRegressor-45"><a href="#ElasticNetRegressor-45"><span class="linenos">45</span></a>                <span class="s2">&quot;No GPU/TPU computing on Windows yet, backend set to &#39;cpu&#39;&quot;</span>
</span><span id="ElasticNetRegressor-46"><a href="#ElasticNetRegressor-46"><span class="linenos">46</span></a>            <span class="p">)</span>
</span><span id="ElasticNetRegressor-47"><a href="#ElasticNetRegressor-47"><span class="linenos">47</span></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
</span><span id="ElasticNetRegressor-48"><a href="#ElasticNetRegressor-48"><span class="linenos">48</span></a>
</span><span id="ElasticNetRegressor-49"><a href="#ElasticNetRegressor-49"><span class="linenos">49</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">reg_lambda</span>
</span><span id="ElasticNetRegressor-50"><a href="#ElasticNetRegressor-50"><span class="linenos">50</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span><span id="ElasticNetRegressor-51"><a href="#ElasticNetRegressor-51"><span class="linenos">51</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span>
</span><span id="ElasticNetRegressor-52"><a href="#ElasticNetRegressor-52"><span class="linenos">52</span></a>
</span><span id="ElasticNetRegressor-53"><a href="#ElasticNetRegressor-53"><span class="linenos">53</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ElasticNetRegressor-54"><a href="#ElasticNetRegressor-54"><span class="linenos">54</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit matrixops (classifier) to training data (X, y)</span>
</span><span id="ElasticNetRegressor-55"><a href="#ElasticNetRegressor-55"><span class="linenos">55</span></a>
</span><span id="ElasticNetRegressor-56"><a href="#ElasticNetRegressor-56"><span class="linenos">56</span></a><span class="sd">        Args:</span>
</span><span id="ElasticNetRegressor-57"><a href="#ElasticNetRegressor-57"><span class="linenos">57</span></a>
</span><span id="ElasticNetRegressor-58"><a href="#ElasticNetRegressor-58"><span class="linenos">58</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="ElasticNetRegressor-59"><a href="#ElasticNetRegressor-59"><span class="linenos">59</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="ElasticNetRegressor-60"><a href="#ElasticNetRegressor-60"><span class="linenos">60</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="ElasticNetRegressor-61"><a href="#ElasticNetRegressor-61"><span class="linenos">61</span></a>
</span><span id="ElasticNetRegressor-62"><a href="#ElasticNetRegressor-62"><span class="linenos">62</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="ElasticNetRegressor-63"><a href="#ElasticNetRegressor-63"><span class="linenos">63</span></a><span class="sd">                Target values.</span>
</span><span id="ElasticNetRegressor-64"><a href="#ElasticNetRegressor-64"><span class="linenos">64</span></a>
</span><span id="ElasticNetRegressor-65"><a href="#ElasticNetRegressor-65"><span class="linenos">65</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="ElasticNetRegressor-66"><a href="#ElasticNetRegressor-66"><span class="linenos">66</span></a>
</span><span id="ElasticNetRegressor-67"><a href="#ElasticNetRegressor-67"><span class="linenos">67</span></a><span class="sd">        Returns:</span>
</span><span id="ElasticNetRegressor-68"><a href="#ElasticNetRegressor-68"><span class="linenos">68</span></a>
</span><span id="ElasticNetRegressor-69"><a href="#ElasticNetRegressor-69"><span class="linenos">69</span></a><span class="sd">            self: object.</span>
</span><span id="ElasticNetRegressor-70"><a href="#ElasticNetRegressor-70"><span class="linenos">70</span></a>
</span><span id="ElasticNetRegressor-71"><a href="#ElasticNetRegressor-71"><span class="linenos">71</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElasticNetRegressor-72"><a href="#ElasticNetRegressor-72"><span class="linenos">72</span></a>        <span class="n">fit_result</span> <span class="o">=</span> <span class="n">fit_elasticnet</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="ElasticNetRegressor-73"><a href="#ElasticNetRegressor-73"><span class="linenos">73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">fit_result</span><span class="o">.</span><span class="n">coef_</span>
</span><span id="ElasticNetRegressor-74"><a href="#ElasticNetRegressor-74"><span class="linenos">74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_mean</span> <span class="o">=</span> <span class="n">fit_result</span><span class="o">.</span><span class="n">y_train_mean</span>
</span><span id="ElasticNetRegressor-75"><a href="#ElasticNetRegressor-75"><span class="linenos">75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">fit_result</span><span class="o">.</span><span class="n">scaler</span>
</span><span id="ElasticNetRegressor-76"><a href="#ElasticNetRegressor-76"><span class="linenos">76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">converged</span> <span class="o">=</span> <span class="n">fit_result</span><span class="o">.</span><span class="n">converged</span>
</span><span id="ElasticNetRegressor-77"><a href="#ElasticNetRegressor-77"><span class="linenos">77</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="ElasticNetRegressor-78"><a href="#ElasticNetRegressor-78"><span class="linenos">78</span></a>
</span><span id="ElasticNetRegressor-79"><a href="#ElasticNetRegressor-79"><span class="linenos">79</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ElasticNetRegressor-80"><a href="#ElasticNetRegressor-80"><span class="linenos">80</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="ElasticNetRegressor-81"><a href="#ElasticNetRegressor-81"><span class="linenos">81</span></a>
</span><span id="ElasticNetRegressor-82"><a href="#ElasticNetRegressor-82"><span class="linenos">82</span></a><span class="sd">        Args:</span>
</span><span id="ElasticNetRegressor-83"><a href="#ElasticNetRegressor-83"><span class="linenos">83</span></a>
</span><span id="ElasticNetRegressor-84"><a href="#ElasticNetRegressor-84"><span class="linenos">84</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="ElasticNetRegressor-85"><a href="#ElasticNetRegressor-85"><span class="linenos">85</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="ElasticNetRegressor-86"><a href="#ElasticNetRegressor-86"><span class="linenos">86</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="ElasticNetRegressor-87"><a href="#ElasticNetRegressor-87"><span class="linenos">87</span></a>
</span><span id="ElasticNetRegressor-88"><a href="#ElasticNetRegressor-88"><span class="linenos">88</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="ElasticNetRegressor-89"><a href="#ElasticNetRegressor-89"><span class="linenos">89</span></a>
</span><span id="ElasticNetRegressor-90"><a href="#ElasticNetRegressor-90"><span class="linenos">90</span></a><span class="sd">        Returns:</span>
</span><span id="ElasticNetRegressor-91"><a href="#ElasticNetRegressor-91"><span class="linenos">91</span></a>
</span><span id="ElasticNetRegressor-92"><a href="#ElasticNetRegressor-92"><span class="linenos">92</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="ElasticNetRegressor-93"><a href="#ElasticNetRegressor-93"><span class="linenos">93</span></a>
</span><span id="ElasticNetRegressor-94"><a href="#ElasticNetRegressor-94"><span class="linenos">94</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElasticNetRegressor-95"><a href="#ElasticNetRegressor-95"><span class="linenos">95</span></a>        <span class="k">return</span> <span class="n">predict_elasticnet</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Elasticnet.</p>

<p>Attributes:</p>

<pre><code>reg_lambda: float
    regularization parameter.

alpha: float
    compromise between L1 and L2 regularization (must be in [0, 1]),
    for `solver` == 'enet'.

backend: str
    type of backend; must be in ('cpu', 'gpu', 'tpu')
</code></pre>
</div>


                                <div id="ElasticNetRegressor.fit" class="classattr">
                                            <input id="ElasticNetRegressor.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ElasticNetRegressor.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElasticNetRegressor.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElasticNetRegressor.fit-53"><a href="#ElasticNetRegressor.fit-53"><span class="linenos">53</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ElasticNetRegressor.fit-54"><a href="#ElasticNetRegressor.fit-54"><span class="linenos">54</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit matrixops (classifier) to training data (X, y)</span>
</span><span id="ElasticNetRegressor.fit-55"><a href="#ElasticNetRegressor.fit-55"><span class="linenos">55</span></a>
</span><span id="ElasticNetRegressor.fit-56"><a href="#ElasticNetRegressor.fit-56"><span class="linenos">56</span></a><span class="sd">        Args:</span>
</span><span id="ElasticNetRegressor.fit-57"><a href="#ElasticNetRegressor.fit-57"><span class="linenos">57</span></a>
</span><span id="ElasticNetRegressor.fit-58"><a href="#ElasticNetRegressor.fit-58"><span class="linenos">58</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="ElasticNetRegressor.fit-59"><a href="#ElasticNetRegressor.fit-59"><span class="linenos">59</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="ElasticNetRegressor.fit-60"><a href="#ElasticNetRegressor.fit-60"><span class="linenos">60</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="ElasticNetRegressor.fit-61"><a href="#ElasticNetRegressor.fit-61"><span class="linenos">61</span></a>
</span><span id="ElasticNetRegressor.fit-62"><a href="#ElasticNetRegressor.fit-62"><span class="linenos">62</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="ElasticNetRegressor.fit-63"><a href="#ElasticNetRegressor.fit-63"><span class="linenos">63</span></a><span class="sd">                Target values.</span>
</span><span id="ElasticNetRegressor.fit-64"><a href="#ElasticNetRegressor.fit-64"><span class="linenos">64</span></a>
</span><span id="ElasticNetRegressor.fit-65"><a href="#ElasticNetRegressor.fit-65"><span class="linenos">65</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="ElasticNetRegressor.fit-66"><a href="#ElasticNetRegressor.fit-66"><span class="linenos">66</span></a>
</span><span id="ElasticNetRegressor.fit-67"><a href="#ElasticNetRegressor.fit-67"><span class="linenos">67</span></a><span class="sd">        Returns:</span>
</span><span id="ElasticNetRegressor.fit-68"><a href="#ElasticNetRegressor.fit-68"><span class="linenos">68</span></a>
</span><span id="ElasticNetRegressor.fit-69"><a href="#ElasticNetRegressor.fit-69"><span class="linenos">69</span></a><span class="sd">            self: object.</span>
</span><span id="ElasticNetRegressor.fit-70"><a href="#ElasticNetRegressor.fit-70"><span class="linenos">70</span></a>
</span><span id="ElasticNetRegressor.fit-71"><a href="#ElasticNetRegressor.fit-71"><span class="linenos">71</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElasticNetRegressor.fit-72"><a href="#ElasticNetRegressor.fit-72"><span class="linenos">72</span></a>        <span class="n">fit_result</span> <span class="o">=</span> <span class="n">fit_elasticnet</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="ElasticNetRegressor.fit-73"><a href="#ElasticNetRegressor.fit-73"><span class="linenos">73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">fit_result</span><span class="o">.</span><span class="n">coef_</span>
</span><span id="ElasticNetRegressor.fit-74"><a href="#ElasticNetRegressor.fit-74"><span class="linenos">74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_mean</span> <span class="o">=</span> <span class="n">fit_result</span><span class="o">.</span><span class="n">y_train_mean</span>
</span><span id="ElasticNetRegressor.fit-75"><a href="#ElasticNetRegressor.fit-75"><span class="linenos">75</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">fit_result</span><span class="o">.</span><span class="n">scaler</span>
</span><span id="ElasticNetRegressor.fit-76"><a href="#ElasticNetRegressor.fit-76"><span class="linenos">76</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">converged</span> <span class="o">=</span> <span class="n">fit_result</span><span class="o">.</span><span class="n">converged</span>
</span><span id="ElasticNetRegressor.fit-77"><a href="#ElasticNetRegressor.fit-77"><span class="linenos">77</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit matrixops (classifier) to training data (X, y)</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

y: array-like, shape = [n_samples]
    Target values.

**kwargs: additional parameters to be passed to self.cook_training_set.
</code></pre>

<p>Returns:</p>

<pre><code>self: object.
</code></pre>
</div>


                                </div>
                                <div id="ElasticNetRegressor.predict" class="classattr">
                                            <input id="ElasticNetRegressor.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ElasticNetRegressor.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ElasticNetRegressor.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ElasticNetRegressor.predict-79"><a href="#ElasticNetRegressor.predict-79"><span class="linenos">79</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ElasticNetRegressor.predict-80"><a href="#ElasticNetRegressor.predict-80"><span class="linenos">80</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="ElasticNetRegressor.predict-81"><a href="#ElasticNetRegressor.predict-81"><span class="linenos">81</span></a>
</span><span id="ElasticNetRegressor.predict-82"><a href="#ElasticNetRegressor.predict-82"><span class="linenos">82</span></a><span class="sd">        Args:</span>
</span><span id="ElasticNetRegressor.predict-83"><a href="#ElasticNetRegressor.predict-83"><span class="linenos">83</span></a>
</span><span id="ElasticNetRegressor.predict-84"><a href="#ElasticNetRegressor.predict-84"><span class="linenos">84</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="ElasticNetRegressor.predict-85"><a href="#ElasticNetRegressor.predict-85"><span class="linenos">85</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="ElasticNetRegressor.predict-86"><a href="#ElasticNetRegressor.predict-86"><span class="linenos">86</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="ElasticNetRegressor.predict-87"><a href="#ElasticNetRegressor.predict-87"><span class="linenos">87</span></a>
</span><span id="ElasticNetRegressor.predict-88"><a href="#ElasticNetRegressor.predict-88"><span class="linenos">88</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="ElasticNetRegressor.predict-89"><a href="#ElasticNetRegressor.predict-89"><span class="linenos">89</span></a>
</span><span id="ElasticNetRegressor.predict-90"><a href="#ElasticNetRegressor.predict-90"><span class="linenos">90</span></a><span class="sd">        Returns:</span>
</span><span id="ElasticNetRegressor.predict-91"><a href="#ElasticNetRegressor.predict-91"><span class="linenos">91</span></a>
</span><span id="ElasticNetRegressor.predict-92"><a href="#ElasticNetRegressor.predict-92"><span class="linenos">92</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="ElasticNetRegressor.predict-93"><a href="#ElasticNetRegressor.predict-93"><span class="linenos">93</span></a>
</span><span id="ElasticNetRegressor.predict-94"><a href="#ElasticNetRegressor.predict-94"><span class="linenos">94</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ElasticNetRegressor.predict-95"><a href="#ElasticNetRegressor.predict-95"><span class="linenos">95</span></a>        <span class="k">return</span> <span class="n">predict_elasticnet</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to `predict_proba`
</code></pre>

<p>Returns:</p>

<pre><code>model predictions: {array-like}
</code></pre>
</div>


                                </div>
                        
                </section>
                <section id="LassoRegressor">
                            <input id="LassoRegressor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">LassoRegressor</span><wbr>(<span class="base">sklearn.base.BaseEstimator</span>, <span class="base">sklearn.base.RegressorMixin</span>):

                <label class="view-source-button" for="LassoRegressor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LassoRegressor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LassoRegressor-22"><a href="#LassoRegressor-22"><span class="linenos"> 22</span></a><span class="k">class</span> <span class="nc">LassoRegressor</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
</span><span id="LassoRegressor-23"><a href="#LassoRegressor-23"><span class="linenos"> 23</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Lasso.</span>
</span><span id="LassoRegressor-24"><a href="#LassoRegressor-24"><span class="linenos"> 24</span></a>
</span><span id="LassoRegressor-25"><a href="#LassoRegressor-25"><span class="linenos"> 25</span></a><span class="sd">    Attributes:</span>
</span><span id="LassoRegressor-26"><a href="#LassoRegressor-26"><span class="linenos"> 26</span></a>
</span><span id="LassoRegressor-27"><a href="#LassoRegressor-27"><span class="linenos"> 27</span></a><span class="sd">        reg_lambda: float</span>
</span><span id="LassoRegressor-28"><a href="#LassoRegressor-28"><span class="linenos"> 28</span></a><span class="sd">            L1 regularization parameter.</span>
</span><span id="LassoRegressor-29"><a href="#LassoRegressor-29"><span class="linenos"> 29</span></a>
</span><span id="LassoRegressor-30"><a href="#LassoRegressor-30"><span class="linenos"> 30</span></a><span class="sd">        max_iter: int</span>
</span><span id="LassoRegressor-31"><a href="#LassoRegressor-31"><span class="linenos"> 31</span></a><span class="sd">            number of iterations of lasso shooting algorithm.</span>
</span><span id="LassoRegressor-32"><a href="#LassoRegressor-32"><span class="linenos"> 32</span></a>
</span><span id="LassoRegressor-33"><a href="#LassoRegressor-33"><span class="linenos"> 33</span></a><span class="sd">        tol: float</span>
</span><span id="LassoRegressor-34"><a href="#LassoRegressor-34"><span class="linenos"> 34</span></a><span class="sd">            tolerance for convergence of lasso shooting algorithm.</span>
</span><span id="LassoRegressor-35"><a href="#LassoRegressor-35"><span class="linenos"> 35</span></a>
</span><span id="LassoRegressor-36"><a href="#LassoRegressor-36"><span class="linenos"> 36</span></a><span class="sd">        backend: str</span>
</span><span id="LassoRegressor-37"><a href="#LassoRegressor-37"><span class="linenos"> 37</span></a><span class="sd">            type of backend; must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;).</span>
</span><span id="LassoRegressor-38"><a href="#LassoRegressor-38"><span class="linenos"> 38</span></a>
</span><span id="LassoRegressor-39"><a href="#LassoRegressor-39"><span class="linenos"> 39</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="LassoRegressor-40"><a href="#LassoRegressor-40"><span class="linenos"> 40</span></a>
</span><span id="LassoRegressor-41"><a href="#LassoRegressor-41"><span class="linenos"> 41</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
</span><span id="LassoRegressor-42"><a href="#LassoRegressor-42"><span class="linenos"> 42</span></a>        <span class="k">assert</span> <span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LassoRegressor-43"><a href="#LassoRegressor-43"><span class="linenos"> 43</span></a>            <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="LassoRegressor-44"><a href="#LassoRegressor-44"><span class="linenos"> 44</span></a>            <span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
</span><span id="LassoRegressor-45"><a href="#LassoRegressor-45"><span class="linenos"> 45</span></a>            <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
</span><span id="LassoRegressor-46"><a href="#LassoRegressor-46"><span class="linenos"> 46</span></a>        <span class="p">),</span> <span class="s2">&quot;`backend` must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)&quot;</span>
</span><span id="LassoRegressor-47"><a href="#LassoRegressor-47"><span class="linenos"> 47</span></a>
</span><span id="LassoRegressor-48"><a href="#LassoRegressor-48"><span class="linenos"> 48</span></a>        <span class="n">sys_platform</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>
</span><span id="LassoRegressor-49"><a href="#LassoRegressor-49"><span class="linenos"> 49</span></a>
</span><span id="LassoRegressor-50"><a href="#LassoRegressor-50"><span class="linenos"> 50</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">sys_platform</span> <span class="o">==</span> <span class="s2">&quot;Windows&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="s2">&quot;tpu&quot;</span><span class="p">)):</span>
</span><span id="LassoRegressor-51"><a href="#LassoRegressor-51"><span class="linenos"> 51</span></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span id="LassoRegressor-52"><a href="#LassoRegressor-52"><span class="linenos"> 52</span></a>                <span class="s2">&quot;No GPU/TPU computing on Windows yet, backend set to &#39;cpu&#39;&quot;</span>
</span><span id="LassoRegressor-53"><a href="#LassoRegressor-53"><span class="linenos"> 53</span></a>            <span class="p">)</span>
</span><span id="LassoRegressor-54"><a href="#LassoRegressor-54"><span class="linenos"> 54</span></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
</span><span id="LassoRegressor-55"><a href="#LassoRegressor-55"><span class="linenos"> 55</span></a>
</span><span id="LassoRegressor-56"><a href="#LassoRegressor-56"><span class="linenos"> 56</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">reg_lambda</span>
</span><span id="LassoRegressor-57"><a href="#LassoRegressor-57"><span class="linenos"> 57</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
</span><span id="LassoRegressor-58"><a href="#LassoRegressor-58"><span class="linenos"> 58</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
</span><span id="LassoRegressor-59"><a href="#LassoRegressor-59"><span class="linenos"> 59</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span>
</span><span id="LassoRegressor-60"><a href="#LassoRegressor-60"><span class="linenos"> 60</span></a>
</span><span id="LassoRegressor-61"><a href="#LassoRegressor-61"><span class="linenos"> 61</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LassoRegressor-62"><a href="#LassoRegressor-62"><span class="linenos"> 62</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit matrixops (classifier) to training data (X, y)</span>
</span><span id="LassoRegressor-63"><a href="#LassoRegressor-63"><span class="linenos"> 63</span></a>
</span><span id="LassoRegressor-64"><a href="#LassoRegressor-64"><span class="linenos"> 64</span></a><span class="sd">        Args:</span>
</span><span id="LassoRegressor-65"><a href="#LassoRegressor-65"><span class="linenos"> 65</span></a>
</span><span id="LassoRegressor-66"><a href="#LassoRegressor-66"><span class="linenos"> 66</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LassoRegressor-67"><a href="#LassoRegressor-67"><span class="linenos"> 67</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LassoRegressor-68"><a href="#LassoRegressor-68"><span class="linenos"> 68</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LassoRegressor-69"><a href="#LassoRegressor-69"><span class="linenos"> 69</span></a>
</span><span id="LassoRegressor-70"><a href="#LassoRegressor-70"><span class="linenos"> 70</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="LassoRegressor-71"><a href="#LassoRegressor-71"><span class="linenos"> 71</span></a><span class="sd">                Target values.</span>
</span><span id="LassoRegressor-72"><a href="#LassoRegressor-72"><span class="linenos"> 72</span></a>
</span><span id="LassoRegressor-73"><a href="#LassoRegressor-73"><span class="linenos"> 73</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="LassoRegressor-74"><a href="#LassoRegressor-74"><span class="linenos"> 74</span></a>
</span><span id="LassoRegressor-75"><a href="#LassoRegressor-75"><span class="linenos"> 75</span></a><span class="sd">        Returns:</span>
</span><span id="LassoRegressor-76"><a href="#LassoRegressor-76"><span class="linenos"> 76</span></a>
</span><span id="LassoRegressor-77"><a href="#LassoRegressor-77"><span class="linenos"> 77</span></a><span class="sd">            self: object.</span>
</span><span id="LassoRegressor-78"><a href="#LassoRegressor-78"><span class="linenos"> 78</span></a>
</span><span id="LassoRegressor-79"><a href="#LassoRegressor-79"><span class="linenos"> 79</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LassoRegressor-80"><a href="#LassoRegressor-80"><span class="linenos"> 80</span></a>
</span><span id="LassoRegressor-81"><a href="#LassoRegressor-81"><span class="linenos"> 81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="n">centered_y</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">center_response</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="LassoRegressor-82"><a href="#LassoRegressor-82"><span class="linenos"> 82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xm</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="LassoRegressor-83"><a href="#LassoRegressor-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="LassoRegressor-84"><a href="#LassoRegressor-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">xsd</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="LassoRegressor-85"><a href="#LassoRegressor-85"><span class="linenos"> 85</span></a>        <span class="n">X_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xm</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="LassoRegressor-86"><a href="#LassoRegressor-86"><span class="linenos"> 86</span></a>        <span class="n">XX</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">crossprod</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="LassoRegressor-87"><a href="#LassoRegressor-87"><span class="linenos"> 87</span></a>        <span class="n">Xy</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">crossprod</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">centered_y</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="LassoRegressor-88"><a href="#LassoRegressor-88"><span class="linenos"> 88</span></a>        <span class="n">XX2</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">XX</span>
</span><span id="LassoRegressor-89"><a href="#LassoRegressor-89"><span class="linenos"> 89</span></a>        <span class="n">Xy2</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Xy</span>
</span><span id="LassoRegressor-90"><a href="#LassoRegressor-90"><span class="linenos"> 90</span></a>
</span><span id="LassoRegressor-91"><a href="#LassoRegressor-91"><span class="linenos"> 91</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="LassoRegressor-92"><a href="#LassoRegressor-92"><span class="linenos"> 92</span></a>            <span class="c1"># beta0, _, _, _ = np.linalg.lstsq(X_, centered_y, rcond=None)</span>
</span><span id="LassoRegressor-93"><a href="#LassoRegressor-93"><span class="linenos"> 93</span></a>            <span class="n">beta0</span> <span class="o">=</span> <span class="n">get_beta</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">centered_y</span><span class="p">)</span>
</span><span id="LassoRegressor-94"><a href="#LassoRegressor-94"><span class="linenos"> 94</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LassoRegressor-95"><a href="#LassoRegressor-95"><span class="linenos"> 95</span></a>                <span class="n">res</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">get_beta_1D</span><span class="p">(</span>
</span><span id="LassoRegressor-96"><a href="#LassoRegressor-96"><span class="linenos"> 96</span></a>                    <span class="n">beta0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta0</span><span class="p">),</span>
</span><span id="LassoRegressor-97"><a href="#LassoRegressor-97"><span class="linenos"> 97</span></a>                    <span class="n">XX2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">XX2</span><span class="p">),</span>
</span><span id="LassoRegressor-98"><a href="#LassoRegressor-98"><span class="linenos"> 98</span></a>                    <span class="n">Xy2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xy2</span><span class="p">),</span>
</span><span id="LassoRegressor-99"><a href="#LassoRegressor-99"><span class="linenos"> 99</span></a>                    <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LassoRegressor-100"><a href="#LassoRegressor-100"><span class="linenos">100</span></a>                    <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="LassoRegressor-101"><a href="#LassoRegressor-101"><span class="linenos">101</span></a>                    <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
</span><span id="LassoRegressor-102"><a href="#LassoRegressor-102"><span class="linenos">102</span></a>                <span class="p">)</span>
</span><span id="LassoRegressor-103"><a href="#LassoRegressor-103"><span class="linenos">103</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LassoRegressor-104"><a href="#LassoRegressor-104"><span class="linenos">104</span></a>                <span class="k">return</span> <span class="bp">self</span>
</span><span id="LassoRegressor-105"><a href="#LassoRegressor-105"><span class="linenos">105</span></a>
</span><span id="LassoRegressor-106"><a href="#LassoRegressor-106"><span class="linenos">106</span></a>            <span class="n">res</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">get_beta_2D</span><span class="p">(</span>
</span><span id="LassoRegressor-107"><a href="#LassoRegressor-107"><span class="linenos">107</span></a>                <span class="n">beta0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta0</span><span class="p">),</span>
</span><span id="LassoRegressor-108"><a href="#LassoRegressor-108"><span class="linenos">108</span></a>                <span class="n">XX2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">XX2</span><span class="p">),</span>
</span><span id="LassoRegressor-109"><a href="#LassoRegressor-109"><span class="linenos">109</span></a>                <span class="n">Xy2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xy2</span><span class="p">),</span>
</span><span id="LassoRegressor-110"><a href="#LassoRegressor-110"><span class="linenos">110</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LassoRegressor-111"><a href="#LassoRegressor-111"><span class="linenos">111</span></a>                <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="LassoRegressor-112"><a href="#LassoRegressor-112"><span class="linenos">112</span></a>                <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
</span><span id="LassoRegressor-113"><a href="#LassoRegressor-113"><span class="linenos">113</span></a>            <span class="p">)</span>
</span><span id="LassoRegressor-114"><a href="#LassoRegressor-114"><span class="linenos">114</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LassoRegressor-115"><a href="#LassoRegressor-115"><span class="linenos">115</span></a>            <span class="k">return</span> <span class="bp">self</span>
</span><span id="LassoRegressor-116"><a href="#LassoRegressor-116"><span class="linenos">116</span></a>
</span><span id="LassoRegressor-117"><a href="#LassoRegressor-117"><span class="linenos">117</span></a>        <span class="n">invXX</span> <span class="o">=</span> <span class="n">jinv</span><span class="p">(</span><span class="n">XX</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span><span id="LassoRegressor-118"><a href="#LassoRegressor-118"><span class="linenos">118</span></a>        <span class="n">beta0</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">invXX</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="LassoRegressor-119"><a href="#LassoRegressor-119"><span class="linenos">119</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LassoRegressor-120"><a href="#LassoRegressor-120"><span class="linenos">120</span></a>            <span class="n">res</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">get_beta_1D</span><span class="p">(</span>
</span><span id="LassoRegressor-121"><a href="#LassoRegressor-121"><span class="linenos">121</span></a>                <span class="n">beta0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta0</span><span class="p">),</span>
</span><span id="LassoRegressor-122"><a href="#LassoRegressor-122"><span class="linenos">122</span></a>                <span class="n">XX2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">XX2</span><span class="p">),</span>
</span><span id="LassoRegressor-123"><a href="#LassoRegressor-123"><span class="linenos">123</span></a>                <span class="n">Xy2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xy2</span><span class="p">),</span>
</span><span id="LassoRegressor-124"><a href="#LassoRegressor-124"><span class="linenos">124</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LassoRegressor-125"><a href="#LassoRegressor-125"><span class="linenos">125</span></a>                <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="LassoRegressor-126"><a href="#LassoRegressor-126"><span class="linenos">126</span></a>                <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
</span><span id="LassoRegressor-127"><a href="#LassoRegressor-127"><span class="linenos">127</span></a>            <span class="p">)</span>
</span><span id="LassoRegressor-128"><a href="#LassoRegressor-128"><span class="linenos">128</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LassoRegressor-129"><a href="#LassoRegressor-129"><span class="linenos">129</span></a>            <span class="k">return</span> <span class="bp">self</span>
</span><span id="LassoRegressor-130"><a href="#LassoRegressor-130"><span class="linenos">130</span></a>
</span><span id="LassoRegressor-131"><a href="#LassoRegressor-131"><span class="linenos">131</span></a>        <span class="n">res</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">get_beta_2D</span><span class="p">(</span>
</span><span id="LassoRegressor-132"><a href="#LassoRegressor-132"><span class="linenos">132</span></a>            <span class="n">beta0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta0</span><span class="p">),</span>
</span><span id="LassoRegressor-133"><a href="#LassoRegressor-133"><span class="linenos">133</span></a>            <span class="n">XX2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">XX2</span><span class="p">),</span>
</span><span id="LassoRegressor-134"><a href="#LassoRegressor-134"><span class="linenos">134</span></a>            <span class="n">Xy2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xy2</span><span class="p">),</span>
</span><span id="LassoRegressor-135"><a href="#LassoRegressor-135"><span class="linenos">135</span></a>            <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LassoRegressor-136"><a href="#LassoRegressor-136"><span class="linenos">136</span></a>            <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="LassoRegressor-137"><a href="#LassoRegressor-137"><span class="linenos">137</span></a>            <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
</span><span id="LassoRegressor-138"><a href="#LassoRegressor-138"><span class="linenos">138</span></a>        <span class="p">)</span>
</span><span id="LassoRegressor-139"><a href="#LassoRegressor-139"><span class="linenos">139</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LassoRegressor-140"><a href="#LassoRegressor-140"><span class="linenos">140</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="LassoRegressor-141"><a href="#LassoRegressor-141"><span class="linenos">141</span></a>
</span><span id="LassoRegressor-142"><a href="#LassoRegressor-142"><span class="linenos">142</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LassoRegressor-143"><a href="#LassoRegressor-143"><span class="linenos">143</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="LassoRegressor-144"><a href="#LassoRegressor-144"><span class="linenos">144</span></a>
</span><span id="LassoRegressor-145"><a href="#LassoRegressor-145"><span class="linenos">145</span></a><span class="sd">        Args:</span>
</span><span id="LassoRegressor-146"><a href="#LassoRegressor-146"><span class="linenos">146</span></a>
</span><span id="LassoRegressor-147"><a href="#LassoRegressor-147"><span class="linenos">147</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LassoRegressor-148"><a href="#LassoRegressor-148"><span class="linenos">148</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LassoRegressor-149"><a href="#LassoRegressor-149"><span class="linenos">149</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LassoRegressor-150"><a href="#LassoRegressor-150"><span class="linenos">150</span></a>
</span><span id="LassoRegressor-151"><a href="#LassoRegressor-151"><span class="linenos">151</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="LassoRegressor-152"><a href="#LassoRegressor-152"><span class="linenos">152</span></a>
</span><span id="LassoRegressor-153"><a href="#LassoRegressor-153"><span class="linenos">153</span></a>
</span><span id="LassoRegressor-154"><a href="#LassoRegressor-154"><span class="linenos">154</span></a><span class="sd">        Returns:</span>
</span><span id="LassoRegressor-155"><a href="#LassoRegressor-155"><span class="linenos">155</span></a>
</span><span id="LassoRegressor-156"><a href="#LassoRegressor-156"><span class="linenos">156</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="LassoRegressor-157"><a href="#LassoRegressor-157"><span class="linenos">157</span></a>
</span><span id="LassoRegressor-158"><a href="#LassoRegressor-158"><span class="linenos">158</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LassoRegressor-159"><a href="#LassoRegressor-159"><span class="linenos">159</span></a>        <span class="n">X_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xm</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="LassoRegressor-160"><a href="#LassoRegressor-160"><span class="linenos">160</span></a>
</span><span id="LassoRegressor-161"><a href="#LassoRegressor-161"><span class="linenos">161</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="LassoRegressor-162"><a href="#LassoRegressor-162"><span class="linenos">162</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="LassoRegressor-163"><a href="#LassoRegressor-163"><span class="linenos">163</span></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="LassoRegressor-164"><a href="#LassoRegressor-164"><span class="linenos">164</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="LassoRegressor-165"><a href="#LassoRegressor-165"><span class="linenos">165</span></a>
</span><span id="LassoRegressor-166"><a href="#LassoRegressor-166"><span class="linenos">166</span></a>        <span class="c1"># if self.backend in (&quot;gpu&quot;, &quot;tpu&quot;):</span>
</span><span id="LassoRegressor-167"><a href="#LassoRegressor-167"><span class="linenos">167</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="LassoRegressor-168"><a href="#LassoRegressor-168"><span class="linenos">168</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="LassoRegressor-169"><a href="#LassoRegressor-169"><span class="linenos">169</span></a>                <span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="LassoRegressor-170"><a href="#LassoRegressor-170"><span class="linenos">170</span></a>            <span class="p">)</span>
</span><span id="LassoRegressor-171"><a href="#LassoRegressor-171"><span class="linenos">171</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="LassoRegressor-172"><a href="#LassoRegressor-172"><span class="linenos">172</span></a>            <span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="LassoRegressor-173"><a href="#LassoRegressor-173"><span class="linenos">173</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Lasso.</p>

<p>Attributes:</p>

<pre><code>reg_lambda: float
    L1 regularization parameter.

max_iter: int
    number of iterations of lasso shooting algorithm.

tol: float
    tolerance for convergence of lasso shooting algorithm.

backend: str
    type of backend; must be in ('cpu', 'gpu', 'tpu').
</code></pre>
</div>


                                <div id="LassoRegressor.fit" class="classattr">
                                            <input id="LassoRegressor.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="LassoRegressor.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LassoRegressor.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LassoRegressor.fit-61"><a href="#LassoRegressor.fit-61"><span class="linenos"> 61</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LassoRegressor.fit-62"><a href="#LassoRegressor.fit-62"><span class="linenos"> 62</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit matrixops (classifier) to training data (X, y)</span>
</span><span id="LassoRegressor.fit-63"><a href="#LassoRegressor.fit-63"><span class="linenos"> 63</span></a>
</span><span id="LassoRegressor.fit-64"><a href="#LassoRegressor.fit-64"><span class="linenos"> 64</span></a><span class="sd">        Args:</span>
</span><span id="LassoRegressor.fit-65"><a href="#LassoRegressor.fit-65"><span class="linenos"> 65</span></a>
</span><span id="LassoRegressor.fit-66"><a href="#LassoRegressor.fit-66"><span class="linenos"> 66</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LassoRegressor.fit-67"><a href="#LassoRegressor.fit-67"><span class="linenos"> 67</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LassoRegressor.fit-68"><a href="#LassoRegressor.fit-68"><span class="linenos"> 68</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LassoRegressor.fit-69"><a href="#LassoRegressor.fit-69"><span class="linenos"> 69</span></a>
</span><span id="LassoRegressor.fit-70"><a href="#LassoRegressor.fit-70"><span class="linenos"> 70</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="LassoRegressor.fit-71"><a href="#LassoRegressor.fit-71"><span class="linenos"> 71</span></a><span class="sd">                Target values.</span>
</span><span id="LassoRegressor.fit-72"><a href="#LassoRegressor.fit-72"><span class="linenos"> 72</span></a>
</span><span id="LassoRegressor.fit-73"><a href="#LassoRegressor.fit-73"><span class="linenos"> 73</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="LassoRegressor.fit-74"><a href="#LassoRegressor.fit-74"><span class="linenos"> 74</span></a>
</span><span id="LassoRegressor.fit-75"><a href="#LassoRegressor.fit-75"><span class="linenos"> 75</span></a><span class="sd">        Returns:</span>
</span><span id="LassoRegressor.fit-76"><a href="#LassoRegressor.fit-76"><span class="linenos"> 76</span></a>
</span><span id="LassoRegressor.fit-77"><a href="#LassoRegressor.fit-77"><span class="linenos"> 77</span></a><span class="sd">            self: object.</span>
</span><span id="LassoRegressor.fit-78"><a href="#LassoRegressor.fit-78"><span class="linenos"> 78</span></a>
</span><span id="LassoRegressor.fit-79"><a href="#LassoRegressor.fit-79"><span class="linenos"> 79</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LassoRegressor.fit-80"><a href="#LassoRegressor.fit-80"><span class="linenos"> 80</span></a>
</span><span id="LassoRegressor.fit-81"><a href="#LassoRegressor.fit-81"><span class="linenos"> 81</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="n">centered_y</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">center_response</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="LassoRegressor.fit-82"><a href="#LassoRegressor.fit-82"><span class="linenos"> 82</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xm</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="LassoRegressor.fit-83"><a href="#LassoRegressor.fit-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="LassoRegressor.fit-84"><a href="#LassoRegressor.fit-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">xsd</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="LassoRegressor.fit-85"><a href="#LassoRegressor.fit-85"><span class="linenos"> 85</span></a>        <span class="n">X_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xm</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="LassoRegressor.fit-86"><a href="#LassoRegressor.fit-86"><span class="linenos"> 86</span></a>        <span class="n">XX</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">crossprod</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="LassoRegressor.fit-87"><a href="#LassoRegressor.fit-87"><span class="linenos"> 87</span></a>        <span class="n">Xy</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">crossprod</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">centered_y</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="LassoRegressor.fit-88"><a href="#LassoRegressor.fit-88"><span class="linenos"> 88</span></a>        <span class="n">XX2</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">XX</span>
</span><span id="LassoRegressor.fit-89"><a href="#LassoRegressor.fit-89"><span class="linenos"> 89</span></a>        <span class="n">Xy2</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Xy</span>
</span><span id="LassoRegressor.fit-90"><a href="#LassoRegressor.fit-90"><span class="linenos"> 90</span></a>
</span><span id="LassoRegressor.fit-91"><a href="#LassoRegressor.fit-91"><span class="linenos"> 91</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="LassoRegressor.fit-92"><a href="#LassoRegressor.fit-92"><span class="linenos"> 92</span></a>            <span class="c1"># beta0, _, _, _ = np.linalg.lstsq(X_, centered_y, rcond=None)</span>
</span><span id="LassoRegressor.fit-93"><a href="#LassoRegressor.fit-93"><span class="linenos"> 93</span></a>            <span class="n">beta0</span> <span class="o">=</span> <span class="n">get_beta</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">centered_y</span><span class="p">)</span>
</span><span id="LassoRegressor.fit-94"><a href="#LassoRegressor.fit-94"><span class="linenos"> 94</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LassoRegressor.fit-95"><a href="#LassoRegressor.fit-95"><span class="linenos"> 95</span></a>                <span class="n">res</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">get_beta_1D</span><span class="p">(</span>
</span><span id="LassoRegressor.fit-96"><a href="#LassoRegressor.fit-96"><span class="linenos"> 96</span></a>                    <span class="n">beta0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta0</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-97"><a href="#LassoRegressor.fit-97"><span class="linenos"> 97</span></a>                    <span class="n">XX2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">XX2</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-98"><a href="#LassoRegressor.fit-98"><span class="linenos"> 98</span></a>                    <span class="n">Xy2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xy2</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-99"><a href="#LassoRegressor.fit-99"><span class="linenos"> 99</span></a>                    <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-100"><a href="#LassoRegressor.fit-100"><span class="linenos">100</span></a>                    <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-101"><a href="#LassoRegressor.fit-101"><span class="linenos">101</span></a>                    <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-102"><a href="#LassoRegressor.fit-102"><span class="linenos">102</span></a>                <span class="p">)</span>
</span><span id="LassoRegressor.fit-103"><a href="#LassoRegressor.fit-103"><span class="linenos">103</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LassoRegressor.fit-104"><a href="#LassoRegressor.fit-104"><span class="linenos">104</span></a>                <span class="k">return</span> <span class="bp">self</span>
</span><span id="LassoRegressor.fit-105"><a href="#LassoRegressor.fit-105"><span class="linenos">105</span></a>
</span><span id="LassoRegressor.fit-106"><a href="#LassoRegressor.fit-106"><span class="linenos">106</span></a>            <span class="n">res</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">get_beta_2D</span><span class="p">(</span>
</span><span id="LassoRegressor.fit-107"><a href="#LassoRegressor.fit-107"><span class="linenos">107</span></a>                <span class="n">beta0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta0</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-108"><a href="#LassoRegressor.fit-108"><span class="linenos">108</span></a>                <span class="n">XX2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">XX2</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-109"><a href="#LassoRegressor.fit-109"><span class="linenos">109</span></a>                <span class="n">Xy2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xy2</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-110"><a href="#LassoRegressor.fit-110"><span class="linenos">110</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-111"><a href="#LassoRegressor.fit-111"><span class="linenos">111</span></a>                <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-112"><a href="#LassoRegressor.fit-112"><span class="linenos">112</span></a>                <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-113"><a href="#LassoRegressor.fit-113"><span class="linenos">113</span></a>            <span class="p">)</span>
</span><span id="LassoRegressor.fit-114"><a href="#LassoRegressor.fit-114"><span class="linenos">114</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LassoRegressor.fit-115"><a href="#LassoRegressor.fit-115"><span class="linenos">115</span></a>            <span class="k">return</span> <span class="bp">self</span>
</span><span id="LassoRegressor.fit-116"><a href="#LassoRegressor.fit-116"><span class="linenos">116</span></a>
</span><span id="LassoRegressor.fit-117"><a href="#LassoRegressor.fit-117"><span class="linenos">117</span></a>        <span class="n">invXX</span> <span class="o">=</span> <span class="n">jinv</span><span class="p">(</span><span class="n">XX</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</span><span id="LassoRegressor.fit-118"><a href="#LassoRegressor.fit-118"><span class="linenos">118</span></a>        <span class="n">beta0</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">invXX</span><span class="p">,</span> <span class="n">Xy</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="LassoRegressor.fit-119"><a href="#LassoRegressor.fit-119"><span class="linenos">119</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LassoRegressor.fit-120"><a href="#LassoRegressor.fit-120"><span class="linenos">120</span></a>            <span class="n">res</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">get_beta_1D</span><span class="p">(</span>
</span><span id="LassoRegressor.fit-121"><a href="#LassoRegressor.fit-121"><span class="linenos">121</span></a>                <span class="n">beta0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta0</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-122"><a href="#LassoRegressor.fit-122"><span class="linenos">122</span></a>                <span class="n">XX2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">XX2</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-123"><a href="#LassoRegressor.fit-123"><span class="linenos">123</span></a>                <span class="n">Xy2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xy2</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-124"><a href="#LassoRegressor.fit-124"><span class="linenos">124</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-125"><a href="#LassoRegressor.fit-125"><span class="linenos">125</span></a>                <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-126"><a href="#LassoRegressor.fit-126"><span class="linenos">126</span></a>                <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-127"><a href="#LassoRegressor.fit-127"><span class="linenos">127</span></a>            <span class="p">)</span>
</span><span id="LassoRegressor.fit-128"><a href="#LassoRegressor.fit-128"><span class="linenos">128</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LassoRegressor.fit-129"><a href="#LassoRegressor.fit-129"><span class="linenos">129</span></a>            <span class="k">return</span> <span class="bp">self</span>
</span><span id="LassoRegressor.fit-130"><a href="#LassoRegressor.fit-130"><span class="linenos">130</span></a>
</span><span id="LassoRegressor.fit-131"><a href="#LassoRegressor.fit-131"><span class="linenos">131</span></a>        <span class="n">res</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">get_beta_2D</span><span class="p">(</span>
</span><span id="LassoRegressor.fit-132"><a href="#LassoRegressor.fit-132"><span class="linenos">132</span></a>            <span class="n">beta0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">beta0</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-133"><a href="#LassoRegressor.fit-133"><span class="linenos">133</span></a>            <span class="n">XX2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">XX2</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-134"><a href="#LassoRegressor.fit-134"><span class="linenos">134</span></a>            <span class="n">Xy2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Xy2</span><span class="p">),</span>
</span><span id="LassoRegressor.fit-135"><a href="#LassoRegressor.fit-135"><span class="linenos">135</span></a>            <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-136"><a href="#LassoRegressor.fit-136"><span class="linenos">136</span></a>            <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-137"><a href="#LassoRegressor.fit-137"><span class="linenos">137</span></a>            <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
</span><span id="LassoRegressor.fit-138"><a href="#LassoRegressor.fit-138"><span class="linenos">138</span></a>        <span class="p">)</span>
</span><span id="LassoRegressor.fit-139"><a href="#LassoRegressor.fit-139"><span class="linenos">139</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LassoRegressor.fit-140"><a href="#LassoRegressor.fit-140"><span class="linenos">140</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit matrixops (classifier) to training data (X, y)</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

y: array-like, shape = [n_samples]
    Target values.

**kwargs: additional parameters to be passed to self.cook_training_set.
</code></pre>

<p>Returns:</p>

<pre><code>self: object.
</code></pre>
</div>


                                </div>
                                <div id="LassoRegressor.predict" class="classattr">
                                            <input id="LassoRegressor.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="LassoRegressor.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LassoRegressor.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LassoRegressor.predict-142"><a href="#LassoRegressor.predict-142"><span class="linenos">142</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LassoRegressor.predict-143"><a href="#LassoRegressor.predict-143"><span class="linenos">143</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="LassoRegressor.predict-144"><a href="#LassoRegressor.predict-144"><span class="linenos">144</span></a>
</span><span id="LassoRegressor.predict-145"><a href="#LassoRegressor.predict-145"><span class="linenos">145</span></a><span class="sd">        Args:</span>
</span><span id="LassoRegressor.predict-146"><a href="#LassoRegressor.predict-146"><span class="linenos">146</span></a>
</span><span id="LassoRegressor.predict-147"><a href="#LassoRegressor.predict-147"><span class="linenos">147</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LassoRegressor.predict-148"><a href="#LassoRegressor.predict-148"><span class="linenos">148</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LassoRegressor.predict-149"><a href="#LassoRegressor.predict-149"><span class="linenos">149</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LassoRegressor.predict-150"><a href="#LassoRegressor.predict-150"><span class="linenos">150</span></a>
</span><span id="LassoRegressor.predict-151"><a href="#LassoRegressor.predict-151"><span class="linenos">151</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="LassoRegressor.predict-152"><a href="#LassoRegressor.predict-152"><span class="linenos">152</span></a>
</span><span id="LassoRegressor.predict-153"><a href="#LassoRegressor.predict-153"><span class="linenos">153</span></a>
</span><span id="LassoRegressor.predict-154"><a href="#LassoRegressor.predict-154"><span class="linenos">154</span></a><span class="sd">        Returns:</span>
</span><span id="LassoRegressor.predict-155"><a href="#LassoRegressor.predict-155"><span class="linenos">155</span></a>
</span><span id="LassoRegressor.predict-156"><a href="#LassoRegressor.predict-156"><span class="linenos">156</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="LassoRegressor.predict-157"><a href="#LassoRegressor.predict-157"><span class="linenos">157</span></a>
</span><span id="LassoRegressor.predict-158"><a href="#LassoRegressor.predict-158"><span class="linenos">158</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LassoRegressor.predict-159"><a href="#LassoRegressor.predict-159"><span class="linenos">159</span></a>        <span class="n">X_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xm</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="LassoRegressor.predict-160"><a href="#LassoRegressor.predict-160"><span class="linenos">160</span></a>
</span><span id="LassoRegressor.predict-161"><a href="#LassoRegressor.predict-161"><span class="linenos">161</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="LassoRegressor.predict-162"><a href="#LassoRegressor.predict-162"><span class="linenos">162</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="LassoRegressor.predict-163"><a href="#LassoRegressor.predict-163"><span class="linenos">163</span></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="LassoRegressor.predict-164"><a href="#LassoRegressor.predict-164"><span class="linenos">164</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="LassoRegressor.predict-165"><a href="#LassoRegressor.predict-165"><span class="linenos">165</span></a>
</span><span id="LassoRegressor.predict-166"><a href="#LassoRegressor.predict-166"><span class="linenos">166</span></a>        <span class="c1"># if self.backend in (&quot;gpu&quot;, &quot;tpu&quot;):</span>
</span><span id="LassoRegressor.predict-167"><a href="#LassoRegressor.predict-167"><span class="linenos">167</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="LassoRegressor.predict-168"><a href="#LassoRegressor.predict-168"><span class="linenos">168</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="LassoRegressor.predict-169"><a href="#LassoRegressor.predict-169"><span class="linenos">169</span></a>                <span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="LassoRegressor.predict-170"><a href="#LassoRegressor.predict-170"><span class="linenos">170</span></a>            <span class="p">)</span>
</span><span id="LassoRegressor.predict-171"><a href="#LassoRegressor.predict-171"><span class="linenos">171</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="LassoRegressor.predict-172"><a href="#LassoRegressor.predict-172"><span class="linenos">172</span></a>            <span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="LassoRegressor.predict-173"><a href="#LassoRegressor.predict-173"><span class="linenos">173</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to `predict_proba`
</code></pre>

<p>Returns:</p>

<pre><code>model predictions: {array-like}
</code></pre>
</div>


                                </div>
                        
                </section>
                <section id="LSBoostRegressor">
                            <input id="LSBoostRegressor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">LSBoostRegressor</span><wbr>(<span class="base">sklearn.base.BaseEstimator</span>, <span class="base">sklearn.base.RegressorMixin</span>):

                <label class="view-source-button" for="LSBoostRegressor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LSBoostRegressor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LSBoostRegressor-18"><a href="#LSBoostRegressor-18"><span class="linenos"> 18</span></a><span class="k">class</span> <span class="nc">LSBoostRegressor</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
</span><span id="LSBoostRegressor-19"><a href="#LSBoostRegressor-19"><span class="linenos"> 19</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;LSBoost regressor.</span>
</span><span id="LSBoostRegressor-20"><a href="#LSBoostRegressor-20"><span class="linenos"> 20</span></a>
</span><span id="LSBoostRegressor-21"><a href="#LSBoostRegressor-21"><span class="linenos"> 21</span></a><span class="sd">    Attributes:</span>
</span><span id="LSBoostRegressor-22"><a href="#LSBoostRegressor-22"><span class="linenos"> 22</span></a>
</span><span id="LSBoostRegressor-23"><a href="#LSBoostRegressor-23"><span class="linenos"> 23</span></a><span class="sd">        n_estimators: int</span>
</span><span id="LSBoostRegressor-24"><a href="#LSBoostRegressor-24"><span class="linenos"> 24</span></a><span class="sd">            number of boosting iterations.</span>
</span><span id="LSBoostRegressor-25"><a href="#LSBoostRegressor-25"><span class="linenos"> 25</span></a>
</span><span id="LSBoostRegressor-26"><a href="#LSBoostRegressor-26"><span class="linenos"> 26</span></a><span class="sd">        learning_rate: float</span>
</span><span id="LSBoostRegressor-27"><a href="#LSBoostRegressor-27"><span class="linenos"> 27</span></a><span class="sd">            controls the learning speed at training time.</span>
</span><span id="LSBoostRegressor-28"><a href="#LSBoostRegressor-28"><span class="linenos"> 28</span></a>
</span><span id="LSBoostRegressor-29"><a href="#LSBoostRegressor-29"><span class="linenos"> 29</span></a><span class="sd">        n_hidden_features: int</span>
</span><span id="LSBoostRegressor-30"><a href="#LSBoostRegressor-30"><span class="linenos"> 30</span></a><span class="sd">            number of nodes in successive hidden layers.</span>
</span><span id="LSBoostRegressor-31"><a href="#LSBoostRegressor-31"><span class="linenos"> 31</span></a>
</span><span id="LSBoostRegressor-32"><a href="#LSBoostRegressor-32"><span class="linenos"> 32</span></a><span class="sd">        reg_lambda: float</span>
</span><span id="LSBoostRegressor-33"><a href="#LSBoostRegressor-33"><span class="linenos"> 33</span></a><span class="sd">            L2 regularization parameter for successive errors in the optimizer</span>
</span><span id="LSBoostRegressor-34"><a href="#LSBoostRegressor-34"><span class="linenos"> 34</span></a><span class="sd">            (at training time).</span>
</span><span id="LSBoostRegressor-35"><a href="#LSBoostRegressor-35"><span class="linenos"> 35</span></a>
</span><span id="LSBoostRegressor-36"><a href="#LSBoostRegressor-36"><span class="linenos"> 36</span></a><span class="sd">        alpha: float</span>
</span><span id="LSBoostRegressor-37"><a href="#LSBoostRegressor-37"><span class="linenos"> 37</span></a><span class="sd">            compromise between L1 and L2 regularization (must be in [0, 1]),</span>
</span><span id="LSBoostRegressor-38"><a href="#LSBoostRegressor-38"><span class="linenos"> 38</span></a><span class="sd">            for `solver` == &#39;enet&#39;</span>
</span><span id="LSBoostRegressor-39"><a href="#LSBoostRegressor-39"><span class="linenos"> 39</span></a>
</span><span id="LSBoostRegressor-40"><a href="#LSBoostRegressor-40"><span class="linenos"> 40</span></a><span class="sd">        row_sample: float</span>
</span><span id="LSBoostRegressor-41"><a href="#LSBoostRegressor-41"><span class="linenos"> 41</span></a><span class="sd">            percentage of rows chosen from the training set.</span>
</span><span id="LSBoostRegressor-42"><a href="#LSBoostRegressor-42"><span class="linenos"> 42</span></a>
</span><span id="LSBoostRegressor-43"><a href="#LSBoostRegressor-43"><span class="linenos"> 43</span></a><span class="sd">        col_sample: float</span>
</span><span id="LSBoostRegressor-44"><a href="#LSBoostRegressor-44"><span class="linenos"> 44</span></a><span class="sd">            percentage of columns chosen from the training set.</span>
</span><span id="LSBoostRegressor-45"><a href="#LSBoostRegressor-45"><span class="linenos"> 45</span></a>
</span><span id="LSBoostRegressor-46"><a href="#LSBoostRegressor-46"><span class="linenos"> 46</span></a><span class="sd">        dropout: float</span>
</span><span id="LSBoostRegressor-47"><a href="#LSBoostRegressor-47"><span class="linenos"> 47</span></a><span class="sd">            percentage of nodes dropped from the training set.</span>
</span><span id="LSBoostRegressor-48"><a href="#LSBoostRegressor-48"><span class="linenos"> 48</span></a>
</span><span id="LSBoostRegressor-49"><a href="#LSBoostRegressor-49"><span class="linenos"> 49</span></a><span class="sd">        tolerance: float</span>
</span><span id="LSBoostRegressor-50"><a href="#LSBoostRegressor-50"><span class="linenos"> 50</span></a><span class="sd">            controls early stopping in gradient descent (at training time).</span>
</span><span id="LSBoostRegressor-51"><a href="#LSBoostRegressor-51"><span class="linenos"> 51</span></a>
</span><span id="LSBoostRegressor-52"><a href="#LSBoostRegressor-52"><span class="linenos"> 52</span></a><span class="sd">        direct_link: bool</span>
</span><span id="LSBoostRegressor-53"><a href="#LSBoostRegressor-53"><span class="linenos"> 53</span></a><span class="sd">            indicates whether the original features are included (True) in model&#39;s</span>
</span><span id="LSBoostRegressor-54"><a href="#LSBoostRegressor-54"><span class="linenos"> 54</span></a><span class="sd">            fitting or not (False).</span>
</span><span id="LSBoostRegressor-55"><a href="#LSBoostRegressor-55"><span class="linenos"> 55</span></a>
</span><span id="LSBoostRegressor-56"><a href="#LSBoostRegressor-56"><span class="linenos"> 56</span></a><span class="sd">        verbose: int</span>
</span><span id="LSBoostRegressor-57"><a href="#LSBoostRegressor-57"><span class="linenos"> 57</span></a><span class="sd">            progress bar (yes = 1) or not (no = 0) (currently).</span>
</span><span id="LSBoostRegressor-58"><a href="#LSBoostRegressor-58"><span class="linenos"> 58</span></a>
</span><span id="LSBoostRegressor-59"><a href="#LSBoostRegressor-59"><span class="linenos"> 59</span></a><span class="sd">        seed: int</span>
</span><span id="LSBoostRegressor-60"><a href="#LSBoostRegressor-60"><span class="linenos"> 60</span></a><span class="sd">            reproducibility seed for nodes_sim==&#39;uniform&#39;, clustering and dropout.</span>
</span><span id="LSBoostRegressor-61"><a href="#LSBoostRegressor-61"><span class="linenos"> 61</span></a>
</span><span id="LSBoostRegressor-62"><a href="#LSBoostRegressor-62"><span class="linenos"> 62</span></a><span class="sd">        backend: str</span>
</span><span id="LSBoostRegressor-63"><a href="#LSBoostRegressor-63"><span class="linenos"> 63</span></a><span class="sd">            type of backend; must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)</span>
</span><span id="LSBoostRegressor-64"><a href="#LSBoostRegressor-64"><span class="linenos"> 64</span></a>
</span><span id="LSBoostRegressor-65"><a href="#LSBoostRegressor-65"><span class="linenos"> 65</span></a><span class="sd">        solver: str</span>
</span><span id="LSBoostRegressor-66"><a href="#LSBoostRegressor-66"><span class="linenos"> 66</span></a><span class="sd">            type of &#39;weak&#39; learner; currently in (&#39;ridge&#39;, &#39;lasso&#39;)</span>
</span><span id="LSBoostRegressor-67"><a href="#LSBoostRegressor-67"><span class="linenos"> 67</span></a>
</span><span id="LSBoostRegressor-68"><a href="#LSBoostRegressor-68"><span class="linenos"> 68</span></a><span class="sd">        activation: str</span>
</span><span id="LSBoostRegressor-69"><a href="#LSBoostRegressor-69"><span class="linenos"> 69</span></a><span class="sd">            activation function: currently &#39;relu&#39;, &#39;relu6&#39;, &#39;sigmoid&#39;, &#39;tanh&#39;</span>
</span><span id="LSBoostRegressor-70"><a href="#LSBoostRegressor-70"><span class="linenos"> 70</span></a>
</span><span id="LSBoostRegressor-71"><a href="#LSBoostRegressor-71"><span class="linenos"> 71</span></a><span class="sd">        type_pi: str.</span>
</span><span id="LSBoostRegressor-72"><a href="#LSBoostRegressor-72"><span class="linenos"> 72</span></a><span class="sd">            type of prediction interval; currently &quot;kde&quot; (default) or &quot;bootstrap&quot;.</span>
</span><span id="LSBoostRegressor-73"><a href="#LSBoostRegressor-73"><span class="linenos"> 73</span></a><span class="sd">            Used only in `self.predict`, for `self.replications` &gt; 0 and `self.kernel`</span>
</span><span id="LSBoostRegressor-74"><a href="#LSBoostRegressor-74"><span class="linenos"> 74</span></a><span class="sd">            in (&#39;gaussian&#39;, &#39;tophat&#39;). Default is `None`.</span>
</span><span id="LSBoostRegressor-75"><a href="#LSBoostRegressor-75"><span class="linenos"> 75</span></a>
</span><span id="LSBoostRegressor-76"><a href="#LSBoostRegressor-76"><span class="linenos"> 76</span></a><span class="sd">        replications: int.</span>
</span><span id="LSBoostRegressor-77"><a href="#LSBoostRegressor-77"><span class="linenos"> 77</span></a><span class="sd">            number of replications (if needed) for predictive simulation.</span>
</span><span id="LSBoostRegressor-78"><a href="#LSBoostRegressor-78"><span class="linenos"> 78</span></a><span class="sd">            Used only in `self.predict`, for `self.kernel` in (&#39;gaussian&#39;,</span>
</span><span id="LSBoostRegressor-79"><a href="#LSBoostRegressor-79"><span class="linenos"> 79</span></a><span class="sd">            &#39;tophat&#39;) and `self.type_pi = &#39;kde&#39;`. Default is `None`.</span>
</span><span id="LSBoostRegressor-80"><a href="#LSBoostRegressor-80"><span class="linenos"> 80</span></a>
</span><span id="LSBoostRegressor-81"><a href="#LSBoostRegressor-81"><span class="linenos"> 81</span></a><span class="sd">        n_clusters: int</span>
</span><span id="LSBoostRegressor-82"><a href="#LSBoostRegressor-82"><span class="linenos"> 82</span></a><span class="sd">            number of clusters for clustering the features</span>
</span><span id="LSBoostRegressor-83"><a href="#LSBoostRegressor-83"><span class="linenos"> 83</span></a>
</span><span id="LSBoostRegressor-84"><a href="#LSBoostRegressor-84"><span class="linenos"> 84</span></a><span class="sd">        clustering_method: str</span>
</span><span id="LSBoostRegressor-85"><a href="#LSBoostRegressor-85"><span class="linenos"> 85</span></a><span class="sd">            clustering method: currently &#39;kmeans&#39;, &#39;gmm&#39;</span>
</span><span id="LSBoostRegressor-86"><a href="#LSBoostRegressor-86"><span class="linenos"> 86</span></a>
</span><span id="LSBoostRegressor-87"><a href="#LSBoostRegressor-87"><span class="linenos"> 87</span></a><span class="sd">        cluster_scaling: str</span>
</span><span id="LSBoostRegressor-88"><a href="#LSBoostRegressor-88"><span class="linenos"> 88</span></a><span class="sd">            scaling method for clustering: currently &#39;standard&#39;, &#39;robust&#39;, &#39;minmax&#39;</span>
</span><span id="LSBoostRegressor-89"><a href="#LSBoostRegressor-89"><span class="linenos"> 89</span></a>
</span><span id="LSBoostRegressor-90"><a href="#LSBoostRegressor-90"><span class="linenos"> 90</span></a><span class="sd">        degree: int</span>
</span><span id="LSBoostRegressor-91"><a href="#LSBoostRegressor-91"><span class="linenos"> 91</span></a><span class="sd">            degree of features interactions to include in the model</span>
</span><span id="LSBoostRegressor-92"><a href="#LSBoostRegressor-92"><span class="linenos"> 92</span></a>
</span><span id="LSBoostRegressor-93"><a href="#LSBoostRegressor-93"><span class="linenos"> 93</span></a><span class="sd">        weights_distr: str</span>
</span><span id="LSBoostRegressor-94"><a href="#LSBoostRegressor-94"><span class="linenos"> 94</span></a><span class="sd">            distribution of weights for constructing the model&#39;s hidden layer;</span>
</span><span id="LSBoostRegressor-95"><a href="#LSBoostRegressor-95"><span class="linenos"> 95</span></a><span class="sd">            either &#39;uniform&#39; or &#39;gaussian&#39;</span>
</span><span id="LSBoostRegressor-96"><a href="#LSBoostRegressor-96"><span class="linenos"> 96</span></a>
</span><span id="LSBoostRegressor-97"><a href="#LSBoostRegressor-97"><span class="linenos"> 97</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="LSBoostRegressor-98"><a href="#LSBoostRegressor-98"><span class="linenos"> 98</span></a>
</span><span id="LSBoostRegressor-99"><a href="#LSBoostRegressor-99"><span class="linenos"> 99</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="LSBoostRegressor-100"><a href="#LSBoostRegressor-100"><span class="linenos">100</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LSBoostRegressor-101"><a href="#LSBoostRegressor-101"><span class="linenos">101</span></a>        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="LSBoostRegressor-102"><a href="#LSBoostRegressor-102"><span class="linenos">102</span></a>        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="LSBoostRegressor-103"><a href="#LSBoostRegressor-103"><span class="linenos">103</span></a>        <span class="n">n_hidden_features</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span><span id="LSBoostRegressor-104"><a href="#LSBoostRegressor-104"><span class="linenos">104</span></a>        <span class="n">reg_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span><span id="LSBoostRegressor-105"><a href="#LSBoostRegressor-105"><span class="linenos">105</span></a>        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
</span><span id="LSBoostRegressor-106"><a href="#LSBoostRegressor-106"><span class="linenos">106</span></a>        <span class="n">row_sample</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LSBoostRegressor-107"><a href="#LSBoostRegressor-107"><span class="linenos">107</span></a>        <span class="n">col_sample</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LSBoostRegressor-108"><a href="#LSBoostRegressor-108"><span class="linenos">108</span></a>        <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="LSBoostRegressor-109"><a href="#LSBoostRegressor-109"><span class="linenos">109</span></a>        <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
</span><span id="LSBoostRegressor-110"><a href="#LSBoostRegressor-110"><span class="linenos">110</span></a>        <span class="n">direct_link</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LSBoostRegressor-111"><a href="#LSBoostRegressor-111"><span class="linenos">111</span></a>        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LSBoostRegressor-112"><a href="#LSBoostRegressor-112"><span class="linenos">112</span></a>        <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
</span><span id="LSBoostRegressor-113"><a href="#LSBoostRegressor-113"><span class="linenos">113</span></a>        <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-114"><a href="#LSBoostRegressor-114"><span class="linenos">114</span></a>        <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;ridge&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-115"><a href="#LSBoostRegressor-115"><span class="linenos">115</span></a>        <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-116"><a href="#LSBoostRegressor-116"><span class="linenos">116</span></a>        <span class="n">type_pi</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="LSBoostRegressor-117"><a href="#LSBoostRegressor-117"><span class="linenos">117</span></a>        <span class="n">replications</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="LSBoostRegressor-118"><a href="#LSBoostRegressor-118"><span class="linenos">118</span></a>        <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="LSBoostRegressor-119"><a href="#LSBoostRegressor-119"><span class="linenos">119</span></a>        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="LSBoostRegressor-120"><a href="#LSBoostRegressor-120"><span class="linenos">120</span></a>        <span class="n">clustering_method</span><span class="o">=</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-121"><a href="#LSBoostRegressor-121"><span class="linenos">121</span></a>        <span class="n">cluster_scaling</span><span class="o">=</span><span class="s2">&quot;standard&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-122"><a href="#LSBoostRegressor-122"><span class="linenos">122</span></a>        <span class="n">degree</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="LSBoostRegressor-123"><a href="#LSBoostRegressor-123"><span class="linenos">123</span></a>        <span class="n">weights_distr</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-124"><a href="#LSBoostRegressor-124"><span class="linenos">124</span></a>    <span class="p">):</span>
</span><span id="LSBoostRegressor-125"><a href="#LSBoostRegressor-125"><span class="linenos">125</span></a>        <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostRegressor-126"><a href="#LSBoostRegressor-126"><span class="linenos">126</span></a>            <span class="k">assert</span> <span class="n">clustering_method</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostRegressor-127"><a href="#LSBoostRegressor-127"><span class="linenos">127</span></a>                <span class="s2">&quot;kmeans&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-128"><a href="#LSBoostRegressor-128"><span class="linenos">128</span></a>                <span class="s2">&quot;gmm&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-129"><a href="#LSBoostRegressor-129"><span class="linenos">129</span></a>            <span class="p">),</span> <span class="s2">&quot;`clustering_method` must be in (&#39;kmeans&#39;, &#39;gmm&#39;)&quot;</span>
</span><span id="LSBoostRegressor-130"><a href="#LSBoostRegressor-130"><span class="linenos">130</span></a>            <span class="k">assert</span> <span class="n">cluster_scaling</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostRegressor-131"><a href="#LSBoostRegressor-131"><span class="linenos">131</span></a>                <span class="s2">&quot;standard&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-132"><a href="#LSBoostRegressor-132"><span class="linenos">132</span></a>                <span class="s2">&quot;robust&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-133"><a href="#LSBoostRegressor-133"><span class="linenos">133</span></a>                <span class="s2">&quot;minmax&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-134"><a href="#LSBoostRegressor-134"><span class="linenos">134</span></a>            <span class="p">),</span> <span class="s2">&quot;`cluster_scaling` must be in (&#39;standard&#39;, &#39;robust&#39;, &#39;minmax&#39;)&quot;</span>
</span><span id="LSBoostRegressor-135"><a href="#LSBoostRegressor-135"><span class="linenos">135</span></a>
</span><span id="LSBoostRegressor-136"><a href="#LSBoostRegressor-136"><span class="linenos">136</span></a>        <span class="k">assert</span> <span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostRegressor-137"><a href="#LSBoostRegressor-137"><span class="linenos">137</span></a>            <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-138"><a href="#LSBoostRegressor-138"><span class="linenos">138</span></a>            <span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-139"><a href="#LSBoostRegressor-139"><span class="linenos">139</span></a>            <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-140"><a href="#LSBoostRegressor-140"><span class="linenos">140</span></a>        <span class="p">),</span> <span class="s2">&quot;`backend` must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)&quot;</span>
</span><span id="LSBoostRegressor-141"><a href="#LSBoostRegressor-141"><span class="linenos">141</span></a>
</span><span id="LSBoostRegressor-142"><a href="#LSBoostRegressor-142"><span class="linenos">142</span></a>        <span class="k">assert</span> <span class="n">solver</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostRegressor-143"><a href="#LSBoostRegressor-143"><span class="linenos">143</span></a>            <span class="s2">&quot;ridge&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-144"><a href="#LSBoostRegressor-144"><span class="linenos">144</span></a>            <span class="s2">&quot;lasso&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-145"><a href="#LSBoostRegressor-145"><span class="linenos">145</span></a>            <span class="s2">&quot;enet&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-146"><a href="#LSBoostRegressor-146"><span class="linenos">146</span></a>        <span class="p">),</span> <span class="s2">&quot;`solver` must be in (&#39;ridge&#39;, &#39;lasso&#39;, &#39;enet&#39;)&quot;</span>
</span><span id="LSBoostRegressor-147"><a href="#LSBoostRegressor-147"><span class="linenos">147</span></a>
</span><span id="LSBoostRegressor-148"><a href="#LSBoostRegressor-148"><span class="linenos">148</span></a>        <span class="n">sys_platform</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>
</span><span id="LSBoostRegressor-149"><a href="#LSBoostRegressor-149"><span class="linenos">149</span></a>
</span><span id="LSBoostRegressor-150"><a href="#LSBoostRegressor-150"><span class="linenos">150</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">sys_platform</span> <span class="o">==</span> <span class="s2">&quot;Windows&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="s2">&quot;tpu&quot;</span><span class="p">)):</span>
</span><span id="LSBoostRegressor-151"><a href="#LSBoostRegressor-151"><span class="linenos">151</span></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span id="LSBoostRegressor-152"><a href="#LSBoostRegressor-152"><span class="linenos">152</span></a>                <span class="s2">&quot;No GPU/TPU computing on Windows yet, backend set to &#39;cpu&#39;&quot;</span>
</span><span id="LSBoostRegressor-153"><a href="#LSBoostRegressor-153"><span class="linenos">153</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor-154"><a href="#LSBoostRegressor-154"><span class="linenos">154</span></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
</span><span id="LSBoostRegressor-155"><a href="#LSBoostRegressor-155"><span class="linenos">155</span></a>
</span><span id="LSBoostRegressor-156"><a href="#LSBoostRegressor-156"><span class="linenos">156</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
</span><span id="LSBoostRegressor-157"><a href="#LSBoostRegressor-157"><span class="linenos">157</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
</span><span id="LSBoostRegressor-158"><a href="#LSBoostRegressor-158"><span class="linenos">158</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span> <span class="o">=</span> <span class="n">n_hidden_features</span>
</span><span id="LSBoostRegressor-159"><a href="#LSBoostRegressor-159"><span class="linenos">159</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">reg_lambda</span>
</span><span id="LSBoostRegressor-160"><a href="#LSBoostRegressor-160"><span class="linenos">160</span></a>        <span class="k">assert</span> <span class="n">alpha</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">alpha</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;`alpha` must be in [0, 1]&quot;</span>
</span><span id="LSBoostRegressor-161"><a href="#LSBoostRegressor-161"><span class="linenos">161</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span><span id="LSBoostRegressor-162"><a href="#LSBoostRegressor-162"><span class="linenos">162</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span> <span class="o">=</span> <span class="n">row_sample</span>
</span><span id="LSBoostRegressor-163"><a href="#LSBoostRegressor-163"><span class="linenos">163</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span> <span class="o">=</span> <span class="n">col_sample</span>
</span><span id="LSBoostRegressor-164"><a href="#LSBoostRegressor-164"><span class="linenos">164</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
</span><span id="LSBoostRegressor-165"><a href="#LSBoostRegressor-165"><span class="linenos">165</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span> <span class="o">=</span> <span class="n">tolerance</span>
</span><span id="LSBoostRegressor-166"><a href="#LSBoostRegressor-166"><span class="linenos">166</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span> <span class="o">=</span> <span class="n">direct_link</span>
</span><span id="LSBoostRegressor-167"><a href="#LSBoostRegressor-167"><span class="linenos">167</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
</span><span id="LSBoostRegressor-168"><a href="#LSBoostRegressor-168"><span class="linenos">168</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
</span><span id="LSBoostRegressor-169"><a href="#LSBoostRegressor-169"><span class="linenos">169</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span>
</span><span id="LSBoostRegressor-170"><a href="#LSBoostRegressor-170"><span class="linenos">170</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LSBoostRegressor-171"><a href="#LSBoostRegressor-171"><span class="linenos">171</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>
</span><span id="LSBoostRegressor-172"><a href="#LSBoostRegressor-172"><span class="linenos">172</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
</span><span id="LSBoostRegressor-173"><a href="#LSBoostRegressor-173"><span class="linenos">173</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">type_pi</span> <span class="o">=</span> <span class="n">type_pi</span>
</span><span id="LSBoostRegressor-174"><a href="#LSBoostRegressor-174"><span class="linenos">174</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">replications</span> <span class="o">=</span> <span class="n">replications</span>
</span><span id="LSBoostRegressor-175"><a href="#LSBoostRegressor-175"><span class="linenos">175</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
</span><span id="LSBoostRegressor-176"><a href="#LSBoostRegressor-176"><span class="linenos">176</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="n">n_clusters</span>
</span><span id="LSBoostRegressor-177"><a href="#LSBoostRegressor-177"><span class="linenos">177</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span> <span class="o">=</span> <span class="n">clustering_method</span>
</span><span id="LSBoostRegressor-178"><a href="#LSBoostRegressor-178"><span class="linenos">178</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span> <span class="o">=</span> <span class="n">cluster_scaling</span>
</span><span id="LSBoostRegressor-179"><a href="#LSBoostRegressor-179"><span class="linenos">179</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span id="LSBoostRegressor-180"><a href="#LSBoostRegressor-180"><span class="linenos">180</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span>
</span><span id="LSBoostRegressor-181"><a href="#LSBoostRegressor-181"><span class="linenos">181</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LSBoostRegressor-182"><a href="#LSBoostRegressor-182"><span class="linenos">182</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distr</span> <span class="o">=</span> <span class="n">weights_distr</span>
</span><span id="LSBoostRegressor-183"><a href="#LSBoostRegressor-183"><span class="linenos">183</span></a>
</span><span id="LSBoostRegressor-184"><a href="#LSBoostRegressor-184"><span class="linenos">184</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostRegressor-185"><a href="#LSBoostRegressor-185"><span class="linenos">185</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit Booster (regressor) to training data (X, y)</span>
</span><span id="LSBoostRegressor-186"><a href="#LSBoostRegressor-186"><span class="linenos">186</span></a>
</span><span id="LSBoostRegressor-187"><a href="#LSBoostRegressor-187"><span class="linenos">187</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostRegressor-188"><a href="#LSBoostRegressor-188"><span class="linenos">188</span></a>
</span><span id="LSBoostRegressor-189"><a href="#LSBoostRegressor-189"><span class="linenos">189</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostRegressor-190"><a href="#LSBoostRegressor-190"><span class="linenos">190</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostRegressor-191"><a href="#LSBoostRegressor-191"><span class="linenos">191</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostRegressor-192"><a href="#LSBoostRegressor-192"><span class="linenos">192</span></a>
</span><span id="LSBoostRegressor-193"><a href="#LSBoostRegressor-193"><span class="linenos">193</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="LSBoostRegressor-194"><a href="#LSBoostRegressor-194"><span class="linenos">194</span></a><span class="sd">               Target values.</span>
</span><span id="LSBoostRegressor-195"><a href="#LSBoostRegressor-195"><span class="linenos">195</span></a>
</span><span id="LSBoostRegressor-196"><a href="#LSBoostRegressor-196"><span class="linenos">196</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="LSBoostRegressor-197"><a href="#LSBoostRegressor-197"><span class="linenos">197</span></a>
</span><span id="LSBoostRegressor-198"><a href="#LSBoostRegressor-198"><span class="linenos">198</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostRegressor-199"><a href="#LSBoostRegressor-199"><span class="linenos">199</span></a>
</span><span id="LSBoostRegressor-200"><a href="#LSBoostRegressor-200"><span class="linenos">200</span></a><span class="sd">            self: object.</span>
</span><span id="LSBoostRegressor-201"><a href="#LSBoostRegressor-201"><span class="linenos">201</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostRegressor-202"><a href="#LSBoostRegressor-202"><span class="linenos">202</span></a>
</span><span id="LSBoostRegressor-203"><a href="#LSBoostRegressor-203"><span class="linenos">203</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
</span><span id="LSBoostRegressor-204"><a href="#LSBoostRegressor-204"><span class="linenos">204</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
</span><span id="LSBoostRegressor-205"><a href="#LSBoostRegressor-205"><span class="linenos">205</span></a>
</span><span id="LSBoostRegressor-206"><a href="#LSBoostRegressor-206"><span class="linenos">206</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LSBoostRegressor-207"><a href="#LSBoostRegressor-207"><span class="linenos">207</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span>
</span><span id="LSBoostRegressor-208"><a href="#LSBoostRegressor-208"><span class="linenos">208</span></a>                <span class="n">degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="LSBoostRegressor-209"><a href="#LSBoostRegressor-209"><span class="linenos">209</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor-210"><a href="#LSBoostRegressor-210"><span class="linenos">210</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LSBoostRegressor-211"><a href="#LSBoostRegressor-211"><span class="linenos">211</span></a>
</span><span id="LSBoostRegressor-212"><a href="#LSBoostRegressor-212"><span class="linenos">212</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostRegressor-213"><a href="#LSBoostRegressor-213"><span class="linenos">213</span></a>            <span class="n">clustered_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="LSBoostRegressor-214"><a href="#LSBoostRegressor-214"><span class="linenos">214</span></a>                <span class="n">cluster</span><span class="p">(</span>
</span><span id="LSBoostRegressor-215"><a href="#LSBoostRegressor-215"><span class="linenos">215</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostRegressor-216"><a href="#LSBoostRegressor-216"><span class="linenos">216</span></a>                    <span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span>
</span><span id="LSBoostRegressor-217"><a href="#LSBoostRegressor-217"><span class="linenos">217</span></a>                    <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span><span class="p">,</span>
</span><span id="LSBoostRegressor-218"><a href="#LSBoostRegressor-218"><span class="linenos">218</span></a>                    <span class="n">type_scaling</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span><span class="p">,</span>
</span><span id="LSBoostRegressor-219"><a href="#LSBoostRegressor-219"><span class="linenos">219</span></a>                    <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="LSBoostRegressor-220"><a href="#LSBoostRegressor-220"><span class="linenos">220</span></a>                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostRegressor-221"><a href="#LSBoostRegressor-221"><span class="linenos">221</span></a>                <span class="p">)</span>
</span><span id="LSBoostRegressor-222"><a href="#LSBoostRegressor-222"><span class="linenos">222</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor-223"><a href="#LSBoostRegressor-223"><span class="linenos">223</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">clustered_X</span><span class="p">))</span>
</span><span id="LSBoostRegressor-224"><a href="#LSBoostRegressor-224"><span class="linenos">224</span></a>
</span><span id="LSBoostRegressor-225"><a href="#LSBoostRegressor-225"><span class="linenos">225</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="LSBoostRegressor-226"><a href="#LSBoostRegressor-226"><span class="linenos">226</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">boosterc</span><span class="o">.</span><span class="n">fit_booster_regressor</span><span class="p">(</span>
</span><span id="LSBoostRegressor-227"><a href="#LSBoostRegressor-227"><span class="linenos">227</span></a>                <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostRegressor-228"><a href="#LSBoostRegressor-228"><span class="linenos">228</span></a>                <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostRegressor-229"><a href="#LSBoostRegressor-229"><span class="linenos">229</span></a>                <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="LSBoostRegressor-230"><a href="#LSBoostRegressor-230"><span class="linenos">230</span></a>                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LSBoostRegressor-231"><a href="#LSBoostRegressor-231"><span class="linenos">231</span></a>                <span class="n">n_hidden_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span><span class="p">,</span>
</span><span id="LSBoostRegressor-232"><a href="#LSBoostRegressor-232"><span class="linenos">232</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LSBoostRegressor-233"><a href="#LSBoostRegressor-233"><span class="linenos">233</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="LSBoostRegressor-234"><a href="#LSBoostRegressor-234"><span class="linenos">234</span></a>                <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span>
</span><span id="LSBoostRegressor-235"><a href="#LSBoostRegressor-235"><span class="linenos">235</span></a>                <span class="n">col_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span><span class="p">,</span>
</span><span id="LSBoostRegressor-236"><a href="#LSBoostRegressor-236"><span class="linenos">236</span></a>                <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="LSBoostRegressor-237"><a href="#LSBoostRegressor-237"><span class="linenos">237</span></a>                <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="LSBoostRegressor-238"><a href="#LSBoostRegressor-238"><span class="linenos">238</span></a>                <span class="n">direct_link</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span><span class="p">,</span>
</span><span id="LSBoostRegressor-239"><a href="#LSBoostRegressor-239"><span class="linenos">239</span></a>                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="LSBoostRegressor-240"><a href="#LSBoostRegressor-240"><span class="linenos">240</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostRegressor-241"><a href="#LSBoostRegressor-241"><span class="linenos">241</span></a>                <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span>
</span><span id="LSBoostRegressor-242"><a href="#LSBoostRegressor-242"><span class="linenos">242</span></a>                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
</span><span id="LSBoostRegressor-243"><a href="#LSBoostRegressor-243"><span class="linenos">243</span></a>                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
</span><span id="LSBoostRegressor-244"><a href="#LSBoostRegressor-244"><span class="linenos">244</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor-245"><a href="#LSBoostRegressor-245"><span class="linenos">245</span></a>        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="LSBoostRegressor-246"><a href="#LSBoostRegressor-246"><span class="linenos">246</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">_boosterc</span><span class="o">.</span><span class="n">fit_booster_regressor</span><span class="p">(</span>
</span><span id="LSBoostRegressor-247"><a href="#LSBoostRegressor-247"><span class="linenos">247</span></a>                <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostRegressor-248"><a href="#LSBoostRegressor-248"><span class="linenos">248</span></a>                <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostRegressor-249"><a href="#LSBoostRegressor-249"><span class="linenos">249</span></a>                <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="LSBoostRegressor-250"><a href="#LSBoostRegressor-250"><span class="linenos">250</span></a>                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LSBoostRegressor-251"><a href="#LSBoostRegressor-251"><span class="linenos">251</span></a>                <span class="n">n_hidden_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span><span class="p">,</span>
</span><span id="LSBoostRegressor-252"><a href="#LSBoostRegressor-252"><span class="linenos">252</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LSBoostRegressor-253"><a href="#LSBoostRegressor-253"><span class="linenos">253</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="LSBoostRegressor-254"><a href="#LSBoostRegressor-254"><span class="linenos">254</span></a>                <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span>
</span><span id="LSBoostRegressor-255"><a href="#LSBoostRegressor-255"><span class="linenos">255</span></a>                <span class="n">col_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span><span class="p">,</span>
</span><span id="LSBoostRegressor-256"><a href="#LSBoostRegressor-256"><span class="linenos">256</span></a>                <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="LSBoostRegressor-257"><a href="#LSBoostRegressor-257"><span class="linenos">257</span></a>                <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="LSBoostRegressor-258"><a href="#LSBoostRegressor-258"><span class="linenos">258</span></a>                <span class="n">direct_link</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span><span class="p">,</span>
</span><span id="LSBoostRegressor-259"><a href="#LSBoostRegressor-259"><span class="linenos">259</span></a>                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="LSBoostRegressor-260"><a href="#LSBoostRegressor-260"><span class="linenos">260</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostRegressor-261"><a href="#LSBoostRegressor-261"><span class="linenos">261</span></a>                <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span>
</span><span id="LSBoostRegressor-262"><a href="#LSBoostRegressor-262"><span class="linenos">262</span></a>                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
</span><span id="LSBoostRegressor-263"><a href="#LSBoostRegressor-263"><span class="linenos">263</span></a>                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
</span><span id="LSBoostRegressor-264"><a href="#LSBoostRegressor-264"><span class="linenos">264</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor-265"><a href="#LSBoostRegressor-265"><span class="linenos">265</span></a>
</span><span id="LSBoostRegressor-266"><a href="#LSBoostRegressor-266"><span class="linenos">266</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span>
</span><span id="LSBoostRegressor-267"><a href="#LSBoostRegressor-267"><span class="linenos">267</span></a>
</span><span id="LSBoostRegressor-268"><a href="#LSBoostRegressor-268"><span class="linenos">268</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">X</span>
</span><span id="LSBoostRegressor-269"><a href="#LSBoostRegressor-269"><span class="linenos">269</span></a>
</span><span id="LSBoostRegressor-270"><a href="#LSBoostRegressor-270"><span class="linenos">270</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y</span>
</span><span id="LSBoostRegressor-271"><a href="#LSBoostRegressor-271"><span class="linenos">271</span></a>
</span><span id="LSBoostRegressor-272"><a href="#LSBoostRegressor-272"><span class="linenos">272</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="LSBoostRegressor-273"><a href="#LSBoostRegressor-273"><span class="linenos">273</span></a>
</span><span id="LSBoostRegressor-274"><a href="#LSBoostRegressor-274"><span class="linenos">274</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">95</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostRegressor-275"><a href="#LSBoostRegressor-275"><span class="linenos">275</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict probabilities for test data X.</span>
</span><span id="LSBoostRegressor-276"><a href="#LSBoostRegressor-276"><span class="linenos">276</span></a>
</span><span id="LSBoostRegressor-277"><a href="#LSBoostRegressor-277"><span class="linenos">277</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostRegressor-278"><a href="#LSBoostRegressor-278"><span class="linenos">278</span></a>
</span><span id="LSBoostRegressor-279"><a href="#LSBoostRegressor-279"><span class="linenos">279</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostRegressor-280"><a href="#LSBoostRegressor-280"><span class="linenos">280</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostRegressor-281"><a href="#LSBoostRegressor-281"><span class="linenos">281</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostRegressor-282"><a href="#LSBoostRegressor-282"><span class="linenos">282</span></a>
</span><span id="LSBoostRegressor-283"><a href="#LSBoostRegressor-283"><span class="linenos">283</span></a><span class="sd">            level: int</span>
</span><span id="LSBoostRegressor-284"><a href="#LSBoostRegressor-284"><span class="linenos">284</span></a><span class="sd">                Level of confidence (default = 95)</span>
</span><span id="LSBoostRegressor-285"><a href="#LSBoostRegressor-285"><span class="linenos">285</span></a>
</span><span id="LSBoostRegressor-286"><a href="#LSBoostRegressor-286"><span class="linenos">286</span></a><span class="sd">            method: str</span>
</span><span id="LSBoostRegressor-287"><a href="#LSBoostRegressor-287"><span class="linenos">287</span></a><span class="sd">                `None`, or &#39;splitconformal&#39;, &#39;localconformal&#39;</span>
</span><span id="LSBoostRegressor-288"><a href="#LSBoostRegressor-288"><span class="linenos">288</span></a><span class="sd">                prediction (if you specify `return_pi = True`)</span>
</span><span id="LSBoostRegressor-289"><a href="#LSBoostRegressor-289"><span class="linenos">289</span></a>
</span><span id="LSBoostRegressor-290"><a href="#LSBoostRegressor-290"><span class="linenos">290</span></a><span class="sd">            **kwargs: additional parameters to be passed to</span>
</span><span id="LSBoostRegressor-291"><a href="#LSBoostRegressor-291"><span class="linenos">291</span></a><span class="sd">                self.cook_test_set</span>
</span><span id="LSBoostRegressor-292"><a href="#LSBoostRegressor-292"><span class="linenos">292</span></a>
</span><span id="LSBoostRegressor-293"><a href="#LSBoostRegressor-293"><span class="linenos">293</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostRegressor-294"><a href="#LSBoostRegressor-294"><span class="linenos">294</span></a>
</span><span id="LSBoostRegressor-295"><a href="#LSBoostRegressor-295"><span class="linenos">295</span></a><span class="sd">            probability estimates for test data: {array-like}</span>
</span><span id="LSBoostRegressor-296"><a href="#LSBoostRegressor-296"><span class="linenos">296</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostRegressor-297"><a href="#LSBoostRegressor-297"><span class="linenos">297</span></a>
</span><span id="LSBoostRegressor-298"><a href="#LSBoostRegressor-298"><span class="linenos">298</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
</span><span id="LSBoostRegressor-299"><a href="#LSBoostRegressor-299"><span class="linenos">299</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
</span><span id="LSBoostRegressor-300"><a href="#LSBoostRegressor-300"><span class="linenos">300</span></a>
</span><span id="LSBoostRegressor-301"><a href="#LSBoostRegressor-301"><span class="linenos">301</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostRegressor-302"><a href="#LSBoostRegressor-302"><span class="linenos">302</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LSBoostRegressor-303"><a href="#LSBoostRegressor-303"><span class="linenos">303</span></a>
</span><span id="LSBoostRegressor-304"><a href="#LSBoostRegressor-304"><span class="linenos">304</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostRegressor-305"><a href="#LSBoostRegressor-305"><span class="linenos">305</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="LSBoostRegressor-306"><a href="#LSBoostRegressor-306"><span class="linenos">306</span></a>                <span class="p">(</span>
</span><span id="LSBoostRegressor-307"><a href="#LSBoostRegressor-307"><span class="linenos">307</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostRegressor-308"><a href="#LSBoostRegressor-308"><span class="linenos">308</span></a>                    <span class="n">cluster</span><span class="p">(</span>
</span><span id="LSBoostRegressor-309"><a href="#LSBoostRegressor-309"><span class="linenos">309</span></a>                        <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostRegressor-310"><a href="#LSBoostRegressor-310"><span class="linenos">310</span></a>                        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="LSBoostRegressor-311"><a href="#LSBoostRegressor-311"><span class="linenos">311</span></a>                        <span class="n">scaler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span>
</span><span id="LSBoostRegressor-312"><a href="#LSBoostRegressor-312"><span class="linenos">312</span></a>                        <span class="n">label_encoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span>
</span><span id="LSBoostRegressor-313"><a href="#LSBoostRegressor-313"><span class="linenos">313</span></a>                        <span class="n">clusterer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span><span class="p">,</span>
</span><span id="LSBoostRegressor-314"><a href="#LSBoostRegressor-314"><span class="linenos">314</span></a>                        <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostRegressor-315"><a href="#LSBoostRegressor-315"><span class="linenos">315</span></a>                    <span class="p">),</span>
</span><span id="LSBoostRegressor-316"><a href="#LSBoostRegressor-316"><span class="linenos">316</span></a>                <span class="p">)</span>
</span><span id="LSBoostRegressor-317"><a href="#LSBoostRegressor-317"><span class="linenos">317</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor-318"><a href="#LSBoostRegressor-318"><span class="linenos">318</span></a>        <span class="k">if</span> <span class="s2">&quot;return_pi&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
</span><span id="LSBoostRegressor-319"><a href="#LSBoostRegressor-319"><span class="linenos">319</span></a>            <span class="k">assert</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostRegressor-320"><a href="#LSBoostRegressor-320"><span class="linenos">320</span></a>                <span class="s2">&quot;splitconformal&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-321"><a href="#LSBoostRegressor-321"><span class="linenos">321</span></a>                <span class="s2">&quot;localconformal&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor-322"><a href="#LSBoostRegressor-322"><span class="linenos">322</span></a>            <span class="p">),</span> <span class="s2">&quot;method must be in (&#39;splitconformal&#39;, &#39;localconformal&#39;)&quot;</span>
</span><span id="LSBoostRegressor-323"><a href="#LSBoostRegressor-323"><span class="linenos">323</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pi</span> <span class="o">=</span> <span class="n">PredictionInterval</span><span class="p">(</span>
</span><span id="LSBoostRegressor-324"><a href="#LSBoostRegressor-324"><span class="linenos">324</span></a>                <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
</span><span id="LSBoostRegressor-325"><a href="#LSBoostRegressor-325"><span class="linenos">325</span></a>                <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
</span><span id="LSBoostRegressor-326"><a href="#LSBoostRegressor-326"><span class="linenos">326</span></a>                <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
</span><span id="LSBoostRegressor-327"><a href="#LSBoostRegressor-327"><span class="linenos">327</span></a>                <span class="n">type_pi</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">type_pi</span><span class="p">,</span>
</span><span id="LSBoostRegressor-328"><a href="#LSBoostRegressor-328"><span class="linenos">328</span></a>                <span class="n">replications</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">replications</span><span class="p">,</span>
</span><span id="LSBoostRegressor-329"><a href="#LSBoostRegressor-329"><span class="linenos">329</span></a>                <span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span>
</span><span id="LSBoostRegressor-330"><a href="#LSBoostRegressor-330"><span class="linenos">330</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor-331"><a href="#LSBoostRegressor-331"><span class="linenos">331</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
</span><span id="LSBoostRegressor-332"><a href="#LSBoostRegressor-332"><span class="linenos">332</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LSBoostRegressor-333"><a href="#LSBoostRegressor-333"><span class="linenos">333</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LSBoostRegressor-334"><a href="#LSBoostRegressor-334"><span class="linenos">334</span></a>            <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_pi</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="LSBoostRegressor-335"><a href="#LSBoostRegressor-335"><span class="linenos">335</span></a>            <span class="k">return</span> <span class="n">preds</span>
</span><span id="LSBoostRegressor-336"><a href="#LSBoostRegressor-336"><span class="linenos">336</span></a>
</span><span id="LSBoostRegressor-337"><a href="#LSBoostRegressor-337"><span class="linenos">337</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="LSBoostRegressor-338"><a href="#LSBoostRegressor-338"><span class="linenos">338</span></a>            <span class="k">return</span> <span class="n">boosterc</span><span class="o">.</span><span class="n">predict_booster_regressor</span><span class="p">(</span>
</span><span id="LSBoostRegressor-339"><a href="#LSBoostRegressor-339"><span class="linenos">339</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="LSBoostRegressor-340"><a href="#LSBoostRegressor-340"><span class="linenos">340</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor-341"><a href="#LSBoostRegressor-341"><span class="linenos">341</span></a>        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="LSBoostRegressor-342"><a href="#LSBoostRegressor-342"><span class="linenos">342</span></a>            <span class="k">return</span> <span class="n">_boosterc</span><span class="o">.</span><span class="n">predict_booster_regressor</span><span class="p">(</span>
</span><span id="LSBoostRegressor-343"><a href="#LSBoostRegressor-343"><span class="linenos">343</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="LSBoostRegressor-344"><a href="#LSBoostRegressor-344"><span class="linenos">344</span></a>            <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>LSBoost regressor.</p>

<p>Attributes:</p>

<pre><code>n_estimators: int
    number of boosting iterations.

learning_rate: float
    controls the learning speed at training time.

n_hidden_features: int
    number of nodes in successive hidden layers.

reg_lambda: float
    L2 regularization parameter for successive errors in the optimizer
    (at training time).

alpha: float
    compromise between L1 and L2 regularization (must be in [0, 1]),
    for `solver` == 'enet'

row_sample: float
    percentage of rows chosen from the training set.

col_sample: float
    percentage of columns chosen from the training set.

dropout: float
    percentage of nodes dropped from the training set.

tolerance: float
    controls early stopping in gradient descent (at training time).

direct_link: bool
    indicates whether the original features are included (True) in model's
    fitting or not (False).

verbose: int
    progress bar (yes = 1) or not (no = 0) (currently).

seed: int
    reproducibility seed for nodes_sim=='uniform', clustering and dropout.

backend: str
    type of backend; must be in ('cpu', 'gpu', 'tpu')

solver: str
    type of 'weak' learner; currently in ('ridge', 'lasso')

activation: str
    activation function: currently 'relu', 'relu6', 'sigmoid', 'tanh'

type_pi: str.
    type of prediction interval; currently "kde" (default) or "bootstrap".
    Used only in `self.predict`, for `self.replications` &gt; 0 and `self.kernel`
    in ('gaussian', 'tophat'). Default is `None`.

replications: int.
    number of replications (if needed) for predictive simulation.
    Used only in `self.predict`, for `self.kernel` in ('gaussian',
    'tophat') and `self.type_pi = 'kde'`. Default is `None`.

n_clusters: int
    number of clusters for clustering the features

clustering_method: str
    clustering method: currently 'kmeans', 'gmm'

cluster_scaling: str
    scaling method for clustering: currently 'standard', 'robust', 'minmax'

degree: int
    degree of features interactions to include in the model

weights_distr: str
    distribution of weights for constructing the model's hidden layer;
    either 'uniform' or 'gaussian'
</code></pre>
</div>


                                <div id="LSBoostRegressor.fit" class="classattr">
                                            <input id="LSBoostRegressor.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="LSBoostRegressor.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LSBoostRegressor.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LSBoostRegressor.fit-184"><a href="#LSBoostRegressor.fit-184"><span class="linenos">184</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostRegressor.fit-185"><a href="#LSBoostRegressor.fit-185"><span class="linenos">185</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit Booster (regressor) to training data (X, y)</span>
</span><span id="LSBoostRegressor.fit-186"><a href="#LSBoostRegressor.fit-186"><span class="linenos">186</span></a>
</span><span id="LSBoostRegressor.fit-187"><a href="#LSBoostRegressor.fit-187"><span class="linenos">187</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostRegressor.fit-188"><a href="#LSBoostRegressor.fit-188"><span class="linenos">188</span></a>
</span><span id="LSBoostRegressor.fit-189"><a href="#LSBoostRegressor.fit-189"><span class="linenos">189</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostRegressor.fit-190"><a href="#LSBoostRegressor.fit-190"><span class="linenos">190</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostRegressor.fit-191"><a href="#LSBoostRegressor.fit-191"><span class="linenos">191</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostRegressor.fit-192"><a href="#LSBoostRegressor.fit-192"><span class="linenos">192</span></a>
</span><span id="LSBoostRegressor.fit-193"><a href="#LSBoostRegressor.fit-193"><span class="linenos">193</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="LSBoostRegressor.fit-194"><a href="#LSBoostRegressor.fit-194"><span class="linenos">194</span></a><span class="sd">               Target values.</span>
</span><span id="LSBoostRegressor.fit-195"><a href="#LSBoostRegressor.fit-195"><span class="linenos">195</span></a>
</span><span id="LSBoostRegressor.fit-196"><a href="#LSBoostRegressor.fit-196"><span class="linenos">196</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="LSBoostRegressor.fit-197"><a href="#LSBoostRegressor.fit-197"><span class="linenos">197</span></a>
</span><span id="LSBoostRegressor.fit-198"><a href="#LSBoostRegressor.fit-198"><span class="linenos">198</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostRegressor.fit-199"><a href="#LSBoostRegressor.fit-199"><span class="linenos">199</span></a>
</span><span id="LSBoostRegressor.fit-200"><a href="#LSBoostRegressor.fit-200"><span class="linenos">200</span></a><span class="sd">            self: object.</span>
</span><span id="LSBoostRegressor.fit-201"><a href="#LSBoostRegressor.fit-201"><span class="linenos">201</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostRegressor.fit-202"><a href="#LSBoostRegressor.fit-202"><span class="linenos">202</span></a>
</span><span id="LSBoostRegressor.fit-203"><a href="#LSBoostRegressor.fit-203"><span class="linenos">203</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
</span><span id="LSBoostRegressor.fit-204"><a href="#LSBoostRegressor.fit-204"><span class="linenos">204</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
</span><span id="LSBoostRegressor.fit-205"><a href="#LSBoostRegressor.fit-205"><span class="linenos">205</span></a>
</span><span id="LSBoostRegressor.fit-206"><a href="#LSBoostRegressor.fit-206"><span class="linenos">206</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LSBoostRegressor.fit-207"><a href="#LSBoostRegressor.fit-207"><span class="linenos">207</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span>
</span><span id="LSBoostRegressor.fit-208"><a href="#LSBoostRegressor.fit-208"><span class="linenos">208</span></a>                <span class="n">degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span>
</span><span id="LSBoostRegressor.fit-209"><a href="#LSBoostRegressor.fit-209"><span class="linenos">209</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor.fit-210"><a href="#LSBoostRegressor.fit-210"><span class="linenos">210</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LSBoostRegressor.fit-211"><a href="#LSBoostRegressor.fit-211"><span class="linenos">211</span></a>
</span><span id="LSBoostRegressor.fit-212"><a href="#LSBoostRegressor.fit-212"><span class="linenos">212</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostRegressor.fit-213"><a href="#LSBoostRegressor.fit-213"><span class="linenos">213</span></a>            <span class="n">clustered_X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="LSBoostRegressor.fit-214"><a href="#LSBoostRegressor.fit-214"><span class="linenos">214</span></a>                <span class="n">cluster</span><span class="p">(</span>
</span><span id="LSBoostRegressor.fit-215"><a href="#LSBoostRegressor.fit-215"><span class="linenos">215</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-216"><a href="#LSBoostRegressor.fit-216"><span class="linenos">216</span></a>                    <span class="n">n_clusters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-217"><a href="#LSBoostRegressor.fit-217"><span class="linenos">217</span></a>                    <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clustering_method</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-218"><a href="#LSBoostRegressor.fit-218"><span class="linenos">218</span></a>                    <span class="n">type_scaling</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_scaling</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-219"><a href="#LSBoostRegressor.fit-219"><span class="linenos">219</span></a>                    <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-220"><a href="#LSBoostRegressor.fit-220"><span class="linenos">220</span></a>                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-221"><a href="#LSBoostRegressor.fit-221"><span class="linenos">221</span></a>                <span class="p">)</span>
</span><span id="LSBoostRegressor.fit-222"><a href="#LSBoostRegressor.fit-222"><span class="linenos">222</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor.fit-223"><a href="#LSBoostRegressor.fit-223"><span class="linenos">223</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">clustered_X</span><span class="p">))</span>
</span><span id="LSBoostRegressor.fit-224"><a href="#LSBoostRegressor.fit-224"><span class="linenos">224</span></a>
</span><span id="LSBoostRegressor.fit-225"><a href="#LSBoostRegressor.fit-225"><span class="linenos">225</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="LSBoostRegressor.fit-226"><a href="#LSBoostRegressor.fit-226"><span class="linenos">226</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">boosterc</span><span class="o">.</span><span class="n">fit_booster_regressor</span><span class="p">(</span>
</span><span id="LSBoostRegressor.fit-227"><a href="#LSBoostRegressor.fit-227"><span class="linenos">227</span></a>                <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostRegressor.fit-228"><a href="#LSBoostRegressor.fit-228"><span class="linenos">228</span></a>                <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostRegressor.fit-229"><a href="#LSBoostRegressor.fit-229"><span class="linenos">229</span></a>                <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-230"><a href="#LSBoostRegressor.fit-230"><span class="linenos">230</span></a>                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-231"><a href="#LSBoostRegressor.fit-231"><span class="linenos">231</span></a>                <span class="n">n_hidden_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-232"><a href="#LSBoostRegressor.fit-232"><span class="linenos">232</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-233"><a href="#LSBoostRegressor.fit-233"><span class="linenos">233</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-234"><a href="#LSBoostRegressor.fit-234"><span class="linenos">234</span></a>                <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-235"><a href="#LSBoostRegressor.fit-235"><span class="linenos">235</span></a>                <span class="n">col_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-236"><a href="#LSBoostRegressor.fit-236"><span class="linenos">236</span></a>                <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-237"><a href="#LSBoostRegressor.fit-237"><span class="linenos">237</span></a>                <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-238"><a href="#LSBoostRegressor.fit-238"><span class="linenos">238</span></a>                <span class="n">direct_link</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-239"><a href="#LSBoostRegressor.fit-239"><span class="linenos">239</span></a>                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-240"><a href="#LSBoostRegressor.fit-240"><span class="linenos">240</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-241"><a href="#LSBoostRegressor.fit-241"><span class="linenos">241</span></a>                <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-242"><a href="#LSBoostRegressor.fit-242"><span class="linenos">242</span></a>                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-243"><a href="#LSBoostRegressor.fit-243"><span class="linenos">243</span></a>                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-244"><a href="#LSBoostRegressor.fit-244"><span class="linenos">244</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor.fit-245"><a href="#LSBoostRegressor.fit-245"><span class="linenos">245</span></a>        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="LSBoostRegressor.fit-246"><a href="#LSBoostRegressor.fit-246"><span class="linenos">246</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">_boosterc</span><span class="o">.</span><span class="n">fit_booster_regressor</span><span class="p">(</span>
</span><span id="LSBoostRegressor.fit-247"><a href="#LSBoostRegressor.fit-247"><span class="linenos">247</span></a>                <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostRegressor.fit-248"><a href="#LSBoostRegressor.fit-248"><span class="linenos">248</span></a>                <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">),</span>
</span><span id="LSBoostRegressor.fit-249"><a href="#LSBoostRegressor.fit-249"><span class="linenos">249</span></a>                <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-250"><a href="#LSBoostRegressor.fit-250"><span class="linenos">250</span></a>                <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-251"><a href="#LSBoostRegressor.fit-251"><span class="linenos">251</span></a>                <span class="n">n_hidden_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden_features</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-252"><a href="#LSBoostRegressor.fit-252"><span class="linenos">252</span></a>                <span class="n">reg_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-253"><a href="#LSBoostRegressor.fit-253"><span class="linenos">253</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-254"><a href="#LSBoostRegressor.fit-254"><span class="linenos">254</span></a>                <span class="n">row_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">row_sample</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-255"><a href="#LSBoostRegressor.fit-255"><span class="linenos">255</span></a>                <span class="n">col_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_sample</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-256"><a href="#LSBoostRegressor.fit-256"><span class="linenos">256</span></a>                <span class="n">dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-257"><a href="#LSBoostRegressor.fit-257"><span class="linenos">257</span></a>                <span class="n">tolerance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tolerance</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-258"><a href="#LSBoostRegressor.fit-258"><span class="linenos">258</span></a>                <span class="n">direct_link</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_link</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-259"><a href="#LSBoostRegressor.fit-259"><span class="linenos">259</span></a>                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-260"><a href="#LSBoostRegressor.fit-260"><span class="linenos">260</span></a>                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-261"><a href="#LSBoostRegressor.fit-261"><span class="linenos">261</span></a>                <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-262"><a href="#LSBoostRegressor.fit-262"><span class="linenos">262</span></a>                <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-263"><a href="#LSBoostRegressor.fit-263"><span class="linenos">263</span></a>                <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
</span><span id="LSBoostRegressor.fit-264"><a href="#LSBoostRegressor.fit-264"><span class="linenos">264</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor.fit-265"><a href="#LSBoostRegressor.fit-265"><span class="linenos">265</span></a>
</span><span id="LSBoostRegressor.fit-266"><a href="#LSBoostRegressor.fit-266"><span class="linenos">266</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">[</span><span class="s2">&quot;n_estimators&quot;</span><span class="p">]</span>
</span><span id="LSBoostRegressor.fit-267"><a href="#LSBoostRegressor.fit-267"><span class="linenos">267</span></a>
</span><span id="LSBoostRegressor.fit-268"><a href="#LSBoostRegressor.fit-268"><span class="linenos">268</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="n">X</span>
</span><span id="LSBoostRegressor.fit-269"><a href="#LSBoostRegressor.fit-269"><span class="linenos">269</span></a>
</span><span id="LSBoostRegressor.fit-270"><a href="#LSBoostRegressor.fit-270"><span class="linenos">270</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y</span>
</span><span id="LSBoostRegressor.fit-271"><a href="#LSBoostRegressor.fit-271"><span class="linenos">271</span></a>
</span><span id="LSBoostRegressor.fit-272"><a href="#LSBoostRegressor.fit-272"><span class="linenos">272</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit Booster (regressor) to training data (X, y)</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

y: array-like, shape = [n_samples]
   Target values.

**kwargs: additional parameters to be passed to self.cook_training_set.
</code></pre>

<p>Returns:</p>

<pre><code>self: object.
</code></pre>
</div>


                                </div>
                                <div id="LSBoostRegressor.predict" class="classattr">
                                            <input id="LSBoostRegressor.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">level</span><span class="o">=</span><span class="mi">95</span>, </span><span class="param"><span class="n">method</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="LSBoostRegressor.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LSBoostRegressor.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LSBoostRegressor.predict-274"><a href="#LSBoostRegressor.predict-274"><span class="linenos">274</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">95</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="LSBoostRegressor.predict-275"><a href="#LSBoostRegressor.predict-275"><span class="linenos">275</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict probabilities for test data X.</span>
</span><span id="LSBoostRegressor.predict-276"><a href="#LSBoostRegressor.predict-276"><span class="linenos">276</span></a>
</span><span id="LSBoostRegressor.predict-277"><a href="#LSBoostRegressor.predict-277"><span class="linenos">277</span></a><span class="sd">        Args:</span>
</span><span id="LSBoostRegressor.predict-278"><a href="#LSBoostRegressor.predict-278"><span class="linenos">278</span></a>
</span><span id="LSBoostRegressor.predict-279"><a href="#LSBoostRegressor.predict-279"><span class="linenos">279</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="LSBoostRegressor.predict-280"><a href="#LSBoostRegressor.predict-280"><span class="linenos">280</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="LSBoostRegressor.predict-281"><a href="#LSBoostRegressor.predict-281"><span class="linenos">281</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="LSBoostRegressor.predict-282"><a href="#LSBoostRegressor.predict-282"><span class="linenos">282</span></a>
</span><span id="LSBoostRegressor.predict-283"><a href="#LSBoostRegressor.predict-283"><span class="linenos">283</span></a><span class="sd">            level: int</span>
</span><span id="LSBoostRegressor.predict-284"><a href="#LSBoostRegressor.predict-284"><span class="linenos">284</span></a><span class="sd">                Level of confidence (default = 95)</span>
</span><span id="LSBoostRegressor.predict-285"><a href="#LSBoostRegressor.predict-285"><span class="linenos">285</span></a>
</span><span id="LSBoostRegressor.predict-286"><a href="#LSBoostRegressor.predict-286"><span class="linenos">286</span></a><span class="sd">            method: str</span>
</span><span id="LSBoostRegressor.predict-287"><a href="#LSBoostRegressor.predict-287"><span class="linenos">287</span></a><span class="sd">                `None`, or &#39;splitconformal&#39;, &#39;localconformal&#39;</span>
</span><span id="LSBoostRegressor.predict-288"><a href="#LSBoostRegressor.predict-288"><span class="linenos">288</span></a><span class="sd">                prediction (if you specify `return_pi = True`)</span>
</span><span id="LSBoostRegressor.predict-289"><a href="#LSBoostRegressor.predict-289"><span class="linenos">289</span></a>
</span><span id="LSBoostRegressor.predict-290"><a href="#LSBoostRegressor.predict-290"><span class="linenos">290</span></a><span class="sd">            **kwargs: additional parameters to be passed to</span>
</span><span id="LSBoostRegressor.predict-291"><a href="#LSBoostRegressor.predict-291"><span class="linenos">291</span></a><span class="sd">                self.cook_test_set</span>
</span><span id="LSBoostRegressor.predict-292"><a href="#LSBoostRegressor.predict-292"><span class="linenos">292</span></a>
</span><span id="LSBoostRegressor.predict-293"><a href="#LSBoostRegressor.predict-293"><span class="linenos">293</span></a><span class="sd">        Returns:</span>
</span><span id="LSBoostRegressor.predict-294"><a href="#LSBoostRegressor.predict-294"><span class="linenos">294</span></a>
</span><span id="LSBoostRegressor.predict-295"><a href="#LSBoostRegressor.predict-295"><span class="linenos">295</span></a><span class="sd">            probability estimates for test data: {array-like}</span>
</span><span id="LSBoostRegressor.predict-296"><a href="#LSBoostRegressor.predict-296"><span class="linenos">296</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LSBoostRegressor.predict-297"><a href="#LSBoostRegressor.predict-297"><span class="linenos">297</span></a>
</span><span id="LSBoostRegressor.predict-298"><a href="#LSBoostRegressor.predict-298"><span class="linenos">298</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
</span><span id="LSBoostRegressor.predict-299"><a href="#LSBoostRegressor.predict-299"><span class="linenos">299</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
</span><span id="LSBoostRegressor.predict-300"><a href="#LSBoostRegressor.predict-300"><span class="linenos">300</span></a>
</span><span id="LSBoostRegressor.predict-301"><a href="#LSBoostRegressor.predict-301"><span class="linenos">301</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostRegressor.predict-302"><a href="#LSBoostRegressor.predict-302"><span class="linenos">302</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">poly_</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LSBoostRegressor.predict-303"><a href="#LSBoostRegressor.predict-303"><span class="linenos">303</span></a>
</span><span id="LSBoostRegressor.predict-304"><a href="#LSBoostRegressor.predict-304"><span class="linenos">304</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LSBoostRegressor.predict-305"><a href="#LSBoostRegressor.predict-305"><span class="linenos">305</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="LSBoostRegressor.predict-306"><a href="#LSBoostRegressor.predict-306"><span class="linenos">306</span></a>                <span class="p">(</span>
</span><span id="LSBoostRegressor.predict-307"><a href="#LSBoostRegressor.predict-307"><span class="linenos">307</span></a>                    <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-308"><a href="#LSBoostRegressor.predict-308"><span class="linenos">308</span></a>                    <span class="n">cluster</span><span class="p">(</span>
</span><span id="LSBoostRegressor.predict-309"><a href="#LSBoostRegressor.predict-309"><span class="linenos">309</span></a>                        <span class="n">X</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-310"><a href="#LSBoostRegressor.predict-310"><span class="linenos">310</span></a>                        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-311"><a href="#LSBoostRegressor.predict-311"><span class="linenos">311</span></a>                        <span class="n">scaler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler_</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-312"><a href="#LSBoostRegressor.predict-312"><span class="linenos">312</span></a>                        <span class="n">label_encoder</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_encoder_</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-313"><a href="#LSBoostRegressor.predict-313"><span class="linenos">313</span></a>                        <span class="n">clusterer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clusterer_</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-314"><a href="#LSBoostRegressor.predict-314"><span class="linenos">314</span></a>                        <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-315"><a href="#LSBoostRegressor.predict-315"><span class="linenos">315</span></a>                    <span class="p">),</span>
</span><span id="LSBoostRegressor.predict-316"><a href="#LSBoostRegressor.predict-316"><span class="linenos">316</span></a>                <span class="p">)</span>
</span><span id="LSBoostRegressor.predict-317"><a href="#LSBoostRegressor.predict-317"><span class="linenos">317</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor.predict-318"><a href="#LSBoostRegressor.predict-318"><span class="linenos">318</span></a>        <span class="k">if</span> <span class="s2">&quot;return_pi&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
</span><span id="LSBoostRegressor.predict-319"><a href="#LSBoostRegressor.predict-319"><span class="linenos">319</span></a>            <span class="k">assert</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="LSBoostRegressor.predict-320"><a href="#LSBoostRegressor.predict-320"><span class="linenos">320</span></a>                <span class="s2">&quot;splitconformal&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-321"><a href="#LSBoostRegressor.predict-321"><span class="linenos">321</span></a>                <span class="s2">&quot;localconformal&quot;</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-322"><a href="#LSBoostRegressor.predict-322"><span class="linenos">322</span></a>            <span class="p">),</span> <span class="s2">&quot;method must be in (&#39;splitconformal&#39;, &#39;localconformal&#39;)&quot;</span>
</span><span id="LSBoostRegressor.predict-323"><a href="#LSBoostRegressor.predict-323"><span class="linenos">323</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pi</span> <span class="o">=</span> <span class="n">PredictionInterval</span><span class="p">(</span>
</span><span id="LSBoostRegressor.predict-324"><a href="#LSBoostRegressor.predict-324"><span class="linenos">324</span></a>                <span class="n">obj</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-325"><a href="#LSBoostRegressor.predict-325"><span class="linenos">325</span></a>                <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-326"><a href="#LSBoostRegressor.predict-326"><span class="linenos">326</span></a>                <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-327"><a href="#LSBoostRegressor.predict-327"><span class="linenos">327</span></a>                <span class="n">type_pi</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">type_pi</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-328"><a href="#LSBoostRegressor.predict-328"><span class="linenos">328</span></a>                <span class="n">replications</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">replications</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-329"><a href="#LSBoostRegressor.predict-329"><span class="linenos">329</span></a>                <span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span>
</span><span id="LSBoostRegressor.predict-330"><a href="#LSBoostRegressor.predict-330"><span class="linenos">330</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor.predict-331"><a href="#LSBoostRegressor.predict-331"><span class="linenos">331</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">)</span>
</span><span id="LSBoostRegressor.predict-332"><a href="#LSBoostRegressor.predict-332"><span class="linenos">332</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LSBoostRegressor.predict-333"><a href="#LSBoostRegressor.predict-333"><span class="linenos">333</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LSBoostRegressor.predict-334"><a href="#LSBoostRegressor.predict-334"><span class="linenos">334</span></a>            <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_pi</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="LSBoostRegressor.predict-335"><a href="#LSBoostRegressor.predict-335"><span class="linenos">335</span></a>            <span class="k">return</span> <span class="n">preds</span>
</span><span id="LSBoostRegressor.predict-336"><a href="#LSBoostRegressor.predict-336"><span class="linenos">336</span></a>
</span><span id="LSBoostRegressor.predict-337"><a href="#LSBoostRegressor.predict-337"><span class="linenos">337</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="LSBoostRegressor.predict-338"><a href="#LSBoostRegressor.predict-338"><span class="linenos">338</span></a>            <span class="k">return</span> <span class="n">boosterc</span><span class="o">.</span><span class="n">predict_booster_regressor</span><span class="p">(</span>
</span><span id="LSBoostRegressor.predict-339"><a href="#LSBoostRegressor.predict-339"><span class="linenos">339</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="LSBoostRegressor.predict-340"><a href="#LSBoostRegressor.predict-340"><span class="linenos">340</span></a>            <span class="p">)</span>
</span><span id="LSBoostRegressor.predict-341"><a href="#LSBoostRegressor.predict-341"><span class="linenos">341</span></a>        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="LSBoostRegressor.predict-342"><a href="#LSBoostRegressor.predict-342"><span class="linenos">342</span></a>            <span class="k">return</span> <span class="n">_boosterc</span><span class="o">.</span><span class="n">predict_booster_regressor</span><span class="p">(</span>
</span><span id="LSBoostRegressor.predict-343"><a href="#LSBoostRegressor.predict-343"><span class="linenos">343</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
</span><span id="LSBoostRegressor.predict-344"><a href="#LSBoostRegressor.predict-344"><span class="linenos">344</span></a>            <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict probabilities for test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

level: int
    Level of confidence (default = 95)

method: str
    `None`, or 'splitconformal', 'localconformal'
    prediction (if you specify `return_pi = True`)

**kwargs: additional parameters to be passed to
    self.cook_test_set
</code></pre>

<p>Returns:</p>

<pre><code>probability estimates for test data: {array-like}
</code></pre>
</div>


                                </div>
                        
                </section>
                <section id="RidgeRegressor">
                            <input id="RidgeRegressor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">RidgeRegressor</span><wbr>(<span class="base">sklearn.base.BaseEstimator</span>, <span class="base">sklearn.base.RegressorMixin</span>):

                <label class="view-source-button" for="RidgeRegressor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RidgeRegressor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RidgeRegressor-21"><a href="#RidgeRegressor-21"><span class="linenos"> 21</span></a><span class="k">class</span> <span class="nc">RidgeRegressor</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
</span><span id="RidgeRegressor-22"><a href="#RidgeRegressor-22"><span class="linenos"> 22</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Ridge.</span>
</span><span id="RidgeRegressor-23"><a href="#RidgeRegressor-23"><span class="linenos"> 23</span></a>
</span><span id="RidgeRegressor-24"><a href="#RidgeRegressor-24"><span class="linenos"> 24</span></a><span class="sd">    Attributes:</span>
</span><span id="RidgeRegressor-25"><a href="#RidgeRegressor-25"><span class="linenos"> 25</span></a>
</span><span id="RidgeRegressor-26"><a href="#RidgeRegressor-26"><span class="linenos"> 26</span></a><span class="sd">        reg_lambda: float</span>
</span><span id="RidgeRegressor-27"><a href="#RidgeRegressor-27"><span class="linenos"> 27</span></a><span class="sd">            regularization parameter.</span>
</span><span id="RidgeRegressor-28"><a href="#RidgeRegressor-28"><span class="linenos"> 28</span></a>
</span><span id="RidgeRegressor-29"><a href="#RidgeRegressor-29"><span class="linenos"> 29</span></a><span class="sd">        backend: str</span>
</span><span id="RidgeRegressor-30"><a href="#RidgeRegressor-30"><span class="linenos"> 30</span></a><span class="sd">            type of backend; must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)</span>
</span><span id="RidgeRegressor-31"><a href="#RidgeRegressor-31"><span class="linenos"> 31</span></a>
</span><span id="RidgeRegressor-32"><a href="#RidgeRegressor-32"><span class="linenos"> 32</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="RidgeRegressor-33"><a href="#RidgeRegressor-33"><span class="linenos"> 33</span></a>
</span><span id="RidgeRegressor-34"><a href="#RidgeRegressor-34"><span class="linenos"> 34</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_lambda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
</span><span id="RidgeRegressor-35"><a href="#RidgeRegressor-35"><span class="linenos"> 35</span></a>        <span class="k">assert</span> <span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span>
</span><span id="RidgeRegressor-36"><a href="#RidgeRegressor-36"><span class="linenos"> 36</span></a>            <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="RidgeRegressor-37"><a href="#RidgeRegressor-37"><span class="linenos"> 37</span></a>            <span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
</span><span id="RidgeRegressor-38"><a href="#RidgeRegressor-38"><span class="linenos"> 38</span></a>            <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
</span><span id="RidgeRegressor-39"><a href="#RidgeRegressor-39"><span class="linenos"> 39</span></a>        <span class="p">),</span> <span class="s2">&quot;`backend` must be in (&#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;)&quot;</span>
</span><span id="RidgeRegressor-40"><a href="#RidgeRegressor-40"><span class="linenos"> 40</span></a>
</span><span id="RidgeRegressor-41"><a href="#RidgeRegressor-41"><span class="linenos"> 41</span></a>        <span class="n">sys_platform</span> <span class="o">=</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span>
</span><span id="RidgeRegressor-42"><a href="#RidgeRegressor-42"><span class="linenos"> 42</span></a>
</span><span id="RidgeRegressor-43"><a href="#RidgeRegressor-43"><span class="linenos"> 43</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">sys_platform</span> <span class="o">==</span> <span class="s2">&quot;Windows&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">backend</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="s2">&quot;tpu&quot;</span><span class="p">)):</span>
</span><span id="RidgeRegressor-44"><a href="#RidgeRegressor-44"><span class="linenos"> 44</span></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span id="RidgeRegressor-45"><a href="#RidgeRegressor-45"><span class="linenos"> 45</span></a>                <span class="s2">&quot;No GPU/TPU computing on Windows yet, backend set to &#39;cpu&#39;&quot;</span>
</span><span id="RidgeRegressor-46"><a href="#RidgeRegressor-46"><span class="linenos"> 46</span></a>            <span class="p">)</span>
</span><span id="RidgeRegressor-47"><a href="#RidgeRegressor-47"><span class="linenos"> 47</span></a>            <span class="n">backend</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
</span><span id="RidgeRegressor-48"><a href="#RidgeRegressor-48"><span class="linenos"> 48</span></a>
</span><span id="RidgeRegressor-49"><a href="#RidgeRegressor-49"><span class="linenos"> 49</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">reg_lambda</span>
</span><span id="RidgeRegressor-50"><a href="#RidgeRegressor-50"><span class="linenos"> 50</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span>
</span><span id="RidgeRegressor-51"><a href="#RidgeRegressor-51"><span class="linenos"> 51</span></a>
</span><span id="RidgeRegressor-52"><a href="#RidgeRegressor-52"><span class="linenos"> 52</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="RidgeRegressor-53"><a href="#RidgeRegressor-53"><span class="linenos"> 53</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit matrixops (classifier) to training data (X, y)</span>
</span><span id="RidgeRegressor-54"><a href="#RidgeRegressor-54"><span class="linenos"> 54</span></a>
</span><span id="RidgeRegressor-55"><a href="#RidgeRegressor-55"><span class="linenos"> 55</span></a><span class="sd">        Args:</span>
</span><span id="RidgeRegressor-56"><a href="#RidgeRegressor-56"><span class="linenos"> 56</span></a>
</span><span id="RidgeRegressor-57"><a href="#RidgeRegressor-57"><span class="linenos"> 57</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="RidgeRegressor-58"><a href="#RidgeRegressor-58"><span class="linenos"> 58</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="RidgeRegressor-59"><a href="#RidgeRegressor-59"><span class="linenos"> 59</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="RidgeRegressor-60"><a href="#RidgeRegressor-60"><span class="linenos"> 60</span></a>
</span><span id="RidgeRegressor-61"><a href="#RidgeRegressor-61"><span class="linenos"> 61</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="RidgeRegressor-62"><a href="#RidgeRegressor-62"><span class="linenos"> 62</span></a><span class="sd">                Target values.</span>
</span><span id="RidgeRegressor-63"><a href="#RidgeRegressor-63"><span class="linenos"> 63</span></a>
</span><span id="RidgeRegressor-64"><a href="#RidgeRegressor-64"><span class="linenos"> 64</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="RidgeRegressor-65"><a href="#RidgeRegressor-65"><span class="linenos"> 65</span></a>
</span><span id="RidgeRegressor-66"><a href="#RidgeRegressor-66"><span class="linenos"> 66</span></a><span class="sd">        Returns:</span>
</span><span id="RidgeRegressor-67"><a href="#RidgeRegressor-67"><span class="linenos"> 67</span></a>
</span><span id="RidgeRegressor-68"><a href="#RidgeRegressor-68"><span class="linenos"> 68</span></a><span class="sd">            self: object.</span>
</span><span id="RidgeRegressor-69"><a href="#RidgeRegressor-69"><span class="linenos"> 69</span></a>
</span><span id="RidgeRegressor-70"><a href="#RidgeRegressor-70"><span class="linenos"> 70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="RidgeRegressor-71"><a href="#RidgeRegressor-71"><span class="linenos"> 71</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="n">centered_y</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">center_response</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="RidgeRegressor-72"><a href="#RidgeRegressor-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xm</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="RidgeRegressor-73"><a href="#RidgeRegressor-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="RidgeRegressor-74"><a href="#RidgeRegressor-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">xsd</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># avoid division by zero</span>
</span><span id="RidgeRegressor-75"><a href="#RidgeRegressor-75"><span class="linenos"> 75</span></a>        <span class="n">X_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xm</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RidgeRegressor-76"><a href="#RidgeRegressor-76"><span class="linenos"> 76</span></a>
</span><span id="RidgeRegressor-77"><a href="#RidgeRegressor-77"><span class="linenos"> 77</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="RidgeRegressor-78"><a href="#RidgeRegressor-78"><span class="linenos"> 78</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">centered_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="RidgeRegressor-79"><a href="#RidgeRegressor-79"><span class="linenos"> 79</span></a>                <span class="n">eye_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="RidgeRegressor-80"><a href="#RidgeRegressor-80"><span class="linenos"> 80</span></a>                <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">X_</span><span class="p">,</span> <span class="n">eye_term</span><span class="p">))</span>
</span><span id="RidgeRegressor-81"><a href="#RidgeRegressor-81"><span class="linenos"> 81</span></a>                <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">centered_y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
</span><span id="RidgeRegressor-82"><a href="#RidgeRegressor-82"><span class="linenos"> 82</span></a>                <span class="c1"># self.beta, _, _, _ = np.linalg.lstsq(X_, y_, rcond=None)</span>
</span><span id="RidgeRegressor-83"><a href="#RidgeRegressor-83"><span class="linenos"> 83</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">get_beta</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
</span><span id="RidgeRegressor-84"><a href="#RidgeRegressor-84"><span class="linenos"> 84</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="RidgeRegressor-85"><a href="#RidgeRegressor-85"><span class="linenos"> 85</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="RidgeRegressor-86"><a href="#RidgeRegressor-86"><span class="linenos"> 86</span></a>                    <span class="n">eye_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="RidgeRegressor-87"><a href="#RidgeRegressor-87"><span class="linenos"> 87</span></a>                    <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">X_</span><span class="p">,</span> <span class="n">eye_term</span><span class="p">))</span>
</span><span id="RidgeRegressor-88"><a href="#RidgeRegressor-88"><span class="linenos"> 88</span></a>                    <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">(</span>
</span><span id="RidgeRegressor-89"><a href="#RidgeRegressor-89"><span class="linenos"> 89</span></a>                        <span class="p">(</span>
</span><span id="RidgeRegressor-90"><a href="#RidgeRegressor-90"><span class="linenos"> 90</span></a>                            <span class="n">centered_y</span><span class="p">,</span>
</span><span id="RidgeRegressor-91"><a href="#RidgeRegressor-91"><span class="linenos"> 91</span></a>                            <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">eye_term</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">centered_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span>
</span><span id="RidgeRegressor-92"><a href="#RidgeRegressor-92"><span class="linenos"> 92</span></a>                        <span class="p">)</span>
</span><span id="RidgeRegressor-93"><a href="#RidgeRegressor-93"><span class="linenos"> 93</span></a>                    <span class="p">)</span>
</span><span id="RidgeRegressor-94"><a href="#RidgeRegressor-94"><span class="linenos"> 94</span></a>                    <span class="c1"># self.beta, _, _, _ = np.linalg.lstsq(X_, y_, rcond=None)</span>
</span><span id="RidgeRegressor-95"><a href="#RidgeRegressor-95"><span class="linenos"> 95</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">get_beta</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
</span><span id="RidgeRegressor-96"><a href="#RidgeRegressor-96"><span class="linenos"> 96</span></a>                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
</span><span id="RidgeRegressor-97"><a href="#RidgeRegressor-97"><span class="linenos"> 97</span></a>                    <span class="n">x</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span>
</span><span id="RidgeRegressor-98"><a href="#RidgeRegressor-98"><span class="linenos"> 98</span></a>                        <span class="n">mo</span><span class="o">.</span><span class="n">crossprod</span><span class="p">(</span><span class="n">X_</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="RidgeRegressor-99"><a href="#RidgeRegressor-99"><span class="linenos"> 99</span></a>                    <span class="p">)</span>
</span><span id="RidgeRegressor-100"><a href="#RidgeRegressor-100"><span class="linenos">100</span></a>                    <span class="n">hat_matrix</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">tcrossprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_</span><span class="p">)</span>
</span><span id="RidgeRegressor-101"><a href="#RidgeRegressor-101"><span class="linenos">101</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">hat_matrix</span><span class="p">,</span> <span class="n">centered_y</span><span class="p">)</span>
</span><span id="RidgeRegressor-102"><a href="#RidgeRegressor-102"><span class="linenos">102</span></a>            <span class="k">return</span> <span class="bp">self</span>
</span><span id="RidgeRegressor-103"><a href="#RidgeRegressor-103"><span class="linenos">103</span></a>
</span><span id="RidgeRegressor-104"><a href="#RidgeRegressor-104"><span class="linenos">104</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">jinv</span><span class="p">(</span>
</span><span id="RidgeRegressor-105"><a href="#RidgeRegressor-105"><span class="linenos">105</span></a>            <span class="n">mo</span><span class="o">.</span><span class="n">crossprod</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="RidgeRegressor-106"><a href="#RidgeRegressor-106"><span class="linenos">106</span></a>            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="RidgeRegressor-107"><a href="#RidgeRegressor-107"><span class="linenos">107</span></a>        <span class="p">)</span>
</span><span id="RidgeRegressor-108"><a href="#RidgeRegressor-108"><span class="linenos">108</span></a>        <span class="n">hat_matrix</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">tcrossprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="RidgeRegressor-109"><a href="#RidgeRegressor-109"><span class="linenos">109</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="RidgeRegressor-110"><a href="#RidgeRegressor-110"><span class="linenos">110</span></a>            <span class="n">hat_matrix</span><span class="p">,</span> <span class="n">centered_y</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="RidgeRegressor-111"><a href="#RidgeRegressor-111"><span class="linenos">111</span></a>        <span class="p">)</span>
</span><span id="RidgeRegressor-112"><a href="#RidgeRegressor-112"><span class="linenos">112</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="RidgeRegressor-113"><a href="#RidgeRegressor-113"><span class="linenos">113</span></a>
</span><span id="RidgeRegressor-114"><a href="#RidgeRegressor-114"><span class="linenos">114</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="RidgeRegressor-115"><a href="#RidgeRegressor-115"><span class="linenos">115</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="RidgeRegressor-116"><a href="#RidgeRegressor-116"><span class="linenos">116</span></a>
</span><span id="RidgeRegressor-117"><a href="#RidgeRegressor-117"><span class="linenos">117</span></a><span class="sd">        Args:</span>
</span><span id="RidgeRegressor-118"><a href="#RidgeRegressor-118"><span class="linenos">118</span></a>
</span><span id="RidgeRegressor-119"><a href="#RidgeRegressor-119"><span class="linenos">119</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="RidgeRegressor-120"><a href="#RidgeRegressor-120"><span class="linenos">120</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="RidgeRegressor-121"><a href="#RidgeRegressor-121"><span class="linenos">121</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="RidgeRegressor-122"><a href="#RidgeRegressor-122"><span class="linenos">122</span></a>
</span><span id="RidgeRegressor-123"><a href="#RidgeRegressor-123"><span class="linenos">123</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="RidgeRegressor-124"><a href="#RidgeRegressor-124"><span class="linenos">124</span></a>
</span><span id="RidgeRegressor-125"><a href="#RidgeRegressor-125"><span class="linenos">125</span></a><span class="sd">        Returns:</span>
</span><span id="RidgeRegressor-126"><a href="#RidgeRegressor-126"><span class="linenos">126</span></a>
</span><span id="RidgeRegressor-127"><a href="#RidgeRegressor-127"><span class="linenos">127</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="RidgeRegressor-128"><a href="#RidgeRegressor-128"><span class="linenos">128</span></a>
</span><span id="RidgeRegressor-129"><a href="#RidgeRegressor-129"><span class="linenos">129</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="RidgeRegressor-130"><a href="#RidgeRegressor-130"><span class="linenos">130</span></a>        <span class="n">X_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xm</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RidgeRegressor-131"><a href="#RidgeRegressor-131"><span class="linenos">131</span></a>
</span><span id="RidgeRegressor-132"><a href="#RidgeRegressor-132"><span class="linenos">132</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="RidgeRegressor-133"><a href="#RidgeRegressor-133"><span class="linenos">133</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="RidgeRegressor-134"><a href="#RidgeRegressor-134"><span class="linenos">134</span></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="RidgeRegressor-135"><a href="#RidgeRegressor-135"><span class="linenos">135</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="RidgeRegressor-136"><a href="#RidgeRegressor-136"><span class="linenos">136</span></a>
</span><span id="RidgeRegressor-137"><a href="#RidgeRegressor-137"><span class="linenos">137</span></a>        <span class="c1"># if self.backend in (&quot;gpu&quot;, &quot;tpu&quot;):</span>
</span><span id="RidgeRegressor-138"><a href="#RidgeRegressor-138"><span class="linenos">138</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="RidgeRegressor-139"><a href="#RidgeRegressor-139"><span class="linenos">139</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="RidgeRegressor-140"><a href="#RidgeRegressor-140"><span class="linenos">140</span></a>                <span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="RidgeRegressor-141"><a href="#RidgeRegressor-141"><span class="linenos">141</span></a>            <span class="p">)</span>
</span><span id="RidgeRegressor-142"><a href="#RidgeRegressor-142"><span class="linenos">142</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="RidgeRegressor-143"><a href="#RidgeRegressor-143"><span class="linenos">143</span></a>            <span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="RidgeRegressor-144"><a href="#RidgeRegressor-144"><span class="linenos">144</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Ridge.</p>

<p>Attributes:</p>

<pre><code>reg_lambda: float
    regularization parameter.

backend: str
    type of backend; must be in ('cpu', 'gpu', 'tpu')
</code></pre>
</div>


                                <div id="RidgeRegressor.fit" class="classattr">
                                            <input id="RidgeRegressor.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="n">y</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="RidgeRegressor.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RidgeRegressor.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RidgeRegressor.fit-52"><a href="#RidgeRegressor.fit-52"><span class="linenos"> 52</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="RidgeRegressor.fit-53"><a href="#RidgeRegressor.fit-53"><span class="linenos"> 53</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit matrixops (classifier) to training data (X, y)</span>
</span><span id="RidgeRegressor.fit-54"><a href="#RidgeRegressor.fit-54"><span class="linenos"> 54</span></a>
</span><span id="RidgeRegressor.fit-55"><a href="#RidgeRegressor.fit-55"><span class="linenos"> 55</span></a><span class="sd">        Args:</span>
</span><span id="RidgeRegressor.fit-56"><a href="#RidgeRegressor.fit-56"><span class="linenos"> 56</span></a>
</span><span id="RidgeRegressor.fit-57"><a href="#RidgeRegressor.fit-57"><span class="linenos"> 57</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="RidgeRegressor.fit-58"><a href="#RidgeRegressor.fit-58"><span class="linenos"> 58</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="RidgeRegressor.fit-59"><a href="#RidgeRegressor.fit-59"><span class="linenos"> 59</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="RidgeRegressor.fit-60"><a href="#RidgeRegressor.fit-60"><span class="linenos"> 60</span></a>
</span><span id="RidgeRegressor.fit-61"><a href="#RidgeRegressor.fit-61"><span class="linenos"> 61</span></a><span class="sd">            y: array-like, shape = [n_samples]</span>
</span><span id="RidgeRegressor.fit-62"><a href="#RidgeRegressor.fit-62"><span class="linenos"> 62</span></a><span class="sd">                Target values.</span>
</span><span id="RidgeRegressor.fit-63"><a href="#RidgeRegressor.fit-63"><span class="linenos"> 63</span></a>
</span><span id="RidgeRegressor.fit-64"><a href="#RidgeRegressor.fit-64"><span class="linenos"> 64</span></a><span class="sd">            **kwargs: additional parameters to be passed to self.cook_training_set.</span>
</span><span id="RidgeRegressor.fit-65"><a href="#RidgeRegressor.fit-65"><span class="linenos"> 65</span></a>
</span><span id="RidgeRegressor.fit-66"><a href="#RidgeRegressor.fit-66"><span class="linenos"> 66</span></a><span class="sd">        Returns:</span>
</span><span id="RidgeRegressor.fit-67"><a href="#RidgeRegressor.fit-67"><span class="linenos"> 67</span></a>
</span><span id="RidgeRegressor.fit-68"><a href="#RidgeRegressor.fit-68"><span class="linenos"> 68</span></a><span class="sd">            self: object.</span>
</span><span id="RidgeRegressor.fit-69"><a href="#RidgeRegressor.fit-69"><span class="linenos"> 69</span></a>
</span><span id="RidgeRegressor.fit-70"><a href="#RidgeRegressor.fit-70"><span class="linenos"> 70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="RidgeRegressor.fit-71"><a href="#RidgeRegressor.fit-71"><span class="linenos"> 71</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="n">centered_y</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">center_response</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-72"><a href="#RidgeRegressor.fit-72"><span class="linenos"> 72</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xm</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-73"><a href="#RidgeRegressor.fit-73"><span class="linenos"> 73</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-74"><a href="#RidgeRegressor.fit-74"><span class="linenos"> 74</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">xsd</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># avoid division by zero</span>
</span><span id="RidgeRegressor.fit-75"><a href="#RidgeRegressor.fit-75"><span class="linenos"> 75</span></a>        <span class="n">X_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xm</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RidgeRegressor.fit-76"><a href="#RidgeRegressor.fit-76"><span class="linenos"> 76</span></a>
</span><span id="RidgeRegressor.fit-77"><a href="#RidgeRegressor.fit-77"><span class="linenos"> 77</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="RidgeRegressor.fit-78"><a href="#RidgeRegressor.fit-78"><span class="linenos"> 78</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">centered_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="RidgeRegressor.fit-79"><a href="#RidgeRegressor.fit-79"><span class="linenos"> 79</span></a>                <span class="n">eye_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="RidgeRegressor.fit-80"><a href="#RidgeRegressor.fit-80"><span class="linenos"> 80</span></a>                <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">X_</span><span class="p">,</span> <span class="n">eye_term</span><span class="p">))</span>
</span><span id="RidgeRegressor.fit-81"><a href="#RidgeRegressor.fit-81"><span class="linenos"> 81</span></a>                <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">centered_y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
</span><span id="RidgeRegressor.fit-82"><a href="#RidgeRegressor.fit-82"><span class="linenos"> 82</span></a>                <span class="c1"># self.beta, _, _, _ = np.linalg.lstsq(X_, y_, rcond=None)</span>
</span><span id="RidgeRegressor.fit-83"><a href="#RidgeRegressor.fit-83"><span class="linenos"> 83</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">get_beta</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-84"><a href="#RidgeRegressor.fit-84"><span class="linenos"> 84</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="RidgeRegressor.fit-85"><a href="#RidgeRegressor.fit-85"><span class="linenos"> 85</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="RidgeRegressor.fit-86"><a href="#RidgeRegressor.fit-86"><span class="linenos"> 86</span></a>                    <span class="n">eye_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="RidgeRegressor.fit-87"><a href="#RidgeRegressor.fit-87"><span class="linenos"> 87</span></a>                    <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">((</span><span class="n">X_</span><span class="p">,</span> <span class="n">eye_term</span><span class="p">))</span>
</span><span id="RidgeRegressor.fit-88"><a href="#RidgeRegressor.fit-88"><span class="linenos"> 88</span></a>                    <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">row_stack</span><span class="p">(</span>
</span><span id="RidgeRegressor.fit-89"><a href="#RidgeRegressor.fit-89"><span class="linenos"> 89</span></a>                        <span class="p">(</span>
</span><span id="RidgeRegressor.fit-90"><a href="#RidgeRegressor.fit-90"><span class="linenos"> 90</span></a>                            <span class="n">centered_y</span><span class="p">,</span>
</span><span id="RidgeRegressor.fit-91"><a href="#RidgeRegressor.fit-91"><span class="linenos"> 91</span></a>                            <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">eye_term</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">centered_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span>
</span><span id="RidgeRegressor.fit-92"><a href="#RidgeRegressor.fit-92"><span class="linenos"> 92</span></a>                        <span class="p">)</span>
</span><span id="RidgeRegressor.fit-93"><a href="#RidgeRegressor.fit-93"><span class="linenos"> 93</span></a>                    <span class="p">)</span>
</span><span id="RidgeRegressor.fit-94"><a href="#RidgeRegressor.fit-94"><span class="linenos"> 94</span></a>                    <span class="c1"># self.beta, _, _, _ = np.linalg.lstsq(X_, y_, rcond=None)</span>
</span><span id="RidgeRegressor.fit-95"><a href="#RidgeRegressor.fit-95"><span class="linenos"> 95</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">get_beta</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y_</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-96"><a href="#RidgeRegressor.fit-96"><span class="linenos"> 96</span></a>                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
</span><span id="RidgeRegressor.fit-97"><a href="#RidgeRegressor.fit-97"><span class="linenos"> 97</span></a>                    <span class="n">x</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span>
</span><span id="RidgeRegressor.fit-98"><a href="#RidgeRegressor.fit-98"><span class="linenos"> 98</span></a>                        <span class="n">mo</span><span class="o">.</span><span class="n">crossprod</span><span class="p">(</span><span class="n">X_</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="RidgeRegressor.fit-99"><a href="#RidgeRegressor.fit-99"><span class="linenos"> 99</span></a>                    <span class="p">)</span>
</span><span id="RidgeRegressor.fit-100"><a href="#RidgeRegressor.fit-100"><span class="linenos">100</span></a>                    <span class="n">hat_matrix</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">tcrossprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-101"><a href="#RidgeRegressor.fit-101"><span class="linenos">101</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">hat_matrix</span><span class="p">,</span> <span class="n">centered_y</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-102"><a href="#RidgeRegressor.fit-102"><span class="linenos">102</span></a>            <span class="k">return</span> <span class="bp">self</span>
</span><span id="RidgeRegressor.fit-103"><a href="#RidgeRegressor.fit-103"><span class="linenos">103</span></a>
</span><span id="RidgeRegressor.fit-104"><a href="#RidgeRegressor.fit-104"><span class="linenos">104</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">jinv</span><span class="p">(</span>
</span><span id="RidgeRegressor.fit-105"><a href="#RidgeRegressor.fit-105"><span class="linenos">105</span></a>            <span class="n">mo</span><span class="o">.</span><span class="n">crossprod</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-106"><a href="#RidgeRegressor.fit-106"><span class="linenos">106</span></a>            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg_lambda</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="RidgeRegressor.fit-107"><a href="#RidgeRegressor.fit-107"><span class="linenos">107</span></a>        <span class="p">)</span>
</span><span id="RidgeRegressor.fit-108"><a href="#RidgeRegressor.fit-108"><span class="linenos">108</span></a>        <span class="n">hat_matrix</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">tcrossprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">X_</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="p">)</span>
</span><span id="RidgeRegressor.fit-109"><a href="#RidgeRegressor.fit-109"><span class="linenos">109</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="RidgeRegressor.fit-110"><a href="#RidgeRegressor.fit-110"><span class="linenos">110</span></a>            <span class="n">hat_matrix</span><span class="p">,</span> <span class="n">centered_y</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="RidgeRegressor.fit-111"><a href="#RidgeRegressor.fit-111"><span class="linenos">111</span></a>        <span class="p">)</span>
</span><span id="RidgeRegressor.fit-112"><a href="#RidgeRegressor.fit-112"><span class="linenos">112</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Fit matrixops (classifier) to training data (X, y)</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

y: array-like, shape = [n_samples]
    Target values.

**kwargs: additional parameters to be passed to self.cook_training_set.
</code></pre>

<p>Returns:</p>

<pre><code>self: object.
</code></pre>
</div>


                                </div>
                                <div id="RidgeRegressor.predict" class="classattr">
                                            <input id="RidgeRegressor.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="RidgeRegressor.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RidgeRegressor.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RidgeRegressor.predict-114"><a href="#RidgeRegressor.predict-114"><span class="linenos">114</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="RidgeRegressor.predict-115"><a href="#RidgeRegressor.predict-115"><span class="linenos">115</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Predict test data X.</span>
</span><span id="RidgeRegressor.predict-116"><a href="#RidgeRegressor.predict-116"><span class="linenos">116</span></a>
</span><span id="RidgeRegressor.predict-117"><a href="#RidgeRegressor.predict-117"><span class="linenos">117</span></a><span class="sd">        Args:</span>
</span><span id="RidgeRegressor.predict-118"><a href="#RidgeRegressor.predict-118"><span class="linenos">118</span></a>
</span><span id="RidgeRegressor.predict-119"><a href="#RidgeRegressor.predict-119"><span class="linenos">119</span></a><span class="sd">            X: {array-like}, shape = [n_samples, n_features]</span>
</span><span id="RidgeRegressor.predict-120"><a href="#RidgeRegressor.predict-120"><span class="linenos">120</span></a><span class="sd">                Training vectors, where n_samples is the number</span>
</span><span id="RidgeRegressor.predict-121"><a href="#RidgeRegressor.predict-121"><span class="linenos">121</span></a><span class="sd">                of samples and n_features is the number of features.</span>
</span><span id="RidgeRegressor.predict-122"><a href="#RidgeRegressor.predict-122"><span class="linenos">122</span></a>
</span><span id="RidgeRegressor.predict-123"><a href="#RidgeRegressor.predict-123"><span class="linenos">123</span></a><span class="sd">            **kwargs: additional parameters to be passed to `predict_proba`</span>
</span><span id="RidgeRegressor.predict-124"><a href="#RidgeRegressor.predict-124"><span class="linenos">124</span></a>
</span><span id="RidgeRegressor.predict-125"><a href="#RidgeRegressor.predict-125"><span class="linenos">125</span></a><span class="sd">        Returns:</span>
</span><span id="RidgeRegressor.predict-126"><a href="#RidgeRegressor.predict-126"><span class="linenos">126</span></a>
</span><span id="RidgeRegressor.predict-127"><a href="#RidgeRegressor.predict-127"><span class="linenos">127</span></a><span class="sd">            model predictions: {array-like}</span>
</span><span id="RidgeRegressor.predict-128"><a href="#RidgeRegressor.predict-128"><span class="linenos">128</span></a>
</span><span id="RidgeRegressor.predict-129"><a href="#RidgeRegressor.predict-129"><span class="linenos">129</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="RidgeRegressor.predict-130"><a href="#RidgeRegressor.predict-130"><span class="linenos">130</span></a>        <span class="n">X_</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">xm</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">xsd</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="RidgeRegressor.predict-131"><a href="#RidgeRegressor.predict-131"><span class="linenos">131</span></a>
</span><span id="RidgeRegressor.predict-132"><a href="#RidgeRegressor.predict-132"><span class="linenos">132</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="RidgeRegressor.predict-133"><a href="#RidgeRegressor.predict-133"><span class="linenos">133</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="RidgeRegressor.predict-134"><a href="#RidgeRegressor.predict-134"><span class="linenos">134</span></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="RidgeRegressor.predict-135"><a href="#RidgeRegressor.predict-135"><span class="linenos">135</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="RidgeRegressor.predict-136"><a href="#RidgeRegressor.predict-136"><span class="linenos">136</span></a>
</span><span id="RidgeRegressor.predict-137"><a href="#RidgeRegressor.predict-137"><span class="linenos">137</span></a>        <span class="c1"># if self.backend in (&quot;gpu&quot;, &quot;tpu&quot;):</span>
</span><span id="RidgeRegressor.predict-138"><a href="#RidgeRegressor.predict-138"><span class="linenos">138</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
</span><span id="RidgeRegressor.predict-139"><a href="#RidgeRegressor.predict-139"><span class="linenos">139</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="RidgeRegressor.predict-140"><a href="#RidgeRegressor.predict-140"><span class="linenos">140</span></a>                <span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="RidgeRegressor.predict-141"><a href="#RidgeRegressor.predict-141"><span class="linenos">141</span></a>            <span class="p">)</span>
</span><span id="RidgeRegressor.predict-142"><a href="#RidgeRegressor.predict-142"><span class="linenos">142</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ym</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">mo</span><span class="o">.</span><span class="n">safe_sparse_dot</span><span class="p">(</span>
</span><span id="RidgeRegressor.predict-143"><a href="#RidgeRegressor.predict-143"><span class="linenos">143</span></a>            <span class="n">X_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">backend</span>
</span><span id="RidgeRegressor.predict-144"><a href="#RidgeRegressor.predict-144"><span class="linenos">144</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Predict test data X.</p>

<p>Args:</p>

<pre><code>X: {array-like}, shape = [n_samples, n_features]
    Training vectors, where n_samples is the number
    of samples and n_features is the number of features.

**kwargs: additional parameters to be passed to `predict_proba`
</code></pre>

<p>Returns:</p>

<pre><code>model predictions: {array-like}
</code></pre>
</div>


                                </div>
                        
                </section>
                <section id="download">
                            <input id="download-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">download</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">pkgname</span><span class="o">=</span><span class="s1">&#39;MASS&#39;</span>,</span><span class="param">	<span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;Boston&#39;</span>,</span><span class="param">	<span class="n">source</span><span class="o">=</span><span class="s1">&#39;https://cran.r-universe.dev/&#39;</span>,</span><span class="param">	<span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="download-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#download"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="download-6"><a href="#download-6"><span class="linenos"> 6</span></a><span class="k">def</span> <span class="nf">download</span><span class="p">(</span>
</span><span id="download-7"><a href="#download-7"><span class="linenos"> 7</span></a>    <span class="n">pkgname</span><span class="o">=</span><span class="s2">&quot;MASS&quot;</span><span class="p">,</span>
</span><span id="download-8"><a href="#download-8"><span class="linenos"> 8</span></a>    <span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;Boston&quot;</span><span class="p">,</span>
</span><span id="download-9"><a href="#download-9"><span class="linenos"> 9</span></a>    <span class="n">source</span><span class="o">=</span><span class="s2">&quot;https://cran.r-universe.dev/&quot;</span><span class="p">,</span>
</span><span id="download-10"><a href="#download-10"><span class="linenos">10</span></a>    <span class="o">**</span><span class="n">kwargs</span>
</span><span id="download-11"><a href="#download-11"><span class="linenos">11</span></a><span class="p">):</span>
</span><span id="download-12"><a href="#download-12"><span class="linenos">12</span></a>    <span class="n">URL</span> <span class="o">=</span> <span class="n">source</span> <span class="o">+</span> <span class="n">pkgname</span> <span class="o">+</span> <span class="s2">&quot;/data/&quot;</span> <span class="o">+</span> <span class="n">dataset</span> <span class="o">+</span> <span class="s2">&quot;/json&quot;</span>
</span><span id="download-13"><a href="#download-13"><span class="linenos">13</span></a>    <span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">URL</span><span class="p">)</span>
</span><span id="download-14"><a href="#download-14"><span class="linenos">14</span></a>    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">json</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></pre></div>


    

                </section>
                <section id="get_config">
                            <input id="get_config-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_config</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="get_config-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_config"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_config-16"><a href="#get_config-16"><span class="linenos">16</span></a><span class="k">def</span> <span class="nf">get_config</span><span class="p">():</span>
</span><span id="get_config-17"><a href="#get_config-17"><span class="linenos">17</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Retrieve current values for configuration set by :func:`set_config`</span>
</span><span id="get_config-18"><a href="#get_config-18"><span class="linenos">18</span></a>
</span><span id="get_config-19"><a href="#get_config-19"><span class="linenos">19</span></a><span class="sd">    Returns</span>
</span><span id="get_config-20"><a href="#get_config-20"><span class="linenos">20</span></a><span class="sd">    -------</span>
</span><span id="get_config-21"><a href="#get_config-21"><span class="linenos">21</span></a><span class="sd">    config : dict</span>
</span><span id="get_config-22"><a href="#get_config-22"><span class="linenos">22</span></a><span class="sd">        Keys are parameter names that can be passed to :func:`set_config`.</span>
</span><span id="get_config-23"><a href="#get_config-23"><span class="linenos">23</span></a>
</span><span id="get_config-24"><a href="#get_config-24"><span class="linenos">24</span></a><span class="sd">    See Also</span>
</span><span id="get_config-25"><a href="#get_config-25"><span class="linenos">25</span></a><span class="sd">    --------</span>
</span><span id="get_config-26"><a href="#get_config-26"><span class="linenos">26</span></a><span class="sd">    config_context: Context manager for global mlsauce configuration</span>
</span><span id="get_config-27"><a href="#get_config-27"><span class="linenos">27</span></a><span class="sd">    set_config: Set global mlsauce configuration</span>
</span><span id="get_config-28"><a href="#get_config-28"><span class="linenos">28</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="get_config-29"><a href="#get_config-29"><span class="linenos">29</span></a>    <span class="k">return</span> <span class="n">_global_config</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Retrieve current values for configuration set by <code><a href="#set_config">set_config()</a></code></p>

<h2 id="returns">Returns</h2>

<p>config : dict
    Keys are parameter names that can be passed to <code><a href="#set_config">set_config()</a></code>.</p>

<h2 id="see-also">See Also</h2>

<p>config_context: Context manager for global mlsauce configuration
set_config: Set global mlsauce configuration</p>
</div>


                </section>
                <section id="set_config">
                            <input id="set_config-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">set_config</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">assume_finite</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">working_memory</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">print_changed_only</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">display</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="set_config-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#set_config"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="set_config-32"><a href="#set_config-32"><span class="linenos">32</span></a><span class="k">def</span> <span class="nf">set_config</span><span class="p">(</span>
</span><span id="set_config-33"><a href="#set_config-33"><span class="linenos">33</span></a>    <span class="n">assume_finite</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="set_config-34"><a href="#set_config-34"><span class="linenos">34</span></a>    <span class="n">working_memory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="set_config-35"><a href="#set_config-35"><span class="linenos">35</span></a>    <span class="n">print_changed_only</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="set_config-36"><a href="#set_config-36"><span class="linenos">36</span></a>    <span class="n">display</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="set_config-37"><a href="#set_config-37"><span class="linenos">37</span></a><span class="p">):</span>
</span><span id="set_config-38"><a href="#set_config-38"><span class="linenos">38</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Set global mlsauce configuration</span>
</span><span id="set_config-39"><a href="#set_config-39"><span class="linenos">39</span></a>
</span><span id="set_config-40"><a href="#set_config-40"><span class="linenos">40</span></a><span class="sd">    .. versionadded:: 0.3.0</span>
</span><span id="set_config-41"><a href="#set_config-41"><span class="linenos">41</span></a>
</span><span id="set_config-42"><a href="#set_config-42"><span class="linenos">42</span></a><span class="sd">    Parameters</span>
</span><span id="set_config-43"><a href="#set_config-43"><span class="linenos">43</span></a><span class="sd">    ----------</span>
</span><span id="set_config-44"><a href="#set_config-44"><span class="linenos">44</span></a><span class="sd">    assume_finite : bool, optional</span>
</span><span id="set_config-45"><a href="#set_config-45"><span class="linenos">45</span></a><span class="sd">        If True, validation for finiteness will be skipped,</span>
</span><span id="set_config-46"><a href="#set_config-46"><span class="linenos">46</span></a><span class="sd">        saving time, but leading to potential crashes. If</span>
</span><span id="set_config-47"><a href="#set_config-47"><span class="linenos">47</span></a><span class="sd">        False, validation for finiteness will be performed,</span>
</span><span id="set_config-48"><a href="#set_config-48"><span class="linenos">48</span></a><span class="sd">        avoiding error.  Global default: False.</span>
</span><span id="set_config-49"><a href="#set_config-49"><span class="linenos">49</span></a>
</span><span id="set_config-50"><a href="#set_config-50"><span class="linenos">50</span></a><span class="sd">        .. versionadded:: 0.3.0</span>
</span><span id="set_config-51"><a href="#set_config-51"><span class="linenos">51</span></a>
</span><span id="set_config-52"><a href="#set_config-52"><span class="linenos">52</span></a><span class="sd">    working_memory : int, optional</span>
</span><span id="set_config-53"><a href="#set_config-53"><span class="linenos">53</span></a><span class="sd">        If set, mlsauce will attempt to limit the size of temporary arrays</span>
</span><span id="set_config-54"><a href="#set_config-54"><span class="linenos">54</span></a><span class="sd">        to this number of MiB (per job when parallelised), often saving both</span>
</span><span id="set_config-55"><a href="#set_config-55"><span class="linenos">55</span></a><span class="sd">        computation time and memory on expensive operations that can be</span>
</span><span id="set_config-56"><a href="#set_config-56"><span class="linenos">56</span></a><span class="sd">        performed in chunks. Global default: 1024.</span>
</span><span id="set_config-57"><a href="#set_config-57"><span class="linenos">57</span></a>
</span><span id="set_config-58"><a href="#set_config-58"><span class="linenos">58</span></a><span class="sd">        .. versionadded:: 0.3.0</span>
</span><span id="set_config-59"><a href="#set_config-59"><span class="linenos">59</span></a>
</span><span id="set_config-60"><a href="#set_config-60"><span class="linenos">60</span></a><span class="sd">    print_changed_only : bool, optional</span>
</span><span id="set_config-61"><a href="#set_config-61"><span class="linenos">61</span></a><span class="sd">        If True, only the parameters that were set to non-default</span>
</span><span id="set_config-62"><a href="#set_config-62"><span class="linenos">62</span></a><span class="sd">        values will be printed when printing an estimator. For example,</span>
</span><span id="set_config-63"><a href="#set_config-63"><span class="linenos">63</span></a><span class="sd">        ``print(SVC())`` while True will only print &#39;SVC()&#39; while the default</span>
</span><span id="set_config-64"><a href="#set_config-64"><span class="linenos">64</span></a><span class="sd">        behaviour would be to print &#39;SVC(C=1.0, cache_size=200, ...)&#39; with</span>
</span><span id="set_config-65"><a href="#set_config-65"><span class="linenos">65</span></a><span class="sd">        all the non-changed parameters.</span>
</span><span id="set_config-66"><a href="#set_config-66"><span class="linenos">66</span></a>
</span><span id="set_config-67"><a href="#set_config-67"><span class="linenos">67</span></a><span class="sd">        .. versionadded:: 0.3.0</span>
</span><span id="set_config-68"><a href="#set_config-68"><span class="linenos">68</span></a>
</span><span id="set_config-69"><a href="#set_config-69"><span class="linenos">69</span></a><span class="sd">    display : {&#39;text&#39;, &#39;diagram&#39;}, optional</span>
</span><span id="set_config-70"><a href="#set_config-70"><span class="linenos">70</span></a><span class="sd">        If &#39;diagram&#39;, estimators will be displayed as text in a jupyter lab</span>
</span><span id="set_config-71"><a href="#set_config-71"><span class="linenos">71</span></a><span class="sd">        of notebook context. If &#39;text&#39;, estimators will be displayed as</span>
</span><span id="set_config-72"><a href="#set_config-72"><span class="linenos">72</span></a><span class="sd">        text. Default is &#39;text&#39;.</span>
</span><span id="set_config-73"><a href="#set_config-73"><span class="linenos">73</span></a>
</span><span id="set_config-74"><a href="#set_config-74"><span class="linenos">74</span></a><span class="sd">        .. versionadded:: 0.3.0</span>
</span><span id="set_config-75"><a href="#set_config-75"><span class="linenos">75</span></a>
</span><span id="set_config-76"><a href="#set_config-76"><span class="linenos">76</span></a><span class="sd">    See Also</span>
</span><span id="set_config-77"><a href="#set_config-77"><span class="linenos">77</span></a><span class="sd">    --------</span>
</span><span id="set_config-78"><a href="#set_config-78"><span class="linenos">78</span></a><span class="sd">    config_context: Context manager for global mlsauce configuration</span>
</span><span id="set_config-79"><a href="#set_config-79"><span class="linenos">79</span></a><span class="sd">    get_config: Retrieve current values of the global configuration</span>
</span><span id="set_config-80"><a href="#set_config-80"><span class="linenos">80</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="set_config-81"><a href="#set_config-81"><span class="linenos">81</span></a>    <span class="k">if</span> <span class="n">assume_finite</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="set_config-82"><a href="#set_config-82"><span class="linenos">82</span></a>        <span class="n">_global_config</span><span class="p">[</span><span class="s2">&quot;assume_finite&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">assume_finite</span>
</span><span id="set_config-83"><a href="#set_config-83"><span class="linenos">83</span></a>    <span class="k">if</span> <span class="n">working_memory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="set_config-84"><a href="#set_config-84"><span class="linenos">84</span></a>        <span class="n">_global_config</span><span class="p">[</span><span class="s2">&quot;working_memory&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">working_memory</span>
</span><span id="set_config-85"><a href="#set_config-85"><span class="linenos">85</span></a>    <span class="k">if</span> <span class="n">print_changed_only</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="set_config-86"><a href="#set_config-86"><span class="linenos">86</span></a>        <span class="n">_global_config</span><span class="p">[</span><span class="s2">&quot;print_changed_only&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">print_changed_only</span>
</span><span id="set_config-87"><a href="#set_config-87"><span class="linenos">87</span></a>    <span class="k">if</span> <span class="n">display</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="set_config-88"><a href="#set_config-88"><span class="linenos">88</span></a>        <span class="n">_global_config</span><span class="p">[</span><span class="s2">&quot;display&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">display</span>
</span></pre></div>


            <div class="docstring"><p>Set global mlsauce configuration</p>

<p><em>New in version 0.3.0.</em></p>

<h2 id="parameters">Parameters</h2>

<p>assume_finite : bool, optional
    If True, validation for finiteness will be skipped,
    saving time, but leading to potential crashes. If
    False, validation for finiteness will be performed,
    avoiding error.  Global default: False.</p>

<pre><code>*New in version 0.3.0.*
</code></pre>

<p>working_memory : int, optional
    If set, mlsauce will attempt to limit the size of temporary arrays
    to this number of MiB (per job when parallelised), often saving both
    computation time and memory on expensive operations that can be
    performed in chunks. Global default: 1024.</p>

<pre><code>*New in version 0.3.0.*
</code></pre>

<p>print_changed_only : bool, optional
    If True, only the parameters that were set to non-default
    values will be printed when printing an estimator. For example,
    <code>print(SVC())</code> while True will only print 'SVC()' while the default
    behaviour would be to print 'SVC(C=1.0, cache_size=200, ...)' with
    all the non-changed parameters.</p>

<pre><code>*New in version 0.3.0.*
</code></pre>

<p>display : {'text', 'diagram'}, optional
    If 'diagram', estimators will be displayed as text in a jupyter lab
    of notebook context. If 'text', estimators will be displayed as
    text. Default is 'text'.</p>

<pre><code>*New in version 0.3.0.*
</code></pre>

<h2 id="see-also">See Also</h2>

<p>config_context: Context manager for global mlsauce configuration
get_config: Retrieve current values of the global configuration</p>
</div>


                </section>
                <section id="config_context">
                            <input id="config_context-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@contextmanager</div>

        <span class="def">def</span>
        <span class="name">config_context</span><span class="signature pdoc-code condensed">(<span class="param"><span class="o">**</span><span class="n">new_config</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="config_context-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#config_context"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="config_context-91"><a href="#config_context-91"><span class="linenos"> 91</span></a><span class="nd">@contextmanager</span>
</span><span id="config_context-92"><a href="#config_context-92"><span class="linenos"> 92</span></a><span class="k">def</span> <span class="nf">config_context</span><span class="p">(</span><span class="o">**</span><span class="n">new_config</span><span class="p">):</span>
</span><span id="config_context-93"><a href="#config_context-93"><span class="linenos"> 93</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Context manager for global mlsauce configuration</span>
</span><span id="config_context-94"><a href="#config_context-94"><span class="linenos"> 94</span></a>
</span><span id="config_context-95"><a href="#config_context-95"><span class="linenos"> 95</span></a><span class="sd">    Parameters</span>
</span><span id="config_context-96"><a href="#config_context-96"><span class="linenos"> 96</span></a><span class="sd">    ----------</span>
</span><span id="config_context-97"><a href="#config_context-97"><span class="linenos"> 97</span></a><span class="sd">    assume_finite : bool, optional</span>
</span><span id="config_context-98"><a href="#config_context-98"><span class="linenos"> 98</span></a><span class="sd">        If True, validation for finiteness will be skipped,</span>
</span><span id="config_context-99"><a href="#config_context-99"><span class="linenos"> 99</span></a><span class="sd">        saving time, but leading to potential crashes. If</span>
</span><span id="config_context-100"><a href="#config_context-100"><span class="linenos">100</span></a><span class="sd">        False, validation for finiteness will be performed,</span>
</span><span id="config_context-101"><a href="#config_context-101"><span class="linenos">101</span></a><span class="sd">        avoiding error.  Global default: False.</span>
</span><span id="config_context-102"><a href="#config_context-102"><span class="linenos">102</span></a>
</span><span id="config_context-103"><a href="#config_context-103"><span class="linenos">103</span></a><span class="sd">    working_memory : int, optional</span>
</span><span id="config_context-104"><a href="#config_context-104"><span class="linenos">104</span></a><span class="sd">        If set, mlsauce will attempt to limit the size of temporary arrays</span>
</span><span id="config_context-105"><a href="#config_context-105"><span class="linenos">105</span></a><span class="sd">        to this number of MiB (per job when parallelised), often saving both</span>
</span><span id="config_context-106"><a href="#config_context-106"><span class="linenos">106</span></a><span class="sd">        computation time and memory on expensive operations that can be</span>
</span><span id="config_context-107"><a href="#config_context-107"><span class="linenos">107</span></a><span class="sd">        performed in chunks. Global default: 1024.</span>
</span><span id="config_context-108"><a href="#config_context-108"><span class="linenos">108</span></a>
</span><span id="config_context-109"><a href="#config_context-109"><span class="linenos">109</span></a><span class="sd">    print_changed_only : bool, optional</span>
</span><span id="config_context-110"><a href="#config_context-110"><span class="linenos">110</span></a><span class="sd">        If True, only the parameters that were set to non-default</span>
</span><span id="config_context-111"><a href="#config_context-111"><span class="linenos">111</span></a><span class="sd">        values will be printed when printing an estimator. For example,</span>
</span><span id="config_context-112"><a href="#config_context-112"><span class="linenos">112</span></a><span class="sd">        ``print(SVC())`` while True will only print &#39;SVC()&#39;, but would print</span>
</span><span id="config_context-113"><a href="#config_context-113"><span class="linenos">113</span></a><span class="sd">        &#39;SVC(C=1.0, cache_size=200, ...)&#39; with all the non-changed parameters</span>
</span><span id="config_context-114"><a href="#config_context-114"><span class="linenos">114</span></a><span class="sd">        when False. Default is True.</span>
</span><span id="config_context-115"><a href="#config_context-115"><span class="linenos">115</span></a>
</span><span id="config_context-116"><a href="#config_context-116"><span class="linenos">116</span></a><span class="sd">        .. versionadded:: 0.3.0</span>
</span><span id="config_context-117"><a href="#config_context-117"><span class="linenos">117</span></a>
</span><span id="config_context-118"><a href="#config_context-118"><span class="linenos">118</span></a><span class="sd">    display : {&#39;text&#39;, &#39;diagram&#39;}, optional</span>
</span><span id="config_context-119"><a href="#config_context-119"><span class="linenos">119</span></a><span class="sd">        If &#39;diagram&#39;, estimators will be displayed as text in a jupyter lab</span>
</span><span id="config_context-120"><a href="#config_context-120"><span class="linenos">120</span></a><span class="sd">        of notebook context. If &#39;text&#39;, estimators will be displayed as</span>
</span><span id="config_context-121"><a href="#config_context-121"><span class="linenos">121</span></a><span class="sd">        text. Default is &#39;text&#39;.</span>
</span><span id="config_context-122"><a href="#config_context-122"><span class="linenos">122</span></a>
</span><span id="config_context-123"><a href="#config_context-123"><span class="linenos">123</span></a><span class="sd">        .. versionadded:: 0.3.0</span>
</span><span id="config_context-124"><a href="#config_context-124"><span class="linenos">124</span></a>
</span><span id="config_context-125"><a href="#config_context-125"><span class="linenos">125</span></a><span class="sd">    Notes</span>
</span><span id="config_context-126"><a href="#config_context-126"><span class="linenos">126</span></a><span class="sd">    -----</span>
</span><span id="config_context-127"><a href="#config_context-127"><span class="linenos">127</span></a><span class="sd">    All settings, not just those presently modified, will be returned to</span>
</span><span id="config_context-128"><a href="#config_context-128"><span class="linenos">128</span></a><span class="sd">    their previous values when the context manager is exited. This is not</span>
</span><span id="config_context-129"><a href="#config_context-129"><span class="linenos">129</span></a><span class="sd">    thread-safe.</span>
</span><span id="config_context-130"><a href="#config_context-130"><span class="linenos">130</span></a>
</span><span id="config_context-131"><a href="#config_context-131"><span class="linenos">131</span></a><span class="sd">    Examples</span>
</span><span id="config_context-132"><a href="#config_context-132"><span class="linenos">132</span></a><span class="sd">    --------</span>
</span><span id="config_context-133"><a href="#config_context-133"><span class="linenos">133</span></a><span class="sd">    &gt;&gt;&gt; import mlsauce</span>
</span><span id="config_context-134"><a href="#config_context-134"><span class="linenos">134</span></a><span class="sd">    &gt;&gt;&gt; from mlsauce.utils.validation import assert_all_finite</span>
</span><span id="config_context-135"><a href="#config_context-135"><span class="linenos">135</span></a><span class="sd">    &gt;&gt;&gt; with mlsauce.config_context(assume_finite=True):</span>
</span><span id="config_context-136"><a href="#config_context-136"><span class="linenos">136</span></a><span class="sd">    ...     assert_all_finite([float(&#39;nan&#39;)])</span>
</span><span id="config_context-137"><a href="#config_context-137"><span class="linenos">137</span></a><span class="sd">    &gt;&gt;&gt; with mlsauce.config_context(assume_finite=True):</span>
</span><span id="config_context-138"><a href="#config_context-138"><span class="linenos">138</span></a><span class="sd">    ...     with mlsauce.config_context(assume_finite=False):</span>
</span><span id="config_context-139"><a href="#config_context-139"><span class="linenos">139</span></a><span class="sd">    ...         assert_all_finite([float(&#39;nan&#39;)])</span>
</span><span id="config_context-140"><a href="#config_context-140"><span class="linenos">140</span></a><span class="sd">    Traceback (most recent call last):</span>
</span><span id="config_context-141"><a href="#config_context-141"><span class="linenos">141</span></a><span class="sd">    ...</span>
</span><span id="config_context-142"><a href="#config_context-142"><span class="linenos">142</span></a><span class="sd">    ValueError: Input contains NaN, ...</span>
</span><span id="config_context-143"><a href="#config_context-143"><span class="linenos">143</span></a>
</span><span id="config_context-144"><a href="#config_context-144"><span class="linenos">144</span></a><span class="sd">    See Also</span>
</span><span id="config_context-145"><a href="#config_context-145"><span class="linenos">145</span></a><span class="sd">    --------</span>
</span><span id="config_context-146"><a href="#config_context-146"><span class="linenos">146</span></a><span class="sd">    set_config: Set global mlsauce configuration</span>
</span><span id="config_context-147"><a href="#config_context-147"><span class="linenos">147</span></a><span class="sd">    get_config: Retrieve current values of the global configuration</span>
</span><span id="config_context-148"><a href="#config_context-148"><span class="linenos">148</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="config_context-149"><a href="#config_context-149"><span class="linenos">149</span></a>    <span class="n">old_config</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="config_context-150"><a href="#config_context-150"><span class="linenos">150</span></a>    <span class="n">set_config</span><span class="p">(</span><span class="o">**</span><span class="n">new_config</span><span class="p">)</span>
</span><span id="config_context-151"><a href="#config_context-151"><span class="linenos">151</span></a>
</span><span id="config_context-152"><a href="#config_context-152"><span class="linenos">152</span></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="config_context-153"><a href="#config_context-153"><span class="linenos">153</span></a>        <span class="k">yield</span>
</span><span id="config_context-154"><a href="#config_context-154"><span class="linenos">154</span></a>    <span class="k">finally</span><span class="p">:</span>
</span><span id="config_context-155"><a href="#config_context-155"><span class="linenos">155</span></a>        <span class="n">set_config</span><span class="p">(</span><span class="o">**</span><span class="n">old_config</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Context manager for global mlsauce configuration</p>

<h2 id="parameters">Parameters</h2>

<p>assume_finite : bool, optional
    If True, validation for finiteness will be skipped,
    saving time, but leading to potential crashes. If
    False, validation for finiteness will be performed,
    avoiding error.  Global default: False.</p>

<p>working_memory : int, optional
    If set, mlsauce will attempt to limit the size of temporary arrays
    to this number of MiB (per job when parallelised), often saving both
    computation time and memory on expensive operations that can be
    performed in chunks. Global default: 1024.</p>

<p>print_changed_only : bool, optional
    If True, only the parameters that were set to non-default
    values will be printed when printing an estimator. For example,
    <code>print(SVC())</code> while True will only print 'SVC()', but would print
    'SVC(C=1.0, cache_size=200, ...)' with all the non-changed parameters
    when False. Default is True.</p>

<pre><code>*New in version 0.3.0.*
</code></pre>

<p>display : {'text', 'diagram'}, optional
    If 'diagram', estimators will be displayed as text in a jupyter lab
    of notebook context. If 'text', estimators will be displayed as
    text. Default is 'text'.</p>

<pre><code>*New in version 0.3.0.*
</code></pre>

<h2 id="notes">Notes</h2>

<p>All settings, not just those presently modified, will be returned to
their previous values when the context manager is exited. This is not
thread-safe.</p>

<h2 id="examples">Examples</h2>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mlsauce</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mlsauce.utils.validation</span> <span class="kn">import</span> <span class="n">assert_all_finite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#config_context">mlsauce.config_context</a></span><span class="p">(</span><span class="n">assume_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">assert_all_finite</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n"><a href="#config_context">mlsauce.config_context</a></span><span class="p">(</span><span class="n">assume_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">with</span> <span class="n"><a href="#config_context">mlsauce.config_context</a></span><span class="p">(</span><span class="n">assume_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">assert_all_finite</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)])</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="c">...</span>
<span class="gr">ValueError</span>: <span class="n">Input contains NaN, ...</span>
</code></pre>
</div>

<h2 id="see-also">See Also</h2>

<p>set_config: Set global mlsauce configuration
get_config: Retrieve current values of the global configuration</p>
</div>


                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>